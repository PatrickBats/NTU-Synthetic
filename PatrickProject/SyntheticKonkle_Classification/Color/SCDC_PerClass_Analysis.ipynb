{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDC (Same Class Different Color) Per-Class Analysis with Error Bars\n",
    "\n",
    "This notebook tests color discrimination within the same object class.\n",
    "For example: Can models distinguish red apple vs blue apple vs green apple?\n",
    "\n",
    "Key difference from Class test:\n",
    "- Class test: Different objects, same properties (apple vs ball, both red-small-smooth)\n",
    "- SCDC test: Same object, different colors (red apple vs blue apple, both small-smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir))\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "\n",
    "# SyntheticKonkle paths - Using 224x224 resized images for faster processing\n",
    "DATA_DIR = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle_224')\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup\n",
    "def build_synthetic_dataset():\n",
    "    \"\"\"Combine all labels.csv files from class_color folders.\"\"\"\n",
    "    all_data = []\n",
    "    # Note: In SyntheticKonkle_224, folders are nested under SyntheticKonkle/\n",
    "    base_dir = os.path.join(DATA_DIR, 'SyntheticKonkle')\n",
    "    \n",
    "    class_folders = [d for d in os.listdir(base_dir) \n",
    "                    if os.path.isdir(os.path.join(base_dir, d)) \n",
    "                    and d.endswith('_color')]\n",
    "    \n",
    "    for folder in class_folders:\n",
    "        labels_path = os.path.join(base_dir, folder, 'labels.csv')\n",
    "        if os.path.exists(labels_path):\n",
    "            df = pd.read_csv(labels_path)\n",
    "            df['folder'] = folder\n",
    "            all_data.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df = combined_df.dropna(subset=['class'])\n",
    "    print(f\"Loaded {len(combined_df)} images from {len(class_folders)} classes\")\n",
    "    unique_classes = combined_df['class'].unique()\n",
    "    unique_colors = combined_df['color'].unique()\n",
    "    print(f\"Classes found: {len(unique_classes)}\")\n",
    "    print(f\"Colors found: {len(unique_colors)}: {unique_colors}\")\n",
    "    return combined_df\n",
    "\n",
    "class SyntheticImageDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform):\n",
    "        self.df = df\n",
    "        # For SyntheticKonkle_224, images are in nested structure\n",
    "        self.data_dir = os.path.join(data_dir, 'SyntheticKonkle')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row['folder'], row['filename'])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "        except:\n",
    "            img = Image.new('RGB', (224, 224), color='black')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    colors = [b[2] for b in batch]\n",
    "    sizes = [b[3] for b in batch]\n",
    "    textures = [b[4] for b in batch]\n",
    "    idxs = [b[5] for b in batch]\n",
    "    return imgs, classes, colors, sizes, textures, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scdc_test_per_class(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', \n",
    "                            batch_size=64, trials_per_class=500):\n",
    "    \"\"\"Run SCDC (Same Class Different Color) test and return per-class results.\n",
    "    \n",
    "    Tests if model can distinguish different colors of the same object.\n",
    "    Example: red apple vs blue apple vs green apple (all small-smooth).\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Load model & transform\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    \n",
    "    # Build dataset and extract embeddings\n",
    "    df = build_synthetic_dataset()\n",
    "    ds = SyntheticImageDataset(df, DATA_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    all_embs, all_classes, all_colors, all_sizes, all_textures, all_idxs = [], [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, colors, sizes, textures, idxs in loader:\n",
    "            feats = extractor.get_img_feature(imgs.to(device))\n",
    "            feats = extractor.norm_features(feats).cpu().float()\n",
    "            all_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_colors.extend(colors)\n",
    "            all_sizes.extend(sizes)\n",
    "            all_textures.extend(textures)\n",
    "            all_idxs.extend(idxs)\n",
    "    all_embs = torch.cat(all_embs, dim=0)\n",
    "\n",
    "    # Group by class, size, texture (keeping these constant) and vary color\n",
    "    # Structure: class_size_texture_groups[cls][(size, texture)] = {color: [idx_list]}\n",
    "    class_size_texture_groups = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    for idx, cls, col, size, texture in zip(all_idxs, all_classes, all_colors, all_sizes, all_textures):\n",
    "        class_size_texture_groups[cls][(size, texture)][col].append(idx)\n",
    "\n",
    "    # Track per-class performance for color discrimination\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    # Get unique classes and colors\n",
    "    unique_classes = list(class_size_texture_groups.keys())\n",
    "    all_colors_set = set(all_colors)\n",
    "    \n",
    "    # Run trials for each class\n",
    "    for target_class in tqdm(unique_classes, desc=f\"Testing {model_name} SCDC\"):\n",
    "        trials_done = 0\n",
    "        \n",
    "        # For each size-texture combination in this class\n",
    "        for (size, texture), color_groups in class_size_texture_groups[target_class].items():\n",
    "            if trials_done >= trials_per_class:\n",
    "                break\n",
    "            \n",
    "            # Need at least 4 different colors for this class-size-texture combo\n",
    "            available_colors = list(color_groups.keys())\n",
    "            if len(available_colors) < 4:\n",
    "                continue\n",
    "            \n",
    "            # Run multiple trials for this combination\n",
    "            n_trials = min(50, trials_per_class - trials_done)  # More trials per combo\n",
    "            \n",
    "            for _ in range(n_trials):\n",
    "                # Pick target color and 3 distractor colors\n",
    "                selected_colors = random.sample(available_colors, 4)\n",
    "                target_color = selected_colors[0]\n",
    "                distractor_colors = selected_colors[1:4]\n",
    "                \n",
    "                # Pick query image from target color\n",
    "                q = random.choice(color_groups[target_color])\n",
    "                \n",
    "                # Build prototype from other images of same color (if available)\n",
    "                same_color_group = [i for i in color_groups[target_color] if i != q]\n",
    "                if same_color_group:\n",
    "                    proto = all_embs[[all_idxs.index(i) for i in same_color_group]].mean(0)\n",
    "                else:\n",
    "                    proto = all_embs[all_idxs.index(q)]\n",
    "                proto = proto / proto.norm()\n",
    "\n",
    "                # Pick one distractor from each distractor color\n",
    "                distractors = []\n",
    "                for dist_color in distractor_colors:\n",
    "                    if color_groups[dist_color]:  # Make sure color group exists\n",
    "                        distractors.append(random.choice(color_groups[dist_color]))\n",
    "                \n",
    "                if len(distractors) < 3:\n",
    "                    continue  # Skip if we couldn't get enough distractors\n",
    "                \n",
    "                candidates = [q] + distractors\n",
    "                \n",
    "                # Compute similarities\n",
    "                feats_cand = all_embs[[all_idxs.index(i) for i in candidates]]\n",
    "                sims = feats_cand @ proto\n",
    "                guess = candidates[sims.argmax().item()]\n",
    "\n",
    "                # Update counts\n",
    "                class_correct[target_class] += int(guess == q)\n",
    "                class_total[target_class] += 1\n",
    "                trials_done += 1\n",
    "    \n",
    "    # Calculate per-class accuracy for color discrimination\n",
    "    class_accuracies = {}\n",
    "    for cls in unique_classes:\n",
    "        if class_total[cls] > 0:\n",
    "            class_accuracies[cls] = class_correct[cls] / class_total[cls]\n",
    "        else:\n",
    "            class_accuracies[cls] = 0.0\n",
    "    \n",
    "    return class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple seeds for both models - PUBLICATION SETTINGS\n",
    "n_seeds = 3  # Limited seeds due to CVCL rate limiting\n",
    "trials_per_class = 500  # Increased trials for better statistical power\n",
    "models_to_test = ['cvcl-resnext', 'clip-res']\n",
    "\n",
    "# First, check dataset\n",
    "test_df = build_synthetic_dataset()\n",
    "n_classes = len(test_df['class'].unique())\n",
    "print(f\"Found {n_classes} unique classes in the dataset\")\n",
    "\n",
    "print(f\"\\nStarting SCDC (Same Class Different Color) evaluation:\")\n",
    "print(f\"Configuration: {n_seeds} seeds × {trials_per_class} trials/class × {n_classes} classes\")\n",
    "print(f\"Total trials per class: {n_seeds * trials_per_class}\")\n",
    "print(f\"Expected margin of error: ~3.5% at 95% confidence level\\n\")\n",
    "\n",
    "all_results = {model: defaultdict(list) for model in models_to_test}\n",
    "\n",
    "# Run evaluation\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Testing {model_name} with {n_seeds} seeds\")\n",
    "    print('='*50)\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        print(f\"\\nSeed {seed+1}/{n_seeds} for {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            class_acc = run_scdc_test_per_class(model_name, seed=seed, trials_per_class=trials_per_class)\n",
    "            \n",
    "            # Store results\n",
    "            for cls, acc in class_acc.items():\n",
    "                all_results[model_name][cls].append(acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if len(class_acc) > 0:\n",
    "                mean_acc = np.mean(list(class_acc.values()))\n",
    "                print(f\"  Mean color discrimination accuracy: {mean_acc:.3f}\")\n",
    "                print(f\"  Classes tested: {len(class_acc)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            if \"404\" in str(e) or \"rate\" in str(e).lower():\n",
    "                print(f\"  Rate limit hit - waiting 60 seconds before retry...\")\n",
    "                import time\n",
    "                time.sleep(60)\n",
    "                try:\n",
    "                    class_acc = run_scdc_test_per_class(model_name, seed=seed, trials_per_class=trials_per_class)\n",
    "                    for cls, acc in class_acc.items():\n",
    "                        all_results[model_name][cls].append(acc)\n",
    "                    print(f\"  Retry successful!\")\n",
    "                except:\n",
    "                    print(f\"  Retry failed - skipping this seed\")\n",
    "                    continue\n",
    "        \n",
    "        # Add delay between seeds for CVCL\n",
    "        if 'cvcl' in model_name and seed < n_seeds - 1:\n",
    "            import time\n",
    "            print(\"  Waiting 30 seconds before next seed to avoid rate limiting...\")\n",
    "            time.sleep(30)\n",
    "\n",
    "# Calculate statistics\n",
    "stats_results = {}\n",
    "for model_name in models_to_test:\n",
    "    stats_results[model_name] = {}\n",
    "    for cls, accs in all_results[model_name].items():\n",
    "        if len(accs) > 0:\n",
    "            n_samples = len(accs)\n",
    "            stats_results[model_name][cls] = {\n",
    "                'mean': np.mean(accs),\n",
    "                'std': np.std(accs, ddof=1) if n_samples > 1 else 0,\n",
    "                'se': np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'ci95': 1.96 * np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'n_samples': n_samples,\n",
    "                'total_trials': n_samples * trials_per_class,\n",
    "                'raw': accs\n",
    "            }\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCDC EVALUATION COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Report statistics\n",
    "for model_name in models_to_test:\n",
    "    if len(stats_results[model_name]) > 0:\n",
    "        all_means = [stats['mean'] for stats in stats_results[model_name].values()]\n",
    "        overall_mean = np.mean(all_means)\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  - {len(stats_results[model_name])} classes tested\")\n",
    "        print(f\"  - Overall color discrimination: {overall_mean:.3f}\")\n",
    "        print(f\"  - Expected: CVCL should struggle, CLIP should excel at color\")\n",
    "\n",
    "# Save results\n",
    "detailed_df = []\n",
    "for model_name in models_to_test:\n",
    "    for cls, stats in stats_results[model_name].items():\n",
    "        for seed_idx, acc in enumerate(stats['raw']):\n",
    "            detailed_df.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'seed': seed_idx,\n",
    "                'accuracy': acc,\n",
    "                'n_trials': trials_per_class,\n",
    "                'test_type': 'SCDC'\n",
    "            })\n",
    "\n",
    "if len(detailed_df) > 0:\n",
    "    detailed_df = pd.DataFrame(detailed_df)\n",
    "    detailed_df.to_csv(os.path.join(RESULTS_DIR, 'scdc_perclass_results.csv'), index=False)\n",
    "    print(f\"\\nSaved detailed results to {os.path.join(RESULTS_DIR, 'scdc_perclass_results.csv')}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_stats = []\n",
    "    for model_name in models_to_test:\n",
    "        for cls, stats in stats_results[model_name].items():\n",
    "            summary_stats.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'mean_accuracy': stats['mean'],\n",
    "                'std': stats['std'],\n",
    "                'se': stats['se'],\n",
    "                'ci95': stats['ci95'],\n",
    "                'n_seeds': stats['n_samples'],\n",
    "                'total_trials': stats['total_trials'],\n",
    "                'test_type': 'SCDC'\n",
    "            })\n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    summary_df.to_csv(os.path.join(RESULTS_DIR, 'scdc_perclass_summary.csv'), index=False)\n",
    "    print(f\"Saved summary to {os.path.join(RESULTS_DIR, 'scdc_perclass_summary.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create publication-quality visualization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m11\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create subplots with space for legend in between\u001b[39;00m\n\u001b[0;32m      5\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot2grid((\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), rowspan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Create publication-quality visualization\n",
    "fig = plt.figure(figsize=(14, 11))\n",
    "\n",
    "# Create subplots with space for legend in between\n",
    "ax1 = plt.subplot2grid((20, 1), (0, 0), rowspan=8)\n",
    "ax2 = plt.subplot2grid((20, 1), (12, 0), rowspan=8)\n",
    "\n",
    "# Prepare data\n",
    "classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "mid_point = len(classes) // 2\n",
    "classes_first_half = classes[:mid_point]\n",
    "classes_second_half = classes[mid_point:]\n",
    "\n",
    "# Colors optimized for color discrimination visualization\n",
    "colors = {\n",
    "    'cvcl-resnext': '#8b4513',  # Brown - CVCL expected to struggle with color\n",
    "    'clip-res': '#4169e1'  # Royal blue - CLIP expected to excel at color\n",
    "}\n",
    "markers = {\n",
    "    'cvcl-resnext': 'o',\n",
    "    'clip-res': 's'\n",
    "}\n",
    "avg_line_styles = {\n",
    "    'cvcl-resnext': '--',\n",
    "    'clip-res': '-.'\n",
    "}\n",
    "\n",
    "legend_elements = []\n",
    "\n",
    "def plot_on_axis(ax, class_subset, is_first=False):\n",
    "    x_pos = np.arange(len(class_subset))\n",
    "    \n",
    "    for model_name in models_to_test:\n",
    "        means = [stats_results[model_name][cls]['mean'] * 100 for cls in class_subset]\n",
    "        errors = [stats_results[model_name][cls]['ci95'] * 100 for cls in class_subset]\n",
    "        \n",
    "        ax.errorbar(x_pos, means, yerr=errors, \n",
    "                    label=model_name.upper().replace('-', ' '),\n",
    "                    color=colors[model_name],\n",
    "                    marker=markers[model_name],\n",
    "                    markersize=7,\n",
    "                    linewidth=0,\n",
    "                    capsize=4,\n",
    "                    capthick=1.5,\n",
    "                    alpha=0.9,\n",
    "                    markeredgecolor='black',\n",
    "                    markeredgewidth=0.5)\n",
    "    \n",
    "    # Chance line\n",
    "    ax.axhline(y=25, color='#ffa500', linestyle=':', alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # Calculate overall averages\n",
    "    all_classes_means = {}\n",
    "    for model_name in models_to_test:\n",
    "        all_means = [stats_results[model_name][cls]['mean'] * 100 for cls in classes]\n",
    "        all_classes_means[model_name] = np.mean(all_means)\n",
    "    \n",
    "    # Add average lines\n",
    "    for model_name in models_to_test:\n",
    "        avg_performance = all_classes_means[model_name]\n",
    "        ax.axhline(y=avg_performance, \n",
    "                  color=colors[model_name], \n",
    "                  linestyle=avg_line_styles[model_name], \n",
    "                  alpha=0.7, \n",
    "                  linewidth=2)\n",
    "        \n",
    "        if is_first:\n",
    "            ax.text(len(class_subset) + 0.8, avg_performance, \n",
    "                   f'{avg_performance:.1f}%', \n",
    "                   fontsize=9, \n",
    "                   color=colors[model_name], \n",
    "                   va='center',\n",
    "                   fontweight='bold')\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_ylabel('Color Discrimination Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(class_subset, rotation=45, ha='right', fontsize=10)\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.set_yticks([0, 25, 50, 75, 100])\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    \n",
    "    # Create legend elements (only once)\n",
    "    global legend_elements\n",
    "    if is_first:\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = []\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], marker=markers[model_name], color='w', \n",
    "                      markerfacecolor=colors[model_name], markeredgecolor='black',\n",
    "                      markersize=8, label=model_name.upper().replace('-', ' '))\n",
    "            )\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            avg_val = all_classes_means[model_name]\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color=colors[model_name], \n",
    "                      linestyle=avg_line_styles[model_name], linewidth=2,\n",
    "                      label=f'{model_name.upper().split(\"-\")[0]} Average ({avg_val:.1f}%)')\n",
    "            )\n",
    "        \n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color='#ffa500', linestyle=':', linewidth=1.5,\n",
    "                  label='Chance Level (25%)')\n",
    "        )\n",
    "\n",
    "# Plot both halves\n",
    "plot_on_axis(ax1, classes_first_half, is_first=True)\n",
    "ax1.set_title('SCDC: Color Discrimination Performance - Part 1\\nSame Class, Different Colors (Size & Texture Controlled)', \n",
    "              fontsize=13, fontweight='bold', pad=10)\n",
    "\n",
    "plot_on_axis(ax2, classes_second_half, is_first=False)\n",
    "ax2.set_title('SCDC: Color Discrimination Performance - Part 2', \n",
    "              fontsize=13, fontweight='bold', pad=10)\n",
    "ax2.set_xlabel('Target Category', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Add legend in the middle\n",
    "legend_ax = fig.add_axes([0.125, 0.44, 0.775, 0.08])\n",
    "legend_ax.axis('off')\n",
    "\n",
    "legend = legend_ax.legend(handles=legend_elements, \n",
    "                          loc='center', \n",
    "                          ncol=3,\n",
    "                          fontsize=10,\n",
    "                          frameon=True,\n",
    "                          fancybox=True,\n",
    "                          shadow=True,\n",
    "                          framealpha=0.95,\n",
    "                          columnspacing=2.5,\n",
    "                          handlelength=3)\n",
    "\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_edgecolor('gray')\n",
    "legend.get_frame().set_linewidth(1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'scdc_perclass_comparison.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'scdc_perclass_comparison.pdf'), bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved SCDC plots to:\")\n",
    "print(f\"  - {os.path.join(RESULTS_DIR, 'scdc_perclass_comparison.png')}\")\n",
    "print(f\"  - {os.path.join(RESULTS_DIR, 'scdc_perclass_comparison.pdf')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary and analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCDC COLOR DISCRIMINATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall comparison\n",
    "for model in models_to_test:\n",
    "    all_accs = []\n",
    "    for cls in classes:\n",
    "        if cls in stats_results[model]:\n",
    "            all_accs.extend(stats_results[model][cls]['raw'])\n",
    "    if all_accs:\n",
    "        mean = np.mean(all_accs)\n",
    "        std = np.std(all_accs)\n",
    "        se = std / np.sqrt(len(all_accs))\n",
    "        ci95 = 1.96 * se\n",
    "        print(f\"\\n{model}:\")\n",
    "        print(f\"  Overall: {mean:.3f} ± {ci95:.3f}\")\n",
    "        \n",
    "        if 'cvcl' in model.lower():\n",
    "            print(f\"  Interpretation: CVCL struggles with color discrimination\")\n",
    "        elif 'clip' in model.lower():\n",
    "            print(f\"  Interpretation: CLIP excels at color due to text training\")\n",
    "\n",
    "# Find biggest differences\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"CLASSES WITH LARGEST MODEL DIFFERENCES:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "differences = []\n",
    "for cls in classes:\n",
    "    if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "        diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "        differences.append((cls, diff, \n",
    "                          stats_results['cvcl-resnext'][cls]['mean'],\n",
    "                          stats_results['clip-res'][cls]['mean']))\n",
    "\n",
    "differences.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 classes where CLIP > CVCL (best color discrimination):\")\n",
    "for cls, diff, cvcl_acc, clip_acc in differences[:5]:\n",
    "    if diff > 0:\n",
    "        print(f\"  {cls:20s}: CVCL={cvcl_acc:.1%}, CLIP={clip_acc:.1%}, Diff={diff:+.1%}\")\n",
    "\n",
    "print(\"\\nClasses where CVCL > CLIP (if any):\")\n",
    "cvcl_wins = [d for d in differences if d[1] < 0]\n",
    "if cvcl_wins:\n",
    "    for cls, diff, cvcl_acc, clip_acc in cvcl_wins[:5]:\n",
    "        print(f\"  {cls:20s}: CVCL={cvcl_acc:.1%}, CLIP={clip_acc:.1%}, Diff={diff:+.1%}\")\n",
    "else:\n",
    "    print(\"  None - CLIP dominates color discrimination across all classes\")\n",
    "\n",
    "# Statistical test\n",
    "from scipy import stats as scipy_stats\n",
    "cvcl_all = []\n",
    "clip_all = []\n",
    "for cls in classes:\n",
    "    if cls in stats_results['cvcl-resnext'] and cls in stats_results['clip-res']:\n",
    "        cvcl_all.extend(stats_results['cvcl-resnext'][cls]['raw'])\n",
    "        clip_all.extend(stats_results['clip-res'][cls]['raw'])\n",
    "\n",
    "if cvcl_all and clip_all:\n",
    "    t_stat, p_value = scipy_stats.ttest_ind(clip_all, cvcl_all)\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"Statistical Test (CLIP vs CVCL on color):\")\n",
    "    print(f\"t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"p-value: {p_value:.6f}\")\n",
    "    if p_value < 0.001:\n",
    "        print(\"Result: HIGHLY SIGNIFICANT difference (p < 0.001)\")\n",
    "        print(\"Conclusion: CLIP significantly outperforms CVCL at color discrimination\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
