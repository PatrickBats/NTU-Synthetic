{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Class Different Texture (SCDT) Text-Vision Analysis with Controlled Attributes\n",
    "\n",
    "This notebook tests texture discrimination WITHIN the same class using text-vision alignment.\n",
    "All trials have matched color and size, with only texture varying (smooth vs bumpy).\n",
    "Text encoding uses texture+class format (e.g., \"smooth apple\", \"bumpy apple\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "import time\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = r'C:\\Users\\jbats\\Projects\\NTU-Synthetic'\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "\n",
    "# SyntheticKonkle paths - Using 224x224 resized images\n",
    "DATA_DIR = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle_224')\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'Textvision')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup with proper attribute tracking\n",
    "def build_synthetic_dataset():\n",
    "    \"\"\"Load the master labels CSV with all visual properties.\"\"\"\n",
    "    # Use the master_labels.csv which has all the attribute information\n",
    "    master_csv = os.path.join(DATA_DIR, 'master_labels.csv')\n",
    "    \n",
    "    if not os.path.exists(master_csv):\n",
    "        print(f\"Warning: {master_csv} not found, trying alternative path...\")\n",
    "        # Try the original SyntheticKonkle folder\n",
    "        master_csv = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle', 'master_labels.csv')\n",
    "    \n",
    "    print(f\"Loading master labels from: {master_csv}\")\n",
    "    df = pd.read_csv(master_csv)\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    required_cols = ['folder', 'filename', 'class', 'color', 'size', 'texture']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Clean the data\n",
    "    df = df.dropna(subset=required_cols)\n",
    "    \n",
    "    # Filter to valid textures only\n",
    "    valid_textures = ['smooth', 'bumpy']\n",
    "    df = df[df['texture'].isin(valid_textures)].copy()\n",
    "    \n",
    "    print(f\"Loaded {len(df)} images\")\n",
    "    print(f\"Classes: {df['class'].nunique()} unique\")\n",
    "    print(f\"Colors: {df['color'].nunique()} unique\")\n",
    "    print(f\"Sizes: {df['size'].nunique()} unique\")\n",
    "    print(f\"Textures: {df['texture'].nunique()} unique ({sorted(df['texture'].unique())})\")\n",
    "    \n",
    "    # Check texture distribution within classes\n",
    "    texture_per_class = df.groupby('class')['texture'].nunique()\n",
    "    print(f\"\\nClasses with both textures: {(texture_per_class == 2).sum()}\")\n",
    "    print(f\"Classes with only one texture: {(texture_per_class == 1).sum()}\")\n",
    "    \n",
    "    # Check combinations that have both textures\n",
    "    combo_check = df.groupby(['class', 'color', 'size'])['texture'].nunique()\n",
    "    valid_combos = combo_check[combo_check == 2].index.tolist()\n",
    "    print(f\"Class-color-size combinations with both textures: {len(valid_combos)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "class SyntheticImageDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform):\n",
    "        self.df = df\n",
    "        # For SyntheticKonkle_224, images are in nested structure\n",
    "        self.data_dir = os.path.join(data_dir, 'SyntheticKonkle')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row['folder'], row['filename'])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "        except Exception as e:\n",
    "            # Return a black image if file not found\n",
    "            img = Image.new('RGB', (224, 224), color='black')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    colors = [b[2] for b in batch]\n",
    "    sizes = [b[3] for b in batch]\n",
    "    textures = [b[4] for b in batch]\n",
    "    idxs = [b[5] for b in batch]\n",
    "    return imgs, classes, colors, sizes, textures, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scdt_text_vision_test_per_class(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', \n",
    "                                        batch_size=32, trials_per_class=500):\n",
    "    \"\"\"\n",
    "    Run Same Class Different Texture text-vision test with controlled color and size.\n",
    "    Returns per-class accuracy results.\n",
    "    \n",
    "    Note: Since there are only 2 textures (smooth, bumpy), for 4-way choice we use:\n",
    "    - 2 images with smooth texture\n",
    "    - 2 images with bumpy texture\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Check if model supports text encoding\n",
    "    if model_name in ['resnext', 'dino_s_resnext50']:\n",
    "        print(f\"[WARNING] {model_name} has no text encoder, skipping\")\n",
    "        return {}\n",
    "\n",
    "    # Load model & transform\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    \n",
    "    # Build dataset and extract image embeddings\n",
    "    df = build_synthetic_dataset()\n",
    "    ds = SyntheticImageDataset(df, DATA_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    print(\"Extracting image embeddings...\")\n",
    "    all_img_embs, all_classes, all_colors, all_sizes, all_textures, all_idxs = [], [], [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, colors, sizes, textures, idxs in tqdm(loader, desc=\"Processing images\"):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = extractor.get_img_feature(imgs)\n",
    "            feats = extractor.norm_features(feats).cpu().float()\n",
    "            all_img_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_colors.extend(colors)\n",
    "            all_sizes.extend(sizes)\n",
    "            all_textures.extend(textures)\n",
    "            all_idxs.extend(idxs)\n",
    "    \n",
    "    all_img_embs = torch.cat(all_img_embs, dim=0)\n",
    "    print(f\"Extracted {len(all_img_embs)} image embeddings\")\n",
    "\n",
    "    # Group images by class, color, size, and texture\n",
    "    # For SCDT: class, color, size are fixed; texture varies\n",
    "    class_color_size_texture_idxs = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    idx_to_row = {idx: i for i, idx in enumerate(all_idxs)}\n",
    "    \n",
    "    for i, (idx, cls, col, size, texture) in enumerate(zip(all_idxs, all_classes, all_colors, all_sizes, all_textures)):\n",
    "        class_color_size_texture_idxs[cls][(col, size)][texture].append(idx)\n",
    "\n",
    "    # Get unique classes and textures\n",
    "    unique_classes = list(set(all_classes))\n",
    "    valid_textures = ['smooth', 'bumpy']\n",
    "    \n",
    "    print(f\"Found {len(unique_classes)} classes\")\n",
    "    \n",
    "    # Pre-encode all texture+class text combinations\n",
    "    print(\"Encoding text labels for all texture-class combinations...\")\n",
    "    text_features_cache = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Create all texture+class combinations\n",
    "        text_labels = []\n",
    "        label_keys = []\n",
    "        for cls in unique_classes:\n",
    "            for texture in valid_textures:\n",
    "                # Format: \"smooth apple\", \"bumpy apple\", etc.\n",
    "                label = f\"{texture} {cls}\"\n",
    "                text_labels.append(label)\n",
    "                label_keys.append((cls, texture))\n",
    "        \n",
    "        # Encode in batches for efficiency\n",
    "        if \"clip\" in model_name:\n",
    "            # CLIP text encoding\n",
    "            tokens = clip.tokenize(text_labels, truncate=True).to(device)\n",
    "            txt_features = model.encode_text(tokens)\n",
    "            txt_features = extractor.norm_features(txt_features).cpu().float()\n",
    "            for i, (cls, texture) in enumerate(label_keys):\n",
    "                text_features_cache[(cls, texture)] = txt_features[i]\n",
    "        else:  # CVCL\n",
    "            # CVCL text encoding with token length\n",
    "            tokens, token_len = model.tokenize(text_labels)\n",
    "            tokens = tokens.to(device)\n",
    "            if isinstance(token_len, torch.Tensor):\n",
    "                token_len = token_len.to(device)\n",
    "            txt_features = model.encode_text(tokens, token_len)\n",
    "            txt_features = extractor.norm_features(txt_features).cpu().float()\n",
    "            for i, (cls, texture) in enumerate(label_keys):\n",
    "                text_features_cache[(cls, texture)] = txt_features[i]\n",
    "    \n",
    "    print(f\"Encoded {len(text_features_cache)} texture-class text combinations\")\n",
    "\n",
    "    # Track per-class performance\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    print(f\"Running {trials_per_class} trials per class for SCDT task...\")\n",
    "    \n",
    "    # Run trials for each class\n",
    "    for target_class in tqdm(unique_classes, desc=f\"Testing {model_name} SCDT\"):\n",
    "        trials_done = 0\n",
    "        \n",
    "        # For each color-size combination in this class\n",
    "        for (color, size), texture_dict in class_color_size_texture_idxs[target_class].items():\n",
    "            if trials_done >= trials_per_class:\n",
    "                break\n",
    "            \n",
    "            # Need both textures for this class-color-size combination\n",
    "            if 'smooth' not in texture_dict or 'bumpy' not in texture_dict:\n",
    "                continue\n",
    "            \n",
    "            # Need at least 2 images per texture for 4-way choice (2 smooth + 2 bumpy)\n",
    "            if len(texture_dict['smooth']) < 2 or len(texture_dict['bumpy']) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Run multiple trials for this combination\n",
    "            n_trials = min(20, trials_per_class - trials_done)\n",
    "            \n",
    "            for _ in range(n_trials):\n",
    "                # For SCDT with only 2 textures, we create 4 candidates:\n",
    "                # 2 smooth images + 2 bumpy images\n",
    "                \n",
    "                candidates = []\n",
    "                candidate_textures = []\n",
    "                \n",
    "                # Select 2 smooth images\n",
    "                smooth_imgs = random.sample(texture_dict['smooth'], \n",
    "                                          min(2, len(texture_dict['smooth'])))\n",
    "                for img_idx in smooth_imgs:\n",
    "                    candidates.append(img_idx)\n",
    "                    candidate_textures.append('smooth')\n",
    "                \n",
    "                # Select 2 bumpy images\n",
    "                bumpy_imgs = random.sample(texture_dict['bumpy'], \n",
    "                                         min(2, len(texture_dict['bumpy'])))\n",
    "                for img_idx in bumpy_imgs:\n",
    "                    candidates.append(img_idx)\n",
    "                    candidate_textures.append('bumpy')\n",
    "                \n",
    "                if len(candidates) != 4:\n",
    "                    continue\n",
    "                \n",
    "                # Randomly select target from the 4 candidates\n",
    "                target_position = random.randint(0, 3)\n",
    "                target_idx = candidates[target_position]\n",
    "                target_texture = candidate_textures[target_position]\n",
    "                \n",
    "                # Shuffle candidates for presentation\n",
    "                indices = list(range(4))\n",
    "                random.shuffle(indices)\n",
    "                shuffled_candidates = [candidates[i] for i in indices]\n",
    "                shuffled_textures = [candidate_textures[i] for i in indices]\n",
    "                \n",
    "                # Find where target ended up after shuffle\n",
    "                correct_position = indices.index(target_position)\n",
    "                \n",
    "                # Get image features for all candidates\n",
    "                cand_features = torch.stack([all_img_embs[idx_to_row[idx]] \n",
    "                                            for idx in shuffled_candidates]).float()\n",
    "                \n",
    "                # Get text feature for target texture+class\n",
    "                target_text_feature = text_features_cache[(target_class, target_texture)].float()\n",
    "                \n",
    "                # Compute similarity with text encoding\n",
    "                similarities = cand_features @ target_text_feature\n",
    "                \n",
    "                # Check if model correctly identifies target\n",
    "                prediction = similarities.argmax().item()\n",
    "                \n",
    "                # Update counts\n",
    "                class_correct[target_class] += int(prediction == correct_position)\n",
    "                class_total[target_class] += 1\n",
    "                trials_done += 1\n",
    "                \n",
    "                if trials_done >= trials_per_class:\n",
    "                    break\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracies = {}\n",
    "    for cls in unique_classes:\n",
    "        if class_total[cls] > 0:\n",
    "            class_accuracies[cls] = class_correct[cls] / class_total[cls]\n",
    "        else:\n",
    "            class_accuracies[cls] = 0.0\n",
    "    \n",
    "    # Print summary\n",
    "    overall_correct = sum(class_correct.values())\n",
    "    overall_total = sum(class_total.values())\n",
    "    overall_acc = overall_correct / overall_total if overall_total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nSCDT Overall: {overall_correct}/{overall_total} = {overall_acc:.3f}\")\n",
    "    print(f\"Classes tested: {len([c for c in class_accuracies if class_total[c] > 0])}\")\n",
    "    \n",
    "    # Show top and bottom performers\n",
    "    sorted_classes = sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop 5 classes for texture discrimination:\")\n",
    "    for cls, acc in sorted_classes[:5]:\n",
    "        if class_total[cls] > 0:\n",
    "            print(f\"  {cls}: {acc:.3f} ({class_total[cls]} trials)\")\n",
    "    print(\"\\nBottom 5 classes for texture discrimination:\")\n",
    "    for cls, acc in sorted_classes[-5:]:\n",
    "        if class_total[cls] > 0:\n",
    "            print(f\"  {cls}: {acc:.3f} ({class_total[cls]} trials)\")\n",
    "    \n",
    "    return class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple seeds for statistical analysis\n",
    "n_seeds = 3  # Limited seeds due to potential rate limiting\n",
    "trials_per_class = 500  # Consistent with other tests\n",
    "models_to_test = ['cvcl-resnext', 'clip-res']\n",
    "\n",
    "# Check dataset first\n",
    "test_df = build_synthetic_dataset()\n",
    "n_classes = len(test_df['class'].unique())\n",
    "n_textures = len(test_df['texture'].unique())\n",
    "print(f\"Found {n_classes} unique classes and {n_textures} unique textures\")\n",
    "\n",
    "print(f\"\\nStarting SCDT Text-Vision evaluation:\")\n",
    "print(f\"Configuration: {n_seeds} seeds × {trials_per_class} trials/class × {n_classes} classes\")\n",
    "print(f\"Task: Same Class Different Texture discrimination\")\n",
    "print(f\"Control: Color and size are held constant within each trial\")\n",
    "print(f\"Text format: texture + class (e.g., 'smooth apple', 'bumpy apple')\")\n",
    "print(f\"Note: With only 2 textures, each trial has 2 smooth + 2 bumpy images\\n\")\n",
    "\n",
    "all_results = {model: defaultdict(list) for model in models_to_test}\n",
    "\n",
    "# Run evaluation\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_name} with SCDT text-vision approach\")\n",
    "    print('='*60)\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        print(f\"\\nSeed {seed+1}/{n_seeds} for {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            class_acc = run_scdt_text_vision_test_per_class(\n",
    "                model_name, \n",
    "                seed=seed, \n",
    "                trials_per_class=trials_per_class\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            for cls, acc in class_acc.items():\n",
    "                all_results[model_name][cls].append(acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if len(class_acc) > 0:\n",
    "                mean_acc = np.mean(list(class_acc.values()))\n",
    "                print(f\"  Mean accuracy across classes: {mean_acc:.3f}\")\n",
    "                print(f\"  Classes successfully tested: {len(class_acc)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            if \"404\" in str(e) or \"rate\" in str(e).lower():\n",
    "                print(f\"  Rate limit hit - waiting 60 seconds...\")\n",
    "                time.sleep(60)\n",
    "                # Retry once\n",
    "                try:\n",
    "                    class_acc = run_scdt_text_vision_test_per_class(\n",
    "                        model_name, seed=seed, trials_per_class=trials_per_class\n",
    "                    )\n",
    "                    for cls, acc in class_acc.items():\n",
    "                        all_results[model_name][cls].append(acc)\n",
    "                    print(f\"  Retry successful!\")\n",
    "                except:\n",
    "                    print(f\"  Retry failed - skipping seed {seed}\")\n",
    "                    continue\n",
    "        \n",
    "        # Add delay between seeds for CVCL\n",
    "        if 'cvcl' in model_name and seed < n_seeds - 1:\n",
    "            print(\"  Waiting 30 seconds before next seed...\")\n",
    "            time.sleep(30)\n",
    "\n",
    "# Calculate statistics\n",
    "stats_results = {}\n",
    "for model_name in models_to_test:\n",
    "    stats_results[model_name] = {}\n",
    "    for cls, accs in all_results[model_name].items():\n",
    "        if len(accs) > 0:\n",
    "            n_samples = len(accs)\n",
    "            stats_results[model_name][cls] = {\n",
    "                'mean': np.mean(accs),\n",
    "                'std': np.std(accs, ddof=1) if n_samples > 1 else 0,\n",
    "                'se': np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'ci95': 1.96 * np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'n_samples': n_samples,\n",
    "                'total_trials': n_samples * trials_per_class,\n",
    "                'raw': accs\n",
    "            }\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCDT TEXT-VISION EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results\n",
    "detailed_df = []\n",
    "for model_name in models_to_test:\n",
    "    for cls, stats in stats_results[model_name].items():\n",
    "        for seed_idx, acc in enumerate(stats['raw']):\n",
    "            detailed_df.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'seed': seed_idx,\n",
    "                'accuracy': acc,\n",
    "                'n_trials': trials_per_class,\n",
    "                'test_type': 'scdt_text_vision'\n",
    "            })\n",
    "\n",
    "if len(detailed_df) > 0:\n",
    "    detailed_df = pd.DataFrame(detailed_df)\n",
    "    output_path = os.path.join(RESULTS_DIR, 'scdt_textvision_perclass_results.csv')\n",
    "    detailed_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSaved detailed results to {output_path}\")\n",
    "    \n",
    "    # Save summary statistics\n",
    "    summary_stats = []\n",
    "    for model_name in models_to_test:\n",
    "        for cls, stats in stats_results[model_name].items():\n",
    "            summary_stats.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'mean_accuracy': stats['mean'],\n",
    "                'std': stats['std'],\n",
    "                'se': stats['se'],\n",
    "                'ci95': stats['ci95'],\n",
    "                'n_seeds': stats['n_samples'],\n",
    "                'total_trials': stats['total_trials']\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    summary_path = os.path.join(RESULTS_DIR, 'scdt_textvision_perclass_summary.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"Saved summary statistics to {summary_path}\")\n",
    "else:\n",
    "    print(\"\\nNo results to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "if len(stats_results[models_to_test[0]]) > 0:\n",
    "    fig = plt.figure(figsize=(14, 11))\n",
    "    \n",
    "    # Create subplots\n",
    "    ax1 = plt.subplot2grid((20, 1), (0, 0), rowspan=8)\n",
    "    ax2 = plt.subplot2grid((20, 1), (12, 0), rowspan=8)\n",
    "    \n",
    "    # Prepare data\n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    mid_point = len(classes) // 2\n",
    "    classes_first_half = classes[:mid_point]\n",
    "    classes_second_half = classes[mid_point:]\n",
    "    \n",
    "    # Define colors and markers\n",
    "    colors = {\n",
    "        'cvcl-resnext': '#2a9d8f',  # Teal for CVCL\n",
    "        'clip-res': '#e63946'  # Red for CLIP\n",
    "    }\n",
    "    markers = {\n",
    "        'cvcl-resnext': 'o',\n",
    "        'clip-res': 's'\n",
    "    }\n",
    "    avg_line_styles = {\n",
    "        'cvcl-resnext': '--',\n",
    "        'clip-res': '-.'\n",
    "    }\n",
    "    \n",
    "    legend_elements = []\n",
    "    \n",
    "    def plot_on_axis(ax, class_subset, is_first=False):\n",
    "        x_pos = np.arange(len(class_subset))\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            means = [stats_results[model_name][cls]['mean'] * 100 for cls in class_subset]\n",
    "            errors = [stats_results[model_name][cls]['ci95'] * 100 for cls in class_subset]\n",
    "            \n",
    "            ax.errorbar(x_pos, means, yerr=errors,\n",
    "                       label=model_name.upper().replace('-', ' '),\n",
    "                       color=colors[model_name],\n",
    "                       marker=markers[model_name],\n",
    "                       markersize=7,\n",
    "                       linewidth=0,\n",
    "                       capsize=4,\n",
    "                       capthick=1.5,\n",
    "                       alpha=0.9,\n",
    "                       markeredgecolor='black',\n",
    "                       markeredgewidth=0.5)\n",
    "        \n",
    "        # Add chance level (50% for binary texture choice)\n",
    "        ax.axhline(y=50, color='#ffa500', linestyle=':', alpha=0.8, linewidth=1.5)\n",
    "        \n",
    "        # Calculate overall averages\n",
    "        all_classes_means = {}\n",
    "        for model_name in models_to_test:\n",
    "            all_means = [stats_results[model_name][cls]['mean'] * 100 for cls in classes]\n",
    "            all_classes_means[model_name] = np.mean(all_means)\n",
    "        \n",
    "        # Add average lines\n",
    "        for model_name in models_to_test:\n",
    "            avg_performance = all_classes_means[model_name]\n",
    "            ax.axhline(y=avg_performance,\n",
    "                      color=colors[model_name],\n",
    "                      linestyle=avg_line_styles[model_name],\n",
    "                      alpha=0.7,\n",
    "                      linewidth=2)\n",
    "            \n",
    "            if is_first:\n",
    "                ax.text(len(class_subset) + 0.8, avg_performance,\n",
    "                       f'{avg_performance:.1f}%',\n",
    "                       fontsize=9,\n",
    "                       color=colors[model_name],\n",
    "                       va='center',\n",
    "                       fontweight='bold')\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_ylabel('SCDT Text-Vision Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(class_subset, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_ylim(0, 105)\n",
    "        ax.set_yticks([0, 25, 50, 75, 100])\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_facecolor('#fafafa')\n",
    "        \n",
    "        # Create legend elements\n",
    "        global legend_elements\n",
    "        if is_first:\n",
    "            from matplotlib.lines import Line2D\n",
    "            legend_elements = []\n",
    "            \n",
    "            for model_name in models_to_test:\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], marker=markers[model_name], color='w',\n",
    "                          markerfacecolor=colors[model_name], markeredgecolor='black',\n",
    "                          markersize=8, label=model_name.upper().replace('-', ' '))\n",
    "                )\n",
    "            \n",
    "            for model_name in models_to_test:\n",
    "                avg_val = all_classes_means[model_name]\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color=colors[model_name],\n",
    "                          linestyle=avg_line_styles[model_name], linewidth=2,\n",
    "                          label=f'{model_name.upper().split(\"-\")[0]} Average ({avg_val:.1f}%)')\n",
    "                )\n",
    "            \n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color='#ffa500', linestyle=':', linewidth=1.5,\n",
    "                      label='Chance Level (50%)')  # Note: 50% for binary texture\n",
    "            )\n",
    "    \n",
    "    # Plot both halves\n",
    "    plot_on_axis(ax1, classes_first_half, is_first=True)\n",
    "    ax1.set_title('SCDT Text-Vision Per-Class Performance - Part 1\\nSame Class Different Texture (Color & Size Controlled)',\n",
    "                 fontsize=13, fontweight='bold', pad=10)\n",
    "    \n",
    "    plot_on_axis(ax2, classes_second_half, is_first=False)\n",
    "    ax2.set_title('SCDT Text-Vision Per-Class Performance - Part 2',\n",
    "                 fontsize=13, fontweight='bold', pad=10)\n",
    "    ax2.set_xlabel('Target Category', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_ax = fig.add_axes([0.125, 0.44, 0.775, 0.08])\n",
    "    legend_ax.axis('off')\n",
    "    \n",
    "    legend = legend_ax.legend(handles=legend_elements,\n",
    "                             loc='center',\n",
    "                             ncol=3,\n",
    "                             fontsize=10,\n",
    "                             frameon=True,\n",
    "                             fancybox=True,\n",
    "                             shadow=True,\n",
    "                             framealpha=0.95,\n",
    "                             columnspacing=2.5,\n",
    "                             handlelength=3)\n",
    "    \n",
    "    legend.get_frame().set_facecolor('white')\n",
    "    legend.get_frame().set_edgecolor('gray')\n",
    "    legend.get_frame().set_linewidth(1.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    \n",
    "    # Save plots\n",
    "    png_path = os.path.join(RESULTS_DIR, 'scdt_textvision_perclass.png')\n",
    "    pdf_path = os.path.join(RESULTS_DIR, 'scdt_textvision_perclass.pdf')\n",
    "    \n",
    "    plt.savefig(png_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(pdf_path, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved plots to:\")\n",
    "    print(f\"  - {png_path}\")\n",
    "    print(f\"  - {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "if len(stats_results) > 0 and len(stats_results[models_to_test[0]]) > 0:\n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    \n",
    "    summary_data = []\n",
    "    for cls in classes:\n",
    "        row = {'Class': cls}\n",
    "        for model in models_to_test:\n",
    "            if cls in stats_results[model]:\n",
    "                stats = stats_results[model][cls]\n",
    "                row[f\"{model}_mean\"] = f\"{stats['mean']:.3f}\"\n",
    "                row[f\"{model}_ci95\"] = f\"±{stats['ci95']:.3f}\"\n",
    "                row[f\"{model}_trials\"] = stats['total_trials']\n",
    "        \n",
    "        # Add difference if both models have results\n",
    "        if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "            diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "            row['difference'] = f\"{diff:+.3f}\"\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SCDT TEXT-VISION PER-CLASS PERFORMANCE SUMMARY\")\n",
    "    print(\"Task: Same Class Different Texture (Color & Size Controlled)\")\n",
    "    print(\"Note: Only 2 textures (smooth vs bumpy), so binary discrimination\")\n",
    "    print(\"=\"*80)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL SCDT TEXT-VISION PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for model in models_to_test:\n",
    "        all_accs = []\n",
    "        for cls in classes:\n",
    "            if cls in stats_results[model]:\n",
    "                all_accs.extend(stats_results[model][cls]['raw'])\n",
    "        \n",
    "        if len(all_accs) > 0:\n",
    "            mean = np.mean(all_accs)\n",
    "            std = np.std(all_accs)\n",
    "            se = std / np.sqrt(len(all_accs))\n",
    "            ci95 = 1.96 * se\n",
    "            print(f\"{model}: {mean:.3f} ± {ci95:.3f} (SE: {se:.3f}, n={len(all_accs)} samples)\")\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats as scipy_stats\n",
    "    \n",
    "    cvcl_all = []\n",
    "    clip_all = []\n",
    "    for cls in classes:\n",
    "        if cls in stats_results['cvcl-resnext']:\n",
    "            cvcl_all.extend(stats_results['cvcl-resnext'][cls]['raw'])\n",
    "        if cls in stats_results['clip-res']:\n",
    "            clip_all.extend(stats_results['clip-res'][cls]['raw'])\n",
    "    \n",
    "    if len(cvcl_all) > 0 and len(clip_all) > 0:\n",
    "        t_stat, p_value = scipy_stats.ttest_ind(cvcl_all, clip_all)\n",
    "        print(f\"\\nt-test: t={t_stat:.3f}, p={p_value:.6f}\")\n",
    "        if p_value < 0.001:\n",
    "            print(\"Result: Highly significant difference (p < 0.001)\")\n",
    "        elif p_value < 0.01:\n",
    "            print(\"Result: Significant difference (p < 0.01)\")\n",
    "        elif p_value < 0.05:\n",
    "            print(\"Result: Significant difference (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"Result: No significant difference\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"This test measures texture discrimination (smooth vs bumpy) within the same object class.\")\n",
    "    print(\"Color and size are held constant, so performance reflects pure texture understanding.\")\n",
    "    print(\"Note: With only 2 textures, this is essentially a binary discrimination task.\")\n",
    "    print(\"Chance level is 50% (not 25%) due to the binary nature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison across all property tests if CSVs exist\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON ACROSS ALL PROPERTY DISCRIMINATION TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_types = [\n",
    "    ('Class', 'class_textvision_perclass_summary.csv'),\n",
    "    ('Color (SCDC)', 'scdc_textvision_perclass_summary.csv'),\n",
    "    ('Size (SCDS)', 'scds_textvision_perclass_summary.csv'),\n",
    "    ('Texture (SCDT)', 'scdt_textvision_perclass_summary.csv')\n",
    "]\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for test_name, csv_file in test_types:\n",
    "    csv_path = os.path.join(RESULTS_DIR, csv_file)\n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        for model in models_to_test:\n",
    "            model_data = df[df['model'] == model]\n",
    "            if len(model_data) > 0:\n",
    "                mean_acc = model_data['mean_accuracy'].mean()\n",
    "                if model not in comparison_results:\n",
    "                    comparison_results[model] = {}\n",
    "                comparison_results[model][test_name] = mean_acc * 100\n",
    "\n",
    "if comparison_results:\n",
    "    # Create comparison plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    test_names = [name for name, _ in test_types if any(name in model_res for model_res in comparison_results.values())]\n",
    "    x = np.arange(len(test_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, model in enumerate(models_to_test):\n",
    "        if model in comparison_results:\n",
    "            values = [comparison_results[model].get(test, 0) for test in test_names]\n",
    "            offset = width * (i - 0.5)\n",
    "            bars = ax.bar(x + offset, values, width, \n",
    "                         label=model.upper().replace('-', ' '),\n",
    "                         color=colors[model], alpha=0.8)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for j, bar in enumerate(bars):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                       f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Test Type', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Text-Vision Performance Across Different Property Discrimination Tests',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(test_names)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add horizontal lines for reference\n",
    "    ax.axhline(y=25, color='orange', linestyle='--', alpha=0.5, label='4-way chance')\n",
    "    ax.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='Binary chance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    comparison_plot_path = os.path.join(RESULTS_DIR, 'all_properties_textvision_comparison.png')\n",
    "    plt.savefig(comparison_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved comparison plot to {comparison_plot_path}\")\n",
    "    \n",
    "    # Print summary table\n",
    "    print(\"\\nPerformance Summary (%):\\n\")\n",
    "    print(f\"{'Test Type':<15} {'CVCL':>10} {'CLIP':>10} {'Difference':>12}\")\n",
    "    print(\"-\" * 50)\n",
    "    for test in test_names:\n",
    "        cvcl_val = comparison_results.get('cvcl-resnext', {}).get(test, 0)\n",
    "        clip_val = comparison_results.get('clip-res', {}).get(test, 0)\n",
    "        diff = clip_val - cvcl_val\n",
    "        print(f\"{test:<15} {cvcl_val:>10.1f} {clip_val:>10.1f} {diff:>+12.1f}\")\n",
    "    \n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(\"- Class discrimination: Easiest task (different objects)\")\n",
    "    print(\"- Color discrimination: Visual property within same class\")\n",
    "    print(\"- Size discrimination: Often harder due to relative nature\")\n",
    "    print(\"- Texture discrimination: Binary (smooth vs bumpy), 50% chance level\")\n",
    "else:\n",
    "    print(\"\\nNo comparison data available. Run other tests to compare.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}