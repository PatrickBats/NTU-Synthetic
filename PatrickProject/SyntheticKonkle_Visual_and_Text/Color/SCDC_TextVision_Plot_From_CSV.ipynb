{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot SCDC Text-Vision Per-Class Results from Saved CSV\n",
    "\n",
    "This notebook loads previously saved Same Class Different Color (SCDC) text-vision results and creates publication-quality plots.\n",
    "Results are from experiments with controlled size and texture, testing color discrimination within same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = r'C:\\Users\\jbats\\Projects\\NTU-Synthetic'\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'Textvision')\n",
    "\n",
    "# Load the SCDC summary CSV\n",
    "summary_file = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass_summary.csv')\n",
    "if os.path.exists(summary_file):\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    print(f\"Loaded SCDC data from {summary_file}\")\n",
    "    print(f\"Shape: {summary_df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(summary_df.head())\n",
    "    print(f\"\\nModels in data: {summary_df['model'].unique()}\")\n",
    "    print(f\"Number of unique classes: {summary_df['class'].nunique()}\")\n",
    "else:\n",
    "    print(f\"File not found: {summary_file}\")\n",
    "    print(\"Please run the SCDC text-vision experiment first to generate the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct stats_results from CSV\n",
    "stats_results = {}\n",
    "models = summary_df['model'].unique()\n",
    "\n",
    "for model in models:\n",
    "    stats_results[model] = {}\n",
    "    model_data = summary_df[summary_df['model'] == model]\n",
    "    \n",
    "    for _, row in model_data.iterrows():\n",
    "        stats_results[model][row['class']] = {\n",
    "            'mean': row['mean_accuracy'],\n",
    "            'std': row['std'] if 'std' in row else 0,\n",
    "            'se': row['se'] if 'se' in row else 0,\n",
    "            'ci95': row['ci95'] if 'ci95' in row else 0,\n",
    "            'n_samples': row['n_seeds'] if 'n_seeds' in row else 1,\n",
    "            'total_trials': row['total_trials'] if 'total_trials' in row else 500\n",
    "        }\n",
    "\n",
    "models_to_test = list(models)\n",
    "print(f\"Models found: {models_to_test}\")\n",
    "print(f\"Number of classes: {len(stats_results[models_to_test[0]])}\")\n",
    "\n",
    "# Calculate overall means for display\n",
    "for model in models_to_test:\n",
    "    all_means = [stats['mean'] * 100 for stats in stats_results[model].values()]\n",
    "    print(f\"\\n{model} SCDC overall mean: {np.mean(all_means):.1f}%\")\n",
    "    print(f\"  (Color discrimination within same class)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-quality visualization with two subplots\n",
    "fig = plt.figure(figsize=(14, 11))\n",
    "\n",
    "# Create subplots with space for legend in between\n",
    "ax1 = plt.subplot2grid((20, 1), (0, 0), rowspan=8)\n",
    "ax2 = plt.subplot2grid((20, 1), (12, 0), rowspan=8)\n",
    "\n",
    "# Prepare data for plotting\n",
    "classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "\n",
    "# Split classes into two groups\n",
    "mid_point = len(classes) // 2\n",
    "classes_first_half = classes[:mid_point]\n",
    "classes_second_half = classes[mid_point:]\n",
    "\n",
    "# Define colors and styles\n",
    "colors = {\n",
    "    'cvcl-resnext': '#2a9d8f',  # Teal/green color for CVCL\n",
    "    'clip-res': '#e63946'  # Red color for CLIP\n",
    "}\n",
    "markers = {\n",
    "    'cvcl-resnext': 'o',\n",
    "    'clip-res': 's'  # Square for CLIP\n",
    "}\n",
    "avg_line_styles = {\n",
    "    'cvcl-resnext': '--',\n",
    "    'clip-res': '-.'\n",
    "}\n",
    "\n",
    "# Short display labels for the legend\n",
    "short_labels = {\n",
    "    'cvcl-resnext': 'CVCL',\n",
    "    'clip-res': 'CLIP'\n",
    "}\n",
    "\n",
    "# Store legend elements globally\n",
    "legend_elements = []\n",
    "\n",
    "# Function to plot data on an axis\n",
    "def plot_on_axis(ax, class_subset, is_first=False):\n",
    "    x_pos = np.arange(len(class_subset))\n",
    "    \n",
    "    # Plot each model\n",
    "    for model_name in models_to_test:\n",
    "        means = [stats_results[model_name][cls]['mean'] * 100 for cls in class_subset]\n",
    "        errors = [stats_results[model_name][cls]['ci95'] * 100 for cls in class_subset]\n",
    "        \n",
    "        ax.errorbar(x_pos, means, yerr=errors, \n",
    "                    label=None,\n",
    "                    color=colors[model_name],\n",
    "                    marker=markers[model_name],\n",
    "                    markersize=7,\n",
    "                    linewidth=0,\n",
    "                    capsize=4,\n",
    "                    capthick=1.5,\n",
    "                    alpha=0.9,\n",
    "                    markeredgecolor='black',\n",
    "                    markeredgewidth=0.5)\n",
    "    \n",
    "    # Add chance line\n",
    "    ax.axhline(y=25, color='#ffa500', linestyle=':', alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # Calculate and add average lines\n",
    "    all_classes_means = {}\n",
    "    for model_name in models_to_test:\n",
    "        all_means = [stats_results[model_name][cls]['mean'] * 100 for cls in classes]\n",
    "        all_classes_means[model_name] = np.mean(all_means)\n",
    "    \n",
    "    for model_name in models_to_test:\n",
    "        avg_performance = all_classes_means[model_name]\n",
    "        ax.axhline(y=avg_performance, \n",
    "                  color=colors[model_name], \n",
    "                  linestyle=avg_line_styles[model_name], \n",
    "                  alpha=0.7, \n",
    "                  linewidth=2)\n",
    "        \n",
    "        if is_first:\n",
    "            ax.text(len(class_subset) + 0.8, avg_performance, \n",
    "                   f'{avg_performance:.1f}%', \n",
    "                   fontsize=9, \n",
    "                   color=colors[model_name], \n",
    "                   va='center',\n",
    "                   fontweight='bold')\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_ylabel('SCDC Text-Vision Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(class_subset, rotation=45, ha='right', fontsize=10)\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.set_yticks([0, 25, 50, 75, 100])\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    \n",
    "    # Create legend elements (only once)\n",
    "    global legend_elements\n",
    "    if is_first:\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = []\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], marker=markers[model_name], color='w', \n",
    "                      markerfacecolor=colors[model_name], markeredgecolor='black',\n",
    "                      markersize=8, label=short_labels[model_name])\n",
    "            )\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            avg_val = all_classes_means[model_name]\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color=colors[model_name], \n",
    "                      linestyle=avg_line_styles[model_name], linewidth=2,\n",
    "                      label=f'{model_name.upper().split(\"-\")[0]} Average ({avg_val:.1f}%)')\n",
    "            )\n",
    "        \n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color='#ffa500', linestyle=':', linewidth=1.5,\n",
    "                  label='Chance Level (25%)')\n",
    "        )\n",
    "\n",
    "# Plot both halves\n",
    "plot_on_axis(ax1, classes_first_half, is_first=True)\n",
    "ax1.set_title('SCDC Text-Vision Per-Class Performance\\n(Same Class Different Color - Size & Texture Controlled)', \n",
    "              fontsize=13, fontweight='bold', pad=10)\n",
    "\n",
    "plot_on_axis(ax2, classes_second_half, is_first=False)\n",
    "ax2.set_xlabel('Target Category', fontsize=11, fontweight='bold')\n",
    "\n",
    "# --- Legend centered between subplots ---\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.35)  # spacing between the two axes\n",
    "\n",
    "legend = fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc='center',\n",
    "    bbox_to_anchor=(0.5, 0.47),   # centered between plots\n",
    "    ncol=3,\n",
    "    fontsize=9,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    framealpha=0.95,\n",
    "    borderpad=0.3,\n",
    "    labelspacing=0.4,\n",
    "    handlelength=2.2,\n",
    "    columnspacing=1.6\n",
    ")\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_edgecolor('gray')\n",
    "legend.get_frame().set_linewidth(1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "# Save plots to Textvision folder\n",
    "png_path = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass_from_csv.png')\n",
    "pdf_path = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass_from_csv.pdf')\n",
    "\n",
    "plt.savefig(png_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.savefig(pdf_path, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved SCDC text-vision plots from CSV data to:\")\n",
    "print(f\"  - {png_path}\")\n",
    "print(f\"  - {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create difference plot (CLIP - CVCL)\n",
    "if 'cvcl-resnext' in models_to_test and 'clip-res' in models_to_test:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    differences = []\n",
    "    for cls in classes:\n",
    "        diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "        differences.append(diff)\n",
    "    \n",
    "    # Color based on which model is better\n",
    "    colors_diff = ['#2ecc71' if d > 0 else '#e74c3c' for d in differences]\n",
    "    \n",
    "    bars = plt.bar(range(len(classes)), differences, color=colors_diff, alpha=0.7, \n",
    "                   edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (cls, diff) in enumerate(zip(classes, differences)):\n",
    "        plt.text(i, diff + (0.01 if diff > 0 else -0.02), f'{diff:.2f}',\n",
    "                ha='center', va='bottom' if diff > 0 else 'top', fontsize=7)\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    plt.xlabel('Object Class', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Performance Difference\\n(CLIP - CVCL)', fontsize=12, fontweight='bold')\n",
    "    plt.title('SCDC Text-Vision Model Performance Differences\\n(Color Discrimination Within Same Class)',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(classes)), classes, rotation=45, ha='right', fontsize=9)\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#2ecc71', alpha=0.7, label='CLIP Better'),\n",
    "        Patch(facecolor='#e74c3c', alpha=0.7, label='CVCL Better')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    diff_plot_path = os.path.join(RESULTS_DIR, 'scdc_textvision_difference_from_csv.png')\n",
    "    plt.savefig(diff_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved SCDC difference plot to {diff_plot_path}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    clip_better = sum(1 for d in differences if d > 0)\n",
    "    cvcl_better = sum(1 for d in differences if d < 0)\n",
    "    tied = sum(1 for d in differences if abs(d) < 0.001)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"SCDC TEXT-VISION PERFORMANCE COMPARISON SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"CLIP performs better: {clip_better}/{len(classes)} classes ({clip_better/len(classes)*100:.1f}%)\")\n",
    "    print(f\"CVCL performs better: {cvcl_better}/{len(classes)} classes ({cvcl_better/len(classes)*100:.1f}%)\")\n",
    "    if tied > 0:\n",
    "        print(f\"No significant difference: {tied}/{len(classes)} classes\")\n",
    "    \n",
    "    avg_diff = np.mean(differences)\n",
    "    print(f\"\\nAverage difference (CLIP - CVCL): {avg_diff:.3f} ({avg_diff*100:.1f} percentage points)\")\n",
    "    print(f\"Median difference: {np.median(differences):.3f}\")\n",
    "    print(f\"Max CLIP advantage: {max(differences):.3f} (class: {classes[differences.index(max(differences))]})\")\n",
    "    print(f\"Max CVCL advantage: {min(differences):.3f} (class: {classes[differences.index(min(differences))]})\")\n",
    "else:\n",
    "    print(\"Both CVCL and CLIP models needed for difference plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed performance table\n",
    "if len(stats_results) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED SCDC TEXT-VISION PERFORMANCE TABLE\")\n",
    "    print(\"Task: Color Discrimination Within Same Class\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create comparison table\n",
    "    table_data = []\n",
    "    for cls in classes:\n",
    "        row = {'Class': cls}\n",
    "        for model in models_to_test:\n",
    "            stats = stats_results[model][cls]\n",
    "            row[f\"{model}_mean\"] = f\"{stats['mean']*100:.1f}%\"\n",
    "            row[f\"{model}_ci95\"] = f\"±{stats['ci95']*100:.1f}%\"\n",
    "        \n",
    "        # Add difference if both models present\n",
    "        if 'cvcl-resnext' in models_to_test and 'clip-res' in models_to_test:\n",
    "            diff = (stats_results['clip-res'][cls]['mean'] - \n",
    "                   stats_results['cvcl-resnext'][cls]['mean']) * 100\n",
    "            row['Difference'] = f\"{diff:+.1f}%\"\n",
    "            \n",
    "            # Mark significant differences\n",
    "            if abs(diff) > 10:\n",
    "                row['Significance'] = '***' if diff > 0 else '---'\n",
    "            elif abs(diff) > 5:\n",
    "                row['Significance'] = '**' if diff > 0 else '--'\n",
    "            elif abs(diff) > 2:\n",
    "                row['Significance'] = '*' if diff > 0 else '-'\n",
    "            else:\n",
    "                row['Significance'] = ''\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    table_df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Display top performers for each model\n",
    "    print(\"\\nTop 10 Classes for CVCL (Color Discrimination):\")\n",
    "    cvcl_sorted = sorted(classes, key=lambda x: stats_results['cvcl-resnext'][x]['mean'], reverse=True)[:10]\n",
    "    for i, cls in enumerate(cvcl_sorted, 1):\n",
    "        acc = stats_results['cvcl-resnext'][cls]['mean'] * 100\n",
    "        print(f\"{i:2d}. {cls:25s}: {acc:.1f}%\")\n",
    "    \n",
    "    print(\"\\nTop 10 Classes for CLIP (Color Discrimination):\")\n",
    "    clip_sorted = sorted(classes, key=lambda x: stats_results['clip-res'][x]['mean'], reverse=True)[:10]\n",
    "    for i, cls in enumerate(clip_sorted, 1):\n",
    "        acc = stats_results['clip-res'][cls]['mean'] * 100\n",
    "        print(f\"{i:2d}. {cls:25s}: {acc:.1f}%\")\n",
    "    \n",
    "    # Save detailed table to CSV\n",
    "    table_path = os.path.join(RESULTS_DIR, 'scdc_textvision_detailed_comparison.csv')\n",
    "    table_df.to_csv(table_path, index=False)\n",
    "    print(f\"\\nSaved detailed SCDC comparison table to {table_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison\n",
    "if 'cvcl-resnext' in models_to_test and 'clip-res' in models_to_test:\n",
    "    from scipy import stats as scipy_stats\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STATISTICAL ANALYSIS - SCDC COLOR DISCRIMINATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get all accuracy values\n",
    "    cvcl_accs = [stats_results['cvcl-resnext'][cls]['mean'] for cls in classes]\n",
    "    clip_accs = [stats_results['clip-res'][cls]['mean'] for cls in classes]\n",
    "    \n",
    "    # Paired t-test (since we're comparing the same classes)\n",
    "    t_stat, p_value = scipy_stats.ttest_rel(cvcl_accs, clip_accs)\n",
    "    \n",
    "    print(f\"Paired t-test results:\")\n",
    "    print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"  p-value: {p_value:.6f}\")\n",
    "    \n",
    "    if p_value < 0.001:\n",
    "        print(\"  Result: Highly significant difference (p < 0.001) ***\")\n",
    "    elif p_value < 0.01:\n",
    "        print(\"  Result: Very significant difference (p < 0.01) **\")\n",
    "    elif p_value < 0.05:\n",
    "        print(\"  Result: Significant difference (p < 0.05) *\")\n",
    "    else:\n",
    "        print(\"  Result: No significant difference\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    diff_mean = np.mean(np.array(clip_accs) - np.array(cvcl_accs))\n",
    "    diff_std = np.std(np.array(clip_accs) - np.array(cvcl_accs))\n",
    "    cohens_d = diff_mean / diff_std if diff_std > 0 else 0\n",
    "    \n",
    "    print(f\"\\nEffect size (Cohen's d): {cohens_d:.3f}\")\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        print(\"  Interpretation: Negligible effect\")\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        print(\"  Interpretation: Small effect\")\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        print(\"  Interpretation: Medium effect\")\n",
    "    else:\n",
    "        print(\"  Interpretation: Large effect\")\n",
    "    \n",
    "    # Overall performance summary\n",
    "    print(f\"\\nOverall SCDC Performance (Color Discrimination):\")\n",
    "    print(f\"  CVCL: {np.mean(cvcl_accs)*100:.1f}% ± {np.std(cvcl_accs)*100:.1f}%\")\n",
    "    print(f\"  CLIP: {np.mean(clip_accs)*100:.1f}% ± {np.std(clip_accs)*100:.1f}%\")\n",
    "    print(f\"  Absolute difference: {(np.mean(clip_accs) - np.mean(cvcl_accs))*100:.1f} percentage points\")\n",
    "    print(f\"  Relative improvement: {((np.mean(clip_accs) / np.mean(cvcl_accs)) - 1)*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"- This test measures color discrimination WITHIN the same object class\")\n",
    "    print(\"- Size and texture are controlled (held constant)\")\n",
    "    print(\"- Performance reflects pure color-text alignment ability\")\n",
    "    print(\"- Lower than class discrimination as it's a harder task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SCDC vs Class discrimination if both CSVs exist\n",
    "class_summary_file = os.path.join(RESULTS_DIR, 'class_textvision_perclass_summary.csv')\n",
    "if os.path.exists(class_summary_file):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON: CLASS vs SCDC DISCRIMINATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load class discrimination results\n",
    "    class_df = pd.read_csv(class_summary_file)\n",
    "    \n",
    "    # Calculate means for each test type\n",
    "    for model in models_to_test:\n",
    "        # Class discrimination mean\n",
    "        class_means = class_df[class_df['model'] == model]['mean_accuracy'].values\n",
    "        class_overall = np.mean(class_means) * 100 if len(class_means) > 0 else 0\n",
    "        \n",
    "        # SCDC mean\n",
    "        scdc_means = summary_df[summary_df['model'] == model]['mean_accuracy'].values\n",
    "        scdc_overall = np.mean(scdc_means) * 100 if len(scdc_means) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{model}:\")\n",
    "        print(f\"  Class discrimination: {class_overall:.1f}%\")\n",
    "        print(f\"  SCDC (color within class): {scdc_overall:.1f}%\")\n",
    "        print(f\"  Difference: {class_overall - scdc_overall:.1f} percentage points\")\n",
    "        print(f\"  Ratio: {class_overall / scdc_overall:.2f}x easier\")\n",
    "    \n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(\"- Class discrimination is typically easier (different objects)\")\n",
    "    print(\"- SCDC is harder (same object, different colors only)\")\n",
    "    print(\"- The gap reveals how much models rely on object vs color features\")\n",
    "else:\n",
    "    print(\"\\nClass discrimination results not found for comparison.\")\n",
    "    print(f\"Run the class text-vision experiment to generate: {class_summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}