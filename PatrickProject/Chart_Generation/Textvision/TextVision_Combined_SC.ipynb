{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Bar Chart - Text-Vision CVCL vs CLIP Across Same-Class Discrimination Tests\n",
    "\n",
    "This notebook creates a horizontal bar chart comparing model performance across SCDC (color), SCDS (size), and SCDT (texture) discrimination tests using text-vision alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = r'C:\\Users\\jbats\\Projects\\NTU-Synthetic'\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'Textvision')\n",
    "\n",
    "# Load all three CSV files\n",
    "scdc_df = pd.read_csv(os.path.join(RESULTS_DIR, 'scdc_textvision_perclass_summary.csv'))\n",
    "scds_df = pd.read_csv(os.path.join(RESULTS_DIR, 'scds_textvision_perclass_summary.csv'))\n",
    "scdt_df = pd.read_csv(os.path.join(RESULTS_DIR, 'scdt_textvision_perclass_summary.csv'))\n",
    "\n",
    "print(\"Loaded text-vision data:\")\n",
    "print(f\"SCDC shape: {scdc_df.shape}\")\n",
    "print(f\"SCDS shape: {scds_df.shape}\")\n",
    "print(f\"SCDT shape: {scdt_df.shape}\")\n",
    "\n",
    "# Check columns\n",
    "print(\"\\nColumns in SCDC:\")\n",
    "print(scdc_df.columns.tolist())\n",
    "print(\"\\nFirst few rows of SCDC:\")\n",
    "print(scdc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each test and model\n",
    "def calculate_stats(df, test_name):\n",
    "    \"\"\"Calculate mean and std for each model in a test.\"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    for model in df['model'].unique():\n",
    "        model_data = df[df['model'] == model]['mean_accuracy'].values\n",
    "        \n",
    "        # Calculate overall mean and standard error\n",
    "        mean_acc = np.mean(model_data) * 100  # Convert to percentage\n",
    "        std_acc = np.std(model_data) * 100\n",
    "        \n",
    "        # Standard error for error bars\n",
    "        n_samples = len(model_data)\n",
    "        se = std_acc / np.sqrt(n_samples)\n",
    "        ci95 = 1.96 * se  # 95% confidence interval\n",
    "        \n",
    "        stats[model] = {\n",
    "            'mean': mean_acc,\n",
    "            'std': std_acc,\n",
    "            'se': se,\n",
    "            'ci95': ci95,\n",
    "            'n': n_samples\n",
    "        }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Calculate stats for each test\n",
    "scdc_stats = calculate_stats(scdc_df, 'SCDC (Color)')\n",
    "scds_stats = calculate_stats(scds_df, 'SCDS (Size)')\n",
    "scdt_stats = calculate_stats(scdt_df, 'SCDT (Texture)')\n",
    "\n",
    "# Print summary\n",
    "print(\"Text-Vision Summary Statistics:\\n\")\n",
    "print(\"SCDC (Color Discrimination):\")\n",
    "for model, stats in scdc_stats.items():\n",
    "    print(f\"  {model}: {stats['mean']:.1f}% ± {stats['ci95']:.1f}%\")\n",
    "\n",
    "print(\"\\nSCDS (Size Discrimination):\")\n",
    "for model, stats in scds_stats.items():\n",
    "    print(f\"  {model}: {stats['mean']:.1f}% ± {stats['ci95']:.1f}%\")\n",
    "\n",
    "print(\"\\nSCDT (Texture Discrimination):\")\n",
    "for model, stats in scdt_stats.items():\n",
    "    print(f\"  {model}: {stats['mean']:.1f}% ± {stats['ci95']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create horizontal bar chart with error bars\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Setup data for plotting\n",
    "tests = ['SCDT\\n(Texture)', 'SCDS\\n(Size)', 'SCDC\\n(Color)']  # Reversed for bottom-to-top\n",
    "test_stats = [scdt_stats, scds_stats, scdc_stats]  # Match order\n",
    "\n",
    "# Model colors - consistent with your notebooks\n",
    "colors = {\n",
    "    'cvcl-resnext': '#2a9d8f',  # Teal/green\n",
    "    'clip-res': '#e63946'  # Red\n",
    "}\n",
    "\n",
    "# Bar settings\n",
    "bar_height = 0.35\n",
    "y_positions = np.arange(len(tests))\n",
    "\n",
    "# Plot bars for each model\n",
    "for i, (test_name, stats) in enumerate(zip(tests, test_stats)):\n",
    "    # CVCL bar\n",
    "    if 'cvcl-resnext' in stats:\n",
    "        cvcl_mean = stats['cvcl-resnext']['mean']\n",
    "        cvcl_error = stats['cvcl-resnext']['ci95']\n",
    "        ax.barh(y_positions[i] - bar_height/2, cvcl_mean, bar_height,\n",
    "                xerr=cvcl_error, \n",
    "                color=colors['cvcl-resnext'],\n",
    "                alpha=0.8,\n",
    "                label='CVCL' if i == 0 else None,\n",
    "                capsize=5,\n",
    "                error_kw={'linewidth': 2, 'ecolor': 'black', 'alpha': 0.7})\n",
    "        \n",
    "        # Add value label\n",
    "        ax.text(cvcl_mean + cvcl_error + 1, y_positions[i] - bar_height/2, \n",
    "                f'{cvcl_mean:.1f}%', \n",
    "                va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # CLIP bar\n",
    "    if 'clip-res' in stats:\n",
    "        clip_mean = stats['clip-res']['mean']\n",
    "        clip_error = stats['clip-res']['ci95']\n",
    "        ax.barh(y_positions[i] + bar_height/2, clip_mean, bar_height,\n",
    "                xerr=clip_error,\n",
    "                color=colors['clip-res'],\n",
    "                alpha=0.8,\n",
    "                label='CLIP' if i == 0 else None,\n",
    "                capsize=5,\n",
    "                error_kw={'linewidth': 2, 'ecolor': 'black', 'alpha': 0.7})\n",
    "        \n",
    "        # Add value label\n",
    "        ax.text(clip_mean + clip_error + 1, y_positions[i] + bar_height/2, \n",
    "                f'{clip_mean:.1f}%', \n",
    "                va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Formatting\n",
    "ax.set_ylabel('Discrimination Test Type', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Text-Vision Model Performance Across Same-Class Feature Discrimination Tests', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Set y-axis\n",
    "ax.set_yticks(y_positions)\n",
    "ax.set_yticklabels(tests, fontsize=11)\n",
    "\n",
    "# Set x-axis\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_xticks([0, 25, 50, 75, 100])\n",
    "ax.set_xticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
    "\n",
    "# Add chance line\n",
    "ax.axvline(x=25, color='gray', linestyle='--', alpha=0.5, linewidth=1.5, label='Chance')\n",
    "\n",
    "# Grid\n",
    "ax.grid(axis='x', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Legend\n",
    "ax.legend(loc='lower right', fontsize=11, frameon=True, fancybox=True, shadow=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'textvision_combined_discrimination_results.png'), \n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'textvision_combined_discrimination_results.pdf'), \n",
    "            bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved as:\")\n",
    "print(f\"  - {os.path.join(RESULTS_DIR, 'textvision_combined_discrimination_results.png')}\")\n",
    "print(f\"  - {os.path.join(RESULTS_DIR, 'textvision_combined_discrimination_results.pdf')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table\n",
    "summary_data = []\n",
    "\n",
    "for test_name, stats in [('SCDC (Color)', scdc_stats), \n",
    "                          ('SCDS (Size)', scds_stats), \n",
    "                          ('SCDT (Texture)', scdt_stats)]:\n",
    "    for model, model_stats in stats.items():\n",
    "        summary_data.append({\n",
    "            'Test': test_name,\n",
    "            'Model': model.replace('-resnext', '').replace('-res', '').upper(),\n",
    "            'Mean Accuracy (%)': f\"{model_stats['mean']:.1f}\",\n",
    "            '95% CI': f\"±{model_stats['ci95']:.1f}\",\n",
    "            'Std Dev (%)': f\"{model_stats['std']:.1f}\",\n",
    "            'N Classes': model_stats['n']\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nText-Vision Summary Table:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary table\n",
    "summary_path = os.path.join(RESULTS_DIR, 'textvision_discrimination_tests_summary.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSummary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison - which model wins each test?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEXT-VISION STATISTICAL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "for test_name, df in [('SCDC (Color)', scdc_df), \n",
    "                       ('SCDS (Size)', scds_df), \n",
    "                       ('SCDT (Texture)', scdt_df)]:\n",
    "    \n",
    "    cvcl_data = df[df['model'] == 'cvcl-resnext']['mean_accuracy'].values\n",
    "    clip_data = df[df['model'] == 'clip-res']['mean_accuracy'].values\n",
    "    \n",
    "    # Paired t-test (since we're comparing the same classes)\n",
    "    t_stat, p_value = scipy_stats.ttest_rel(cvcl_data, clip_data)\n",
    "    \n",
    "    cvcl_mean = np.mean(cvcl_data) * 100\n",
    "    clip_mean = np.mean(clip_data) * 100\n",
    "    diff = clip_mean - cvcl_mean\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  CVCL: {cvcl_mean:.1f}%\")\n",
    "    print(f\"  CLIP: {clip_mean:.1f}%\")\n",
    "    print(f\"  Difference: {diff:+.1f}% ({'CLIP' if diff > 0 else 'CVCL'} better)\")\n",
    "    print(f\"  p-value: {p_value:.6f}\")\n",
    "    \n",
    "    if p_value < 0.001:\n",
    "        print(f\"  Result: ***Highly significant (p < 0.001)\")\n",
    "    elif p_value < 0.01:\n",
    "        print(f\"  Result: **Very significant (p < 0.01)\")\n",
    "    elif p_value < 0.05:\n",
    "        print(f\"  Result: *Significant (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"  Result: Not significant\")\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    diff_mean = np.mean(clip_data - cvcl_data)\n",
    "    diff_std = np.std(clip_data - cvcl_data)\n",
    "    cohens_d = diff_mean / diff_std if diff_std > 0 else 0\n",
    "    \n",
    "    print(f\"  Cohen's d: {cohens_d:.3f}\")\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        print(\"    (Negligible effect)\")\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        print(\"    (Small effect)\")\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        print(\"    (Medium effect)\")\n",
    "    else:\n",
    "        print(\"    (Large effect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model comparison chart - which model is better at what?\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Calculate differences (CLIP - CVCL)\n",
    "differences = []\n",
    "test_labels = ['Color\\n(SCDC)', 'Size\\n(SCDS)', 'Texture\\n(SCDT)']\n",
    "\n",
    "for stats in [scdc_stats, scds_stats, scdt_stats]:\n",
    "    diff = stats['clip-res']['mean'] - stats['cvcl-resnext']['mean']\n",
    "    differences.append(diff)\n",
    "\n",
    "# Create bars\n",
    "x_pos = np.arange(len(test_labels))\n",
    "colors_bar = ['#e63946' if d > 0 else '#2a9d8f' for d in differences]\n",
    "\n",
    "bars = ax.bar(x_pos, differences, color=colors_bar, alpha=0.8, \n",
    "               edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels\n",
    "for i, diff in enumerate(differences):\n",
    "    ax.text(i, diff + (1 if diff > 0 else -1), f'{diff:+.1f}%',\n",
    "            ha='center', va='bottom' if diff > 0 else 'top', \n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "# Formatting\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax.set_ylabel('Performance Difference (%)\\n(CLIP - CVCL)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Discrimination Test Type', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Text-Vision Model Performance Differences\\nPositive = CLIP Better, Negative = CVCL Better',\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(test_labels, fontsize=11)\n",
    "ax.set_ylim(min(differences) - 10, max(differences) + 10)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Add annotations\n",
    "ax.text(0.02, 0.98, 'CLIP excels at:', transform=ax.transAxes,\n",
    "        fontsize=10, va='top', fontweight='bold', color='#e63946')\n",
    "ax.text(0.02, 0.92, '• Color discrimination', transform=ax.transAxes,\n",
    "        fontsize=9, va='top')\n",
    "        \n",
    "ax.text(0.02, 0.82, 'CVCL excels at:', transform=ax.transAxes,\n",
    "        fontsize=10, va='top', fontweight='bold', color='#2a9d8f')\n",
    "ax.text(0.02, 0.76, '• Size discrimination', transform=ax.transAxes,\n",
    "        fontsize=9, va='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "diff_path = os.path.join(RESULTS_DIR, 'textvision_model_differences.png')\n",
    "plt.savefig(diff_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDifference plot saved to {diff_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary insights\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHTS FROM TEXT-VISION EXPERIMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. OVERALL PERFORMANCE:\")\n",
    "for test_name, stats in [('Color (SCDC)', scdc_stats), \n",
    "                          ('Size (SCDS)', scds_stats), \n",
    "                          ('Texture (SCDT)', scdt_stats)]:\n",
    "    cvcl_acc = stats['cvcl-resnext']['mean']\n",
    "    clip_acc = stats['clip-res']['mean']\n",
    "    print(f\"   {test_name:20s} CVCL: {cvcl_acc:5.1f}%  CLIP: {clip_acc:5.1f}%\")\n",
    "\n",
    "print(\"\\n2. MODEL STRENGTHS:\")\n",
    "print(\"   • CLIP: Superior at color discrimination (text-color alignment)\")\n",
    "print(\"   • CVCL: Better at size discrimination (spatial understanding)\")\n",
    "print(\"   • Both: Similar performance on texture discrimination\")\n",
    "\n",
    "print(\"\\n3. COMPARISON TO VISUAL PROTOTYPES:\")\n",
    "print(\"   Text-vision approach uses language to identify visual features\")\n",
    "print(\"   This tests true multimodal understanding vs pure visual similarity\")\n",
    "\n",
    "print(\"\\n4. IMPLICATIONS:\")\n",
    "print(\"   • CLIP's training on web data gives strong color-text associations\")\n",
    "print(\"   • CVCL's infant-inspired training may emphasize size/spatial features\")\n",
    "print(\"   • Texture discrimination may rely less on language alignment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}