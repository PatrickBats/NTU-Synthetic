{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCDS (Same Class Different Size) Per-Class Analysis with Error Bars\n",
    "\n",
    "This notebook tests size discrimination within the same object class.\n",
    "For example: Can models distinguish small apple vs medium apple vs large apple?\n",
    "\n",
    "Key difference from other tests:\n",
    "- SCDC test: Same object, different colors (red apple vs blue apple)\n",
    "- SCDS test: Same object, different sizes (small apple vs large apple)\n",
    "- Hypothesis: CVCL may have advantage in size discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\clip\\clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir))\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "\n",
    "# SyntheticKonkle paths - Using 224x224 resized images for faster processing\n",
    "DATA_DIR = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle_224')\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup\n",
    "def build_synthetic_dataset():\n",
    "    \"\"\"Combine all labels.csv files from class_color folders.\"\"\"\n",
    "    all_data = []\n",
    "    # Note: In SyntheticKonkle_224, folders are nested under SyntheticKonkle/\n",
    "    base_dir = os.path.join(DATA_DIR, 'SyntheticKonkle')\n",
    "    \n",
    "    class_folders = [d for d in os.listdir(base_dir) \n",
    "                    if os.path.isdir(os.path.join(base_dir, d)) \n",
    "                    and d.endswith('_color')]\n",
    "    \n",
    "    for folder in class_folders:\n",
    "        labels_path = os.path.join(base_dir, folder, 'labels.csv')\n",
    "        if os.path.exists(labels_path):\n",
    "            df = pd.read_csv(labels_path)\n",
    "            df['folder'] = folder\n",
    "            all_data.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df = combined_df.dropna(subset=['class'])\n",
    "    print(f\"Loaded {len(combined_df)} images from {len(class_folders)} classes\")\n",
    "    unique_classes = combined_df['class'].unique()\n",
    "    unique_sizes = combined_df['size'].unique()\n",
    "    print(f\"Classes found: {len(unique_classes)}\")\n",
    "    print(f\"Sizes found: {unique_sizes}\")\n",
    "    return combined_df\n",
    "\n",
    "class SyntheticImageDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform):\n",
    "        self.df = df\n",
    "        # For SyntheticKonkle_224, images are in nested structure\n",
    "        self.data_dir = os.path.join(data_dir, 'SyntheticKonkle')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row['folder'], row['filename'])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "        except:\n",
    "            img = Image.new('RGB', (224, 224), color='black')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    colors = [b[2] for b in batch]\n",
    "    sizes = [b[3] for b in batch]\n",
    "    textures = [b[4] for b in batch]\n",
    "    idxs = [b[5] for b in batch]\n",
    "    return imgs, classes, colors, sizes, textures, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scds_test_per_class(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', \n",
    "                            batch_size=64, trials_per_class=500):\n",
    "    \"\"\"Run SCDS (Same Class Different Size) test and return per-class results.\n",
    "    \n",
    "    Tests if model can distinguish different sizes of the same object.\n",
    "    Example: small apple vs medium apple vs large apple (all red-smooth).\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Load model & transform\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    \n",
    "    # Build dataset and extract embeddings\n",
    "    df = build_synthetic_dataset()\n",
    "    ds = SyntheticImageDataset(df, DATA_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    all_embs, all_classes, all_colors, all_sizes, all_textures, all_idxs = [], [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, colors, sizes, textures, idxs in loader:\n",
    "            feats = extractor.get_img_feature(imgs.to(device))\n",
    "            feats = extractor.norm_features(feats).cpu().float()\n",
    "            all_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_colors.extend(colors)\n",
    "            all_sizes.extend(sizes)\n",
    "            all_textures.extend(textures)\n",
    "            all_idxs.extend(idxs)\n",
    "    all_embs = torch.cat(all_embs, dim=0)\n",
    "\n",
    "    # Group by class, color, texture (keeping these constant) and vary SIZE\n",
    "    # Structure: class_color_texture_groups[cls][(color, texture)] = {size: [idx_list]}\n",
    "    class_color_texture_groups = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    for idx, cls, col, size, texture in zip(all_idxs, all_classes, all_colors, all_sizes, all_textures):\n",
    "        class_color_texture_groups[cls][(col, texture)][size].append(idx)\n",
    "\n",
    "    # Track per-class performance for size discrimination\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    # Get unique classes and sizes\n",
    "    unique_classes = list(class_color_texture_groups.keys())\n",
    "    all_sizes_set = ['small', 'medium', 'large']  # Standard sizes in SyntheticKonkle\n",
    "    \n",
    "    # Run trials for each class\n",
    "    for target_class in tqdm(unique_classes, desc=f\"Testing {model_name} SCDS\"):\n",
    "        trials_done = 0\n",
    "        \n",
    "        # For each color-texture combination in this class\n",
    "        for (color, texture), size_groups in class_color_texture_groups[target_class].items():\n",
    "            if trials_done >= trials_per_class:\n",
    "                break\n",
    "            \n",
    "            # Need at least 3 different sizes (small, medium, large)\n",
    "            available_sizes = list(size_groups.keys())\n",
    "            if len(available_sizes) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Run multiple trials for this combination\n",
    "            n_trials = min(50, trials_per_class - trials_done)  # More trials per combo\n",
    "            \n",
    "            for _ in range(n_trials):\n",
    "                # Pick target size and make sure we have all 3 sizes\n",
    "                if 'small' in size_groups and 'medium' in size_groups and 'large' in size_groups:\n",
    "                    target_size = random.choice(['small', 'medium', 'large'])\n",
    "                    \n",
    "                    # Pick query image from target size\n",
    "                    q = random.choice(size_groups[target_size])\n",
    "                    \n",
    "                    # Build prototype from other images of same size (if available)\n",
    "                    same_size_group = [i for i in size_groups[target_size] if i != q]\n",
    "                    if same_size_group:\n",
    "                        proto = all_embs[[all_idxs.index(i) for i in same_size_group]].mean(0)\n",
    "                    else:\n",
    "                        proto = all_embs[all_idxs.index(q)]\n",
    "                    proto = proto / proto.norm()\n",
    "\n",
    "                    # Pick one distractor from each other size\n",
    "                    distractors = []\n",
    "                    for dist_size in ['small', 'medium', 'large']:\n",
    "                        if dist_size != target_size and dist_size in size_groups:\n",
    "                            distractors.append(random.choice(size_groups[dist_size]))\n",
    "                    \n",
    "                    # For 4-way choice, add another distractor from a different size\n",
    "                    if len(distractors) == 2:\n",
    "                        # Pick another from one of the distractor sizes\n",
    "                        extra_size = random.choice([s for s in ['small', 'medium', 'large'] if s != target_size])\n",
    "                        if extra_size in size_groups and len(size_groups[extra_size]) > 1:\n",
    "                            extra = random.choice(size_groups[extra_size])\n",
    "                            if extra not in distractors:\n",
    "                                distractors.append(extra)\n",
    "                    \n",
    "                    if len(distractors) < 3:\n",
    "                        continue  # Skip if we couldn't get enough distractors\n",
    "                    \n",
    "                    candidates = [q] + distractors[:3]  # Ensure exactly 4 candidates\n",
    "                    \n",
    "                    # Compute similarities\n",
    "                    feats_cand = all_embs[[all_idxs.index(i) for i in candidates]]\n",
    "                    sims = feats_cand @ proto\n",
    "                    guess = candidates[sims.argmax().item()]\n",
    "\n",
    "                    # Update counts\n",
    "                    class_correct[target_class] += int(guess == q)\n",
    "                    class_total[target_class] += 1\n",
    "                    trials_done += 1\n",
    "    \n",
    "    # Calculate per-class accuracy for size discrimination\n",
    "    class_accuracies = {}\n",
    "    for cls in unique_classes:\n",
    "        if class_total[cls] > 0:\n",
    "            class_accuracies[cls] = class_correct[cls] / class_total[cls]\n",
    "        else:\n",
    "            class_accuracies[cls] = 0.0\n",
    "    \n",
    "    return class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n",
      "Found 68 unique classes in the dataset\n",
      "\n",
      "Starting SCDS (Same Class Different Size) evaluation:\n",
      "Configuration: 3 seeds × 500 trials/class × 68 classes\n",
      "Total trials per class: 1500\n",
      "Expected margin of error: ~3.5% at 95% confidence level\n",
      "\n",
      "Hypothesis: CVCL may show advantage in size discrimination (fundamental visual property)\n",
      "\n",
      "==================================================\n",
      "Testing cvcl-resnext with 3 seeds\n",
      "==================================================\n",
      "\n",
      "Seed 1/3 for cvcl-resnext\n",
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing cvcl-resnext SCDS: 100%|██████████| 68/68 [00:07<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean size discrimination accuracy: 0.632\n",
      "  Classes tested: 68\n",
      "  Waiting 30 seconds before next seed to avoid rate limiting...\n",
      "\n",
      "Seed 2/3 for cvcl-resnext\n",
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_1.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing cvcl-resnext SCDS: 100%|██████████| 68/68 [00:07<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean size discrimination accuracy: 0.607\n",
      "  Classes tested: 68\n",
      "  Waiting 30 seconds before next seed to avoid rate limiting...\n",
      "\n",
      "Seed 3/3 for cvcl-resnext\n",
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_2.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing cvcl-resnext SCDS: 100%|██████████| 68/68 [00:07<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean size discrimination accuracy: 0.617\n",
      "  Classes tested: 68\n",
      "\n",
      "==================================================\n",
      "Testing clip-res with 3 seeds\n",
      "==================================================\n",
      "\n",
      "Seed 1/3 for clip-res\n",
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Testing clip-res SCDS: 100%|██████████| 68/68 [00:09<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean size discrimination accuracy: 0.504\n",
      "  Classes tested: 68\n",
      "\n",
      "Seed 2/3 for clip-res\n",
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing clip-res SCDS: 100%|██████████| 68/68 [00:09<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean size discrimination accuracy: 0.506\n",
      "  Classes tested: 68\n",
      "\n",
      "Seed 3/3 for clip-res\n",
      "Loaded 8015 images from 68 classes\n",
      "Classes found: 68\n",
      "Sizes found: ['large' 'medium' 'small']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing clip-res SCDS: 100%|██████████| 68/68 [00:09<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean size discrimination accuracy: 0.504\n",
      "  Classes tested: 68\n",
      "\n",
      "==================================================\n",
      "SCDS EVALUATION COMPLETE\n",
      "==================================================\n",
      "cvcl-resnext:\n",
      "  - 68 classes tested\n",
      "  - Overall size discrimination: 0.618\n",
      "  - Check if CVCL shows advantage in size (fundamental property)\n",
      "clip-res:\n",
      "  - 68 classes tested\n",
      "  - Overall size discrimination: 0.505\n",
      "  - Check if CLIP struggles with relative size concepts\n",
      "\n",
      "Saved detailed results to c:\\Users\\jbats\\Projects\\NTU-Synthetic\\PatrickProject\\Chart_Generation\\scds_perclass_results.csv\n",
      "Saved summary to c:\\Users\\jbats\\Projects\\NTU-Synthetic\\PatrickProject\\Chart_Generation\\scds_perclass_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run multiple seeds for both models - PUBLICATION SETTINGS\n",
    "n_seeds = 3  # Limited seeds due to CVCL rate limiting\n",
    "trials_per_class = 500  # Increased trials for better statistical power\n",
    "models_to_test = ['cvcl-resnext', 'clip-res']\n",
    "\n",
    "# First, check dataset\n",
    "test_df = build_synthetic_dataset()\n",
    "n_classes = len(test_df['class'].unique())\n",
    "print(f\"Found {n_classes} unique classes in the dataset\")\n",
    "\n",
    "print(f\"\\nStarting SCDS (Same Class Different Size) evaluation:\")\n",
    "print(f\"Configuration: {n_seeds} seeds × {trials_per_class} trials/class × {n_classes} classes\")\n",
    "print(f\"Total trials per class: {n_seeds * trials_per_class}\")\n",
    "print(f\"Expected margin of error: ~3.5% at 95% confidence level\\n\")\n",
    "print(f\"Hypothesis: CVCL may show advantage in size discrimination (fundamental visual property)\")\n",
    "\n",
    "all_results = {model: defaultdict(list) for model in models_to_test}\n",
    "\n",
    "# Run evaluation\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Testing {model_name} with {n_seeds} seeds\")\n",
    "    print('='*50)\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        print(f\"\\nSeed {seed+1}/{n_seeds} for {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            class_acc = run_scds_test_per_class(model_name, seed=seed, trials_per_class=trials_per_class)\n",
    "            \n",
    "            # Store results\n",
    "            for cls, acc in class_acc.items():\n",
    "                all_results[model_name][cls].append(acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if len(class_acc) > 0:\n",
    "                mean_acc = np.mean(list(class_acc.values()))\n",
    "                print(f\"  Mean size discrimination accuracy: {mean_acc:.3f}\")\n",
    "                print(f\"  Classes tested: {len(class_acc)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            if \"404\" in str(e) or \"rate\" in str(e).lower():\n",
    "                print(f\"  Rate limit hit - waiting 60 seconds before retry...\")\n",
    "                import time\n",
    "                time.sleep(60)\n",
    "                try:\n",
    "                    class_acc = run_scds_test_per_class(model_name, seed=seed, trials_per_class=trials_per_class)\n",
    "                    for cls, acc in class_acc.items():\n",
    "                        all_results[model_name][cls].append(acc)\n",
    "                    print(f\"  Retry successful!\")\n",
    "                except:\n",
    "                    print(f\"  Retry failed - skipping this seed\")\n",
    "                    continue\n",
    "        \n",
    "        # Add delay between seeds for CVCL\n",
    "        if 'cvcl' in model_name and seed < n_seeds - 1:\n",
    "            import time\n",
    "            print(\"  Waiting 30 seconds before next seed to avoid rate limiting...\")\n",
    "            time.sleep(30)\n",
    "\n",
    "# Calculate statistics\n",
    "stats_results = {}\n",
    "for model_name in models_to_test:\n",
    "    stats_results[model_name] = {}\n",
    "    for cls, accs in all_results[model_name].items():\n",
    "        if len(accs) > 0:\n",
    "            n_samples = len(accs)\n",
    "            stats_results[model_name][cls] = {\n",
    "                'mean': np.mean(accs),\n",
    "                'std': np.std(accs, ddof=1) if n_samples > 1 else 0,\n",
    "                'se': np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'ci95': 1.96 * np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'n_samples': n_samples,\n",
    "                'total_trials': n_samples * trials_per_class,\n",
    "                'raw': accs\n",
    "            }\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SCDS EVALUATION COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Report statistics\n",
    "for model_name in models_to_test:\n",
    "    if len(stats_results[model_name]) > 0:\n",
    "        all_means = [stats['mean'] for stats in stats_results[model_name].values()]\n",
    "        overall_mean = np.mean(all_means)\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  - {len(stats_results[model_name])} classes tested\")\n",
    "        print(f\"  - Overall size discrimination: {overall_mean:.3f}\")\n",
    "        if 'cvcl' in model_name.lower():\n",
    "            print(f\"  - Check if CVCL shows advantage in size (fundamental property)\")\n",
    "        elif 'clip' in model_name.lower():\n",
    "            print(f\"  - Check if CLIP struggles with relative size concepts\")\n",
    "\n",
    "# Save results\n",
    "detailed_df = []\n",
    "for model_name in models_to_test:\n",
    "    for cls, stats in stats_results[model_name].items():\n",
    "        for seed_idx, acc in enumerate(stats['raw']):\n",
    "            detailed_df.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'seed': seed_idx,\n",
    "                'accuracy': acc,\n",
    "                'n_trials': trials_per_class,\n",
    "                'test_type': 'SCDS'\n",
    "            })\n",
    "\n",
    "if len(detailed_df) > 0:\n",
    "    detailed_df = pd.DataFrame(detailed_df)\n",
    "    detailed_df.to_csv(os.path.join(RESULTS_DIR, 'scds_perclass_results.csv'), index=False)\n",
    "    print(f\"\\nSaved detailed results to {os.path.join(RESULTS_DIR, 'scds_perclass_results.csv')}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_stats = []\n",
    "    for model_name in models_to_test:\n",
    "        for cls, stats in stats_results[model_name].items():\n",
    "            summary_stats.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'mean_accuracy': stats['mean'],\n",
    "                'std': stats['std'],\n",
    "                'se': stats['se'],\n",
    "                'ci95': stats['ci95'],\n",
    "                'n_seeds': stats['n_samples'],\n",
    "                'total_trials': stats['total_trials'],\n",
    "                'test_type': 'SCDS'\n",
    "            })\n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    summary_df.to_csv(os.path.join(RESULTS_DIR, 'scds_perclass_summary.csv'), index=False)\n",
    "    print(f\"Saved summary to {os.path.join(RESULTS_DIR, 'scds_perclass_summary.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-quality visualization\n",
    "fig = plt.figure(figsize=(14, 11))\n",
    "\n",
    "# Create subplots with space for legend in between\n",
    "ax1 = plt.subplot2grid((20, 1), (0, 0), rowspan=8)\n",
    "ax2 = plt.subplot2grid((20, 1), (12, 0), rowspan=8)\n",
    "\n",
    "# Prepare data\n",
    "classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "mid_point = len(classes) // 2\n",
    "classes_first_half = classes[:mid_point]\n",
    "classes_second_half = classes[mid_point:]\n",
    "\n",
    "# Colors optimized for size discrimination visualization\n",
    "# Green if CVCL performs better, Orange if CLIP performs better\n",
    "colors = {\n",
    "    'cvcl-resnext': '#2d6a4f',  # Forest green - CVCL may have advantage\n",
    "    'clip-res': '#f77f00'  # Orange - CLIP may struggle with size\n",
    "}\n",
    "markers = {\n",
    "    'cvcl-resnext': 'o',\n",
    "    'clip-res': 's'\n",
    "}\n",
    "avg_line_styles = {\n",
    "    'cvcl-resnext': '--',\n",
    "    'clip-res': '-.'\n",
    "}\n",
    "\n",
    "# Short display labels\n",
    "short_labels = {\n",
    "    'cvcl-resnext': 'CVCL',\n",
    "    'clip-res': 'CLIP'\n",
    "}\n",
    "\n",
    "legend_elements = []\n",
    "\n",
    "def plot_on_axis(ax, class_subset, is_first=False):\n",
    "    x_pos = np.arange(len(class_subset))\n",
    "    \n",
    "    for model_name in models_to_test:\n",
    "        means = [stats_results[model_name][cls]['mean'] * 100 for cls in class_subset]\n",
    "        errors = [stats_results[model_name][cls]['ci95'] * 100 for cls in class_subset]\n",
    "        \n",
    "        ax.errorbar(x_pos, means, yerr=errors, \n",
    "                    label=None,\n",
    "                    color=colors[model_name],\n",
    "                    marker=markers[model_name],\n",
    "                    markersize=7,\n",
    "                    linewidth=0,\n",
    "                    capsize=4,\n",
    "                    capthick=1.5,\n",
    "                    alpha=0.9,\n",
    "                    markeredgecolor='black',\n",
    "                    markeredgewidth=0.5)\n",
    "    \n",
    "    # Chance line\n",
    "    ax.axhline(y=25, color='#ffa500', linestyle=':', alpha=0.8, linewidth=1.5)\n",
    "    \n",
    "    # Calculate overall averages\n",
    "    all_classes_means = {}\n",
    "    for model_name in models_to_test:\n",
    "        all_means = [stats_results[model_name][cls]['mean'] * 100 for cls in classes]\n",
    "        all_classes_means[model_name] = np.mean(all_means)\n",
    "    \n",
    "    # Add average lines\n",
    "    for model_name in models_to_test:\n",
    "        avg_performance = all_classes_means[model_name]\n",
    "        ax.axhline(y=avg_performance, \n",
    "                  color=colors[model_name], \n",
    "                  linestyle=avg_line_styles[model_name], \n",
    "                  alpha=0.7, \n",
    "                  linewidth=2)\n",
    "        \n",
    "        if is_first:\n",
    "            ax.text(len(class_subset) + 0.8, avg_performance, \n",
    "                   f'{avg_performance:.1f}%', \n",
    "                   fontsize=9, \n",
    "                   color=colors[model_name], \n",
    "                   va='center',\n",
    "                   fontweight='bold')\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_ylabel('Size Discrimination Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(class_subset, rotation=45, ha='right', fontsize=10)\n",
    "    ax.set_ylim(0, 105)\n",
    "    ax.set_yticks([0, 25, 50, 75, 100])\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_facecolor('#fafafa')\n",
    "    \n",
    "    # Create legend elements (only once)\n",
    "    global legend_elements\n",
    "    if is_first:\n",
    "        from matplotlib.lines import Line2D\n",
    "        legend_elements = []\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], marker=markers[model_name], color='w', \n",
    "                      markerfacecolor=colors[model_name], markeredgecolor='black',\n",
    "                      markersize=8, label=short_labels[model_name])\n",
    "            )\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            avg_val = all_classes_means[model_name]\n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color=colors[model_name], \n",
    "                      linestyle=avg_line_styles[model_name], linewidth=2,\n",
    "                      label=f'{model_name.upper().split(\"-\")[0]} Average ({avg_val:.1f}%)')\n",
    "            )\n",
    "        \n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color='#ffa500', linestyle=':', linewidth=1.5,\n",
    "                  label='Chance Level (25%)')\n",
    "        )\n",
    "\n",
    "# Plot both halves\n",
    "plot_on_axis(ax1, classes_first_half, is_first=True)\n",
    "ax1.set_title('SCDS: Size Discrimination Performance\\nSame Class, Different Sizes (Color & Texture Controlled)', \n",
    "              fontsize=13, fontweight='bold', pad=10)\n",
    "\n",
    "plot_on_axis(ax2, classes_second_half, is_first=False)\n",
    "ax2.set_xlabel('Target Category', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Legend centered between subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "legend = fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc='center',\n",
    "    bbox_to_anchor=(0.5, 0.47),\n",
    "    ncol=3,\n",
    "    fontsize=9,\n",
    "    frameon=True,\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    framealpha=0.95,\n",
    "    borderpad=0.3,\n",
    "    labelspacing=0.4,\n",
    "    handlelength=2.2,\n",
    "    columnspacing=1.6\n",
    ")\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_edgecolor('gray')\n",
    "legend.get_frame().set_linewidth(1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'scds_perclass_comparison.png'), dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'scds_perclass_comparison.pdf'), bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved SCDS plots to:\")\n",
    "print(f\"  - {os.path.join(RESULTS_DIR, 'scds_perclass_comparison.png')}\")\n",
    "print(f\"  - {os.path.join(RESULTS_DIR, 'scds_perclass_comparison.pdf')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary and analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCDS SIZE DISCRIMINATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall comparison\n",
    "for model in models_to_test:\n",
    "    all_accs = []\n",
    "    for cls in classes:\n",
    "        if cls in stats_results[model]:\n",
    "            all_accs.extend(stats_results[model][cls]['raw'])\n",
    "    if all_accs:\n",
    "        mean = np.mean(all_accs)\n",
    "        std = np.std(all_accs)\n",
    "        se = std / np.sqrt(len(all_accs))\n",
    "        ci95 = 1.96 * se\n",
    "        print(f\"\\n{model}:\")\n",
    "        print(f\"  Overall: {mean:.3f} ± {ci95:.3f}\")\n",
    "        \n",
    "        if 'cvcl' in model.lower():\n",
    "            print(f\"  Interpretation: Check if CVCL has advantage in size discrimination\")\n",
    "        elif 'clip' in model.lower():\n",
    "            print(f\"  Interpretation: Size concepts in text may be relative/ambiguous\")\n",
    "\n",
    "# Find biggest differences\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"CLASSES WITH LARGEST MODEL DIFFERENCES:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "differences = []\n",
    "for cls in classes:\n",
    "    if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "        diff = stats_results['cvcl-resnext'][cls]['mean'] - stats_results['clip-res'][cls]['mean']\n",
    "        differences.append((cls, diff, \n",
    "                          stats_results['cvcl-resnext'][cls]['mean'],\n",
    "                          stats_results['clip-res'][cls]['mean']))\n",
    "\n",
    "differences.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 5 classes where CVCL > CLIP (CVCL advantage):\")\n",
    "cvcl_wins = [d for d in differences if d[1] > 0]\n",
    "if cvcl_wins:\n",
    "    for cls, diff, cvcl_acc, clip_acc in cvcl_wins[:5]:\n",
    "        print(f\"  {cls:20s}: CVCL={cvcl_acc:.1%}, CLIP={clip_acc:.1%}, Diff={diff:+.1%}\")\n",
    "else:\n",
    "    print(\"  None - CLIP dominates size discrimination\")\n",
    "\n",
    "print(\"\\nClasses where CLIP > CVCL:\")\n",
    "clip_wins = [d for d in differences if d[1] < 0]\n",
    "if clip_wins:\n",
    "    for cls, diff, cvcl_acc, clip_acc in clip_wins[:5]:\n",
    "        print(f\"  {cls:20s}: CVCL={cvcl_acc:.1%}, CLIP={clip_acc:.1%}, Diff={diff:+.1%}\")\n",
    "\n",
    "# Statistical test\n",
    "from scipy import stats as scipy_stats\n",
    "cvcl_all = []\n",
    "clip_all = []\n",
    "for cls in classes:\n",
    "    if cls in stats_results['cvcl-resnext'] and cls in stats_results['clip-res']:\n",
    "        cvcl_all.extend(stats_results['cvcl-resnext'][cls]['raw'])\n",
    "        clip_all.extend(stats_results['clip-res'][cls]['raw'])\n",
    "\n",
    "if cvcl_all and clip_all:\n",
    "    t_stat, p_value = scipy_stats.ttest_ind(cvcl_all, clip_all)\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"Statistical Test (CVCL vs CLIP on size):\")\n",
    "    print(f\"t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"p-value: {p_value:.6f}\")\n",
    "    if p_value < 0.05:\n",
    "        if np.mean(cvcl_all) > np.mean(clip_all):\n",
    "            print(\"Result: CVCL significantly BETTER at size discrimination (p < 0.05)\")\n",
    "            print(\"Conclusion: CVCL shows advantage in fundamental visual property\")\n",
    "        else:\n",
    "            print(\"Result: CLIP significantly better at size discrimination (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"Result: No significant difference between models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
