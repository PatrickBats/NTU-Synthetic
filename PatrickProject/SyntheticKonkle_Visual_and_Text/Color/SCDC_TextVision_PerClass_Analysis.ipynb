{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Class Different Color (SCDC) Text-Vision Analysis with Controlled Attributes\n",
    "\n",
    "This notebook tests color discrimination WITHIN the same class using text-vision alignment.\n",
    "All trials have matched size and texture, with only color varying.\n",
    "Text encoding uses color+class format (e.g., \"red apple\", \"green apple\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\clip\\clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\n",
      "Results will be saved to: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\PatrickProject\\Chart_Generation\\Textvision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "import time\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = r'C:\\Users\\jbats\\Projects\\NTU-Synthetic'\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "\n",
    "# SyntheticKonkle paths - Using 224x224 resized images\n",
    "DATA_DIR = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle_224')\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'Textvision')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup with proper attribute tracking\n",
    "def build_synthetic_dataset():\n",
    "    \"\"\"Load the master labels CSV with all visual properties.\"\"\"\n",
    "    # Use the master_labels.csv which has all the attribute information\n",
    "    master_csv = os.path.join(DATA_DIR, 'master_labels.csv')\n",
    "    \n",
    "    if not os.path.exists(master_csv):\n",
    "        print(f\"Warning: {master_csv} not found, trying alternative path...\")\n",
    "        # Try the original SyntheticKonkle folder\n",
    "        master_csv = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle', 'master_labels.csv')\n",
    "    \n",
    "    print(f\"Loading master labels from: {master_csv}\")\n",
    "    df = pd.read_csv(master_csv)\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    required_cols = ['folder', 'filename', 'class', 'color', 'size', 'texture']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Clean the data\n",
    "    df = df.dropna(subset=required_cols)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} images\")\n",
    "    print(f\"Classes: {df['class'].nunique()} unique\")\n",
    "    print(f\"Colors: {df['color'].nunique()} unique\")\n",
    "    print(f\"Sizes: {df['size'].nunique()} unique\")\n",
    "    print(f\"Textures: {df['texture'].nunique()} unique\")\n",
    "    \n",
    "    # Check color distribution within classes\n",
    "    color_per_class = df.groupby('class')['color'].nunique()\n",
    "    print(f\"\\nAverage colors per class: {color_per_class.mean():.1f}\")\n",
    "    print(f\"Min colors in a class: {color_per_class.min()}\")\n",
    "    print(f\"Max colors in a class: {color_per_class.max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "class SyntheticImageDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform):\n",
    "        self.df = df\n",
    "        # For SyntheticKonkle_224, images are in nested structure\n",
    "        self.data_dir = os.path.join(data_dir, 'SyntheticKonkle')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row['folder'], row['filename'])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "        except Exception as e:\n",
    "            # Return a black image if file not found\n",
    "            img = Image.new('RGB', (224, 224), color='black')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    colors = [b[2] for b in batch]\n",
    "    sizes = [b[3] for b in batch]\n",
    "    textures = [b[4] for b in batch]\n",
    "    idxs = [b[5] for b in batch]\n",
    "    return imgs, classes, colors, sizes, textures, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scdc_text_vision_test_per_class(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', \n",
    "                                        batch_size=32, trials_per_class=500):\n",
    "    \"\"\"\n",
    "    Run Same Class Different Color text-vision test with controlled size and texture.\n",
    "    Returns per-class accuracy results.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Check if model supports text encoding\n",
    "    if model_name in ['resnext', 'dino_s_resnext50']:\n",
    "        print(f\"[WARNING] {model_name} has no text encoder, skipping\")\n",
    "        return {}\n",
    "\n",
    "    # Load model & transform\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    \n",
    "    # Build dataset and extract image embeddings\n",
    "    df = build_synthetic_dataset()\n",
    "    ds = SyntheticImageDataset(df, DATA_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    print(\"Extracting image embeddings...\")\n",
    "    all_img_embs, all_classes, all_colors, all_sizes, all_textures, all_idxs = [], [], [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, colors, sizes, textures, idxs in tqdm(loader, desc=\"Processing images\"):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = extractor.get_img_feature(imgs)\n",
    "            feats = extractor.norm_features(feats).cpu().float()\n",
    "            all_img_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_colors.extend(colors)\n",
    "            all_sizes.extend(sizes)\n",
    "            all_textures.extend(textures)\n",
    "            all_idxs.extend(idxs)\n",
    "    \n",
    "    all_img_embs = torch.cat(all_img_embs, dim=0)\n",
    "    print(f\"Extracted {len(all_img_embs)} image embeddings\")\n",
    "\n",
    "    # Group images by class, size, texture, and color\n",
    "    # For SCDC: class, size, texture are fixed; color varies\n",
    "    class_size_texture_color_idxs = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    idx_to_row = {idx: i for i, idx in enumerate(all_idxs)}\n",
    "    \n",
    "    for i, (idx, cls, col, size, texture) in enumerate(zip(all_idxs, all_classes, all_colors, all_sizes, all_textures)):\n",
    "        class_size_texture_color_idxs[cls][(size, texture)][col].append(idx)\n",
    "\n",
    "    # Get unique classes and colors\n",
    "    unique_classes = list(set(all_classes))\n",
    "    unique_colors = list(set(all_colors))\n",
    "    \n",
    "    print(f\"Found {len(unique_classes)} classes and {len(unique_colors)} colors\")\n",
    "    \n",
    "    # Pre-encode all color+class text combinations\n",
    "    print(\"Encoding text labels for all color-class combinations...\")\n",
    "    text_features_cache = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Create all color+class combinations\n",
    "        text_labels = []\n",
    "        label_keys = []\n",
    "        for cls in unique_classes:\n",
    "            for color in unique_colors:\n",
    "                # Format: \"red apple\", \"green apple\", etc.\n",
    "                label = f\"{color} {cls}\"\n",
    "                text_labels.append(label)\n",
    "                label_keys.append((cls, color))\n",
    "        \n",
    "        # Encode in batches for efficiency\n",
    "        if \"clip\" in model_name:\n",
    "            # CLIP text encoding\n",
    "            tokens = clip.tokenize(text_labels, truncate=True).to(device)\n",
    "            txt_features = model.encode_text(tokens)\n",
    "            txt_features = extractor.norm_features(txt_features).cpu().float()\n",
    "            for i, (cls, color) in enumerate(label_keys):\n",
    "                text_features_cache[(cls, color)] = txt_features[i]\n",
    "        else:  # CVCL\n",
    "            # CVCL text encoding with token length\n",
    "            tokens, token_len = model.tokenize(text_labels)\n",
    "            tokens = tokens.to(device)\n",
    "            if isinstance(token_len, torch.Tensor):\n",
    "                token_len = token_len.to(device)\n",
    "            txt_features = model.encode_text(tokens, token_len)\n",
    "            txt_features = extractor.norm_features(txt_features).cpu().float()\n",
    "            for i, (cls, color) in enumerate(label_keys):\n",
    "                text_features_cache[(cls, color)] = txt_features[i]\n",
    "    \n",
    "    print(f\"Encoded {len(text_features_cache)} color-class text combinations\")\n",
    "\n",
    "    # Track per-class performance\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    print(f\"Running {trials_per_class} trials per class for SCDC task...\")\n",
    "    \n",
    "    # Run trials for each class\n",
    "    for target_class in tqdm(unique_classes, desc=f\"Testing {model_name} SCDC\"):\n",
    "        trials_done = 0\n",
    "        \n",
    "        # For each size-texture combination in this class\n",
    "        for (size, texture), color_dict in class_size_texture_color_idxs[target_class].items():\n",
    "            if trials_done >= trials_per_class:\n",
    "                break\n",
    "            \n",
    "            # Need at least 4 different colors for this class-size-texture combination\n",
    "            available_colors = list(color_dict.keys())\n",
    "            if len(available_colors) < 4:\n",
    "                continue\n",
    "            \n",
    "            # Run multiple trials for this combination\n",
    "            n_trials = min(20, trials_per_class - trials_done)  # More trials per combination\n",
    "            \n",
    "            for _ in range(n_trials):\n",
    "                # Pick target color and 3 distractor colors\n",
    "                selected_colors = random.sample(available_colors, 4)\n",
    "                target_color = selected_colors[0]\n",
    "                distractor_colors = selected_colors[1:4]\n",
    "                \n",
    "                # Pick one image for each color (all same class, size, texture)\n",
    "                target_idx = random.choice(color_dict[target_color])\n",
    "                distractor_idxs = [random.choice(color_dict[col]) for col in distractor_colors]\n",
    "                \n",
    "                # Create 4-way choice: target + 3 distractors\n",
    "                candidates = [target_idx] + distractor_idxs\n",
    "                \n",
    "                # Get image features for all candidates\n",
    "                cand_features = torch.stack([all_img_embs[idx_to_row[idx]] for idx in candidates]).float()\n",
    "                \n",
    "                # Get text feature for target color+class\n",
    "                target_text_feature = text_features_cache[(target_class, target_color)].float()\n",
    "                \n",
    "                # Compute similarity with text encoding\n",
    "                similarities = cand_features @ target_text_feature\n",
    "                \n",
    "                # Check if model correctly identifies target (index 0)\n",
    "                prediction = similarities.argmax().item()\n",
    "                \n",
    "                # Update counts\n",
    "                class_correct[target_class] += int(prediction == 0)\n",
    "                class_total[target_class] += 1\n",
    "                trials_done += 1\n",
    "                \n",
    "                if trials_done >= trials_per_class:\n",
    "                    break\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracies = {}\n",
    "    for cls in unique_classes:\n",
    "        if class_total[cls] > 0:\n",
    "            class_accuracies[cls] = class_correct[cls] / class_total[cls]\n",
    "        else:\n",
    "            class_accuracies[cls] = 0.0\n",
    "    \n",
    "    # Print summary\n",
    "    overall_correct = sum(class_correct.values())\n",
    "    overall_total = sum(class_total.values())\n",
    "    overall_acc = overall_correct / overall_total if overall_total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nSCDC Overall: {overall_correct}/{overall_total} = {overall_acc:.3f}\")\n",
    "    print(f\"Classes tested: {len([c for c in class_accuracies if class_total[c] > 0])}\")\n",
    "    \n",
    "    # Show top and bottom performers\n",
    "    sorted_classes = sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop 5 classes for color discrimination:\")\n",
    "    for cls, acc in sorted_classes[:5]:\n",
    "        print(f\"  {cls}: {acc:.3f} ({class_total[cls]} trials)\")\n",
    "    print(\"\\nBottom 5 classes for color discrimination:\")\n",
    "    for cls, acc in sorted_classes[-5:]:\n",
    "        print(f\"  {cls}: {acc:.3f} ({class_total[cls]} trials)\")\n",
    "    \n",
    "    return class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Found 67 unique classes and 11 unique colors\n",
      "\n",
      "Starting SCDC Text-Vision evaluation:\n",
      "Configuration: 3 seeds × 500 trials/class × 67 classes\n",
      "Task: Same Class Different Color discrimination\n",
      "Control: Size and texture are held constant within each trial\n",
      "Text format: color + class (e.g., 'red apple')\n",
      "\n",
      "\n",
      "============================================================\n",
      "Testing cvcl-resnext with SCDC text-vision approach\n",
      "============================================================\n",
      "\n",
      "Seed 1/3 for cvcl-resnext\n",
      "Loading cvcl-resnext...\n",
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Extracting image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 247/247 [00:20<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7881 image embeddings\n",
      "Found 67 classes and 11 colors\n",
      "Encoding text labels for all color-class combinations...\n",
      "Encoded 737 color-class text combinations\n",
      "Running 500 trials per class for SCDC task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing cvcl-resnext SCDC: 100%|██████████| 67/67 [00:00<00:00, 533.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCDC Overall: 1992/7920 = 0.252\n",
      "Classes tested: 67\n",
      "\n",
      "Top 5 classes for color discrimination:\n",
      "  apple: 0.375 (120 trials)\n",
      "  meat: 0.367 (120 trials)\n",
      "  grill: 0.358 (120 trials)\n",
      "  phone: 0.340 (100 trials)\n",
      "  keyboard: 0.333 (120 trials)\n",
      "\n",
      "Bottom 5 classes for color discrimination:\n",
      "  lantern: 0.192 (120 trials)\n",
      "  babushkadolls: 0.192 (120 trials)\n",
      "  seashell: 0.183 (120 trials)\n",
      "  dumbell: 0.142 (120 trials)\n",
      "  bell: 0.092 (120 trials)\n",
      "  Mean accuracy across classes: 0.252\n",
      "  Classes successfully tested: 67\n",
      "  Waiting 30 seconds before next seed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 2/3 for cvcl-resnext\n",
      "Loading cvcl-resnext...\n",
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_1.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Extracting image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 247/247 [00:27<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7881 image embeddings\n",
      "Found 67 classes and 11 colors\n",
      "Encoding text labels for all color-class combinations...\n",
      "Encoded 737 color-class text combinations\n",
      "Running 500 trials per class for SCDC task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing cvcl-resnext SCDC: 100%|██████████| 67/67 [00:00<00:00, 496.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCDC Overall: 1904/7920 = 0.240\n",
      "Classes tested: 67\n",
      "\n",
      "Top 5 classes for color discrimination:\n",
      "  phone: 0.390 (100 trials)\n",
      "  sodacan: 0.333 (120 trials)\n",
      "  grill: 0.325 (120 trials)\n",
      "  ornament: 0.317 (120 trials)\n",
      "  dresser: 0.300 (120 trials)\n",
      "\n",
      "Bottom 5 classes for color discrimination:\n",
      "  sippycup: 0.183 (120 trials)\n",
      "  bell: 0.158 (120 trials)\n",
      "  seashell: 0.158 (120 trials)\n",
      "  trophy: 0.150 (120 trials)\n",
      "  cookie: 0.142 (120 trials)\n",
      "  Mean accuracy across classes: 0.241\n",
      "  Classes successfully tested: 67\n",
      "  Waiting 30 seconds before next seed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed 3/3 for cvcl-resnext\n",
      "Loading cvcl-resnext...\n",
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding_seed_2.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Extracting image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 247/247 [00:20<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7881 image embeddings\n",
      "Found 67 classes and 11 colors\n",
      "Encoding text labels for all color-class combinations...\n",
      "Encoded 737 color-class text combinations\n",
      "Running 500 trials per class for SCDC task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing cvcl-resnext SCDC: 100%|██████████| 67/67 [00:00<00:00, 513.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCDC Overall: 1847/7920 = 0.233\n",
      "Classes tested: 67\n",
      "\n",
      "Top 5 classes for color discrimination:\n",
      "  phone: 0.360 (100 trials)\n",
      "  handbag: 0.317 (120 trials)\n",
      "  handheldgame: 0.317 (120 trials)\n",
      "  grill: 0.308 (120 trials)\n",
      "  doorknob: 0.300 (120 trials)\n",
      "\n",
      "Bottom 5 classes for color discrimination:\n",
      "  helmet: 0.167 (120 trials)\n",
      "  ring: 0.167 (120 trials)\n",
      "  fan: 0.158 (120 trials)\n",
      "  suitcase: 0.158 (120 trials)\n",
      "  toothpaste: 0.100 (120 trials)\n",
      "  Mean accuracy across classes: 0.233\n",
      "  Classes successfully tested: 67\n",
      "\n",
      "============================================================\n",
      "Testing clip-res with SCDC text-vision approach\n",
      "============================================================\n",
      "\n",
      "Seed 1/3 for clip-res\n",
      "Loading clip-res...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Extracting image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/247 [00:00<?, ?it/s]c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "Processing images: 100%|██████████| 247/247 [00:17<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7881 image embeddings\n",
      "Found 67 classes and 11 colors\n",
      "Encoding text labels for all color-class combinations...\n",
      "Encoded 737 color-class text combinations\n",
      "Running 500 trials per class for SCDC task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing clip-res SCDC: 100%|██████████| 67/67 [00:00<00:00, 445.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCDC Overall: 7648/7920 = 0.966\n",
      "Classes tested: 67\n",
      "\n",
      "Top 5 classes for color discrimination:\n",
      "  ornament: 1.000 (120 trials)\n",
      "  dresser: 1.000 (120 trials)\n",
      "  camera: 1.000 (120 trials)\n",
      "  suitcase: 1.000 (120 trials)\n",
      "  doll: 1.000 (120 trials)\n",
      "\n",
      "Bottom 5 classes for color discrimination:\n",
      "  trophy: 0.900 (120 trials)\n",
      "  axe: 0.883 (120 trials)\n",
      "  pitcher: 0.875 (120 trials)\n",
      "  tennisracquet: 0.850 (40 trials)\n",
      "  basket: 0.767 (120 trials)\n",
      "  Mean accuracy across classes: 0.965\n",
      "  Classes successfully tested: 67\n",
      "\n",
      "Seed 2/3 for clip-res\n",
      "Loading clip-res...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Extracting image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 247/247 [00:16<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7881 image embeddings\n",
      "Found 67 classes and 11 colors\n",
      "Encoding text labels for all color-class combinations...\n",
      "Encoded 737 color-class text combinations\n",
      "Running 500 trials per class for SCDC task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing clip-res SCDC: 100%|██████████| 67/67 [00:00<00:00, 355.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCDC Overall: 7654/7920 = 0.966\n",
      "Classes tested: 67\n",
      "\n",
      "Top 5 classes for color discrimination:\n",
      "  helmet: 1.000 (120 trials)\n",
      "  ornament: 1.000 (120 trials)\n",
      "  dresser: 1.000 (120 trials)\n",
      "  sodacan: 1.000 (120 trials)\n",
      "  apple: 1.000 (120 trials)\n",
      "\n",
      "Bottom 5 classes for color discrimination:\n",
      "  butterfly: 0.900 (120 trials)\n",
      "  lock: 0.892 (120 trials)\n",
      "  trophy: 0.875 (120 trials)\n",
      "  axe: 0.850 (120 trials)\n",
      "  basket: 0.792 (120 trials)\n",
      "  Mean accuracy across classes: 0.966\n",
      "  Classes successfully tested: 67\n",
      "\n",
      "Seed 3/3 for clip-res\n",
      "Loading clip-res...\n",
      "Loading master labels from: C:\\Users\\jbats\\Projects\\NTU-Synthetic\\data\\SyntheticKonkle_224\\master_labels.csv\n",
      "Loaded 7881 images\n",
      "Classes: 67 unique\n",
      "Colors: 11 unique\n",
      "Sizes: 4 unique\n",
      "Textures: 2 unique\n",
      "\n",
      "Average colors per class: 10.0\n",
      "Min colors in a class: 10\n",
      "Max colors in a class: 11\n",
      "Extracting image embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 247/247 [00:17<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 7881 image embeddings\n",
      "Found 67 classes and 11 colors\n",
      "Encoding text labels for all color-class combinations...\n",
      "Encoded 737 color-class text combinations\n",
      "Running 500 trials per class for SCDC task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing clip-res SCDC: 100%|██████████| 67/67 [00:00<00:00, 422.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCDC Overall: 7649/7920 = 0.966\n",
      "Classes tested: 67\n",
      "\n",
      "Top 5 classes for color discrimination:\n",
      "  helmet: 1.000 (120 trials)\n",
      "  microwave: 1.000 (120 trials)\n",
      "  sodacan: 1.000 (120 trials)\n",
      "  saddle: 1.000 (120 trials)\n",
      "  phone: 1.000 (100 trials)\n",
      "\n",
      "Bottom 5 classes for color discrimination:\n",
      "  butterfly: 0.908 (120 trials)\n",
      "  lock: 0.875 (120 trials)\n",
      "  tennisracquet: 0.850 (40 trials)\n",
      "  axe: 0.833 (120 trials)\n",
      "  basket: 0.758 (120 trials)\n",
      "  Mean accuracy across classes: 0.965\n",
      "  Classes successfully tested: 67\n",
      "\n",
      "============================================================\n",
      "SCDC TEXT-VISION EVALUATION COMPLETE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run multiple seeds for statistical analysis\n",
    "n_seeds = 3  # Limited seeds due to potential rate limiting\n",
    "trials_per_class = 500  # Consistent with class discrimination test\n",
    "models_to_test = ['cvcl-resnext', 'clip-res']\n",
    "\n",
    "# Check dataset first\n",
    "test_df = build_synthetic_dataset()\n",
    "n_classes = len(test_df['class'].unique())\n",
    "n_colors = len(test_df['color'].unique())\n",
    "print(f\"Found {n_classes} unique classes and {n_colors} unique colors\")\n",
    "\n",
    "print(f\"\\nStarting SCDC Text-Vision evaluation:\")\n",
    "print(f\"Configuration: {n_seeds} seeds × {trials_per_class} trials/class × {n_classes} classes\")\n",
    "print(f\"Task: Same Class Different Color discrimination\")\n",
    "print(f\"Control: Size and texture are held constant within each trial\")\n",
    "print(f\"Text format: color + class (e.g., 'red apple')\\n\")\n",
    "\n",
    "all_results = {model: defaultdict(list) for model in models_to_test}\n",
    "\n",
    "# Run evaluation\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_name} with SCDC text-vision approach\")\n",
    "    print('='*60)\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        print(f\"\\nSeed {seed+1}/{n_seeds} for {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            class_acc = run_scdc_text_vision_test_per_class(\n",
    "                model_name, \n",
    "                seed=seed, \n",
    "                trials_per_class=trials_per_class\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            for cls, acc in class_acc.items():\n",
    "                all_results[model_name][cls].append(acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if len(class_acc) > 0:\n",
    "                mean_acc = np.mean(list(class_acc.values()))\n",
    "                print(f\"  Mean accuracy across classes: {mean_acc:.3f}\")\n",
    "                print(f\"  Classes successfully tested: {len(class_acc)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            if \"404\" in str(e) or \"rate\" in str(e).lower():\n",
    "                print(f\"  Rate limit hit - waiting 60 seconds...\")\n",
    "                time.sleep(60)\n",
    "                # Retry once\n",
    "                try:\n",
    "                    class_acc = run_scdc_text_vision_test_per_class(\n",
    "                        model_name, seed=seed, trials_per_class=trials_per_class\n",
    "                    )\n",
    "                    for cls, acc in class_acc.items():\n",
    "                        all_results[model_name][cls].append(acc)\n",
    "                    print(f\"  Retry successful!\")\n",
    "                except:\n",
    "                    print(f\"  Retry failed - skipping seed {seed}\")\n",
    "                    continue\n",
    "        \n",
    "        # Add delay between seeds for CVCL\n",
    "        if 'cvcl' in model_name and seed < n_seeds - 1:\n",
    "            print(\"  Waiting 30 seconds before next seed...\")\n",
    "            time.sleep(30)\n",
    "\n",
    "# Calculate statistics\n",
    "stats_results = {}\n",
    "for model_name in models_to_test:\n",
    "    stats_results[model_name] = {}\n",
    "    for cls, accs in all_results[model_name].items():\n",
    "        if len(accs) > 0:\n",
    "            n_samples = len(accs)\n",
    "            stats_results[model_name][cls] = {\n",
    "                'mean': np.mean(accs),\n",
    "                'std': np.std(accs, ddof=1) if n_samples > 1 else 0,\n",
    "                'se': np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'ci95': 1.96 * np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'n_samples': n_samples,\n",
    "                'total_trials': n_samples * trials_per_class,\n",
    "                'raw': accs\n",
    "            }\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCDC TEXT-VISION EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved detailed results to C:\\Users\\jbats\\Projects\\NTU-Synthetic\\PatrickProject\\Chart_Generation\\Textvision\\scdc_textvision_perclass_results.csv\n",
      "Saved summary statistics to C:\\Users\\jbats\\Projects\\NTU-Synthetic\\PatrickProject\\Chart_Generation\\Textvision\\scdc_textvision_perclass_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results\n",
    "detailed_df = []\n",
    "for model_name in models_to_test:\n",
    "    for cls, stats in stats_results[model_name].items():\n",
    "        for seed_idx, acc in enumerate(stats['raw']):\n",
    "            detailed_df.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'seed': seed_idx,\n",
    "                'accuracy': acc,\n",
    "                'n_trials': trials_per_class,\n",
    "                'test_type': 'scdc_text_vision'\n",
    "            })\n",
    "\n",
    "if len(detailed_df) > 0:\n",
    "    detailed_df = pd.DataFrame(detailed_df)\n",
    "    output_path = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass_results.csv')\n",
    "    detailed_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSaved detailed results to {output_path}\")\n",
    "    \n",
    "    # Save summary statistics\n",
    "    summary_stats = []\n",
    "    for model_name in models_to_test:\n",
    "        for cls, stats in stats_results[model_name].items():\n",
    "            summary_stats.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'mean_accuracy': stats['mean'],\n",
    "                'std': stats['std'],\n",
    "                'se': stats['se'],\n",
    "                'ci95': stats['ci95'],\n",
    "                'n_seeds': stats['n_samples'],\n",
    "                'total_trials': stats['total_trials']\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    summary_path = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass_summary.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"Saved summary statistics to {summary_path}\")\n",
    "else:\n",
    "    print(\"\\nNo results to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "if len(stats_results[models_to_test[0]]) > 0:\n",
    "    fig = plt.figure(figsize=(14, 11))\n",
    "    \n",
    "    # Create subplots\n",
    "    ax1 = plt.subplot2grid((20, 1), (0, 0), rowspan=8)\n",
    "    ax2 = plt.subplot2grid((20, 1), (12, 0), rowspan=8)\n",
    "    \n",
    "    # Prepare data\n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    mid_point = len(classes) // 2\n",
    "    classes_first_half = classes[:mid_point]\n",
    "    classes_second_half = classes[mid_point:]\n",
    "    \n",
    "    # Define colors and markers\n",
    "    colors = {\n",
    "        'cvcl-resnext': '#2a9d8f',  # Teal for CVCL\n",
    "        'clip-res': '#e63946'  # Red for CLIP\n",
    "    }\n",
    "    markers = {\n",
    "        'cvcl-resnext': 'o',\n",
    "        'clip-res': 's'\n",
    "    }\n",
    "    avg_line_styles = {\n",
    "        'cvcl-resnext': '--',\n",
    "        'clip-res': '-.'\n",
    "    }\n",
    "    \n",
    "    legend_elements = []\n",
    "    \n",
    "    def plot_on_axis(ax, class_subset, is_first=False):\n",
    "        x_pos = np.arange(len(class_subset))\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            means = [stats_results[model_name][cls]['mean'] * 100 for cls in class_subset]\n",
    "            errors = [stats_results[model_name][cls]['ci95'] * 100 for cls in class_subset]\n",
    "            \n",
    "            ax.errorbar(x_pos, means, yerr=errors,\n",
    "                       label=model_name.upper().replace('-', ' '),\n",
    "                       color=colors[model_name],\n",
    "                       marker=markers[model_name],\n",
    "                       markersize=7,\n",
    "                       linewidth=0,\n",
    "                       capsize=4,\n",
    "                       capthick=1.5,\n",
    "                       alpha=0.9,\n",
    "                       markeredgecolor='black',\n",
    "                       markeredgewidth=0.5)\n",
    "        \n",
    "        # Add chance level\n",
    "        ax.axhline(y=25, color='#ffa500', linestyle=':', alpha=0.8, linewidth=1.5)\n",
    "        \n",
    "        # Calculate overall averages\n",
    "        all_classes_means = {}\n",
    "        for model_name in models_to_test:\n",
    "            all_means = [stats_results[model_name][cls]['mean'] * 100 for cls in classes]\n",
    "            all_classes_means[model_name] = np.mean(all_means)\n",
    "        \n",
    "        # Add average lines\n",
    "        for model_name in models_to_test:\n",
    "            avg_performance = all_classes_means[model_name]\n",
    "            ax.axhline(y=avg_performance,\n",
    "                      color=colors[model_name],\n",
    "                      linestyle=avg_line_styles[model_name],\n",
    "                      alpha=0.7,\n",
    "                      linewidth=2)\n",
    "            \n",
    "            if is_first:\n",
    "                ax.text(len(class_subset) + 0.8, avg_performance,\n",
    "                       f'{avg_performance:.1f}%',\n",
    "                       fontsize=9,\n",
    "                       color=colors[model_name],\n",
    "                       va='center',\n",
    "                       fontweight='bold')\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_ylabel('SCDC Text-Vision Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(class_subset, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_ylim(0, 105)\n",
    "        ax.set_yticks([0, 25, 50, 75, 100])\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_facecolor('#fafafa')\n",
    "        \n",
    "        # Create legend elements\n",
    "        global legend_elements\n",
    "        if is_first:\n",
    "            from matplotlib.lines import Line2D\n",
    "            legend_elements = []\n",
    "            \n",
    "            for model_name in models_to_test:\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], marker=markers[model_name], color='w',\n",
    "                          markerfacecolor=colors[model_name], markeredgecolor='black',\n",
    "                          markersize=8, label=model_name.upper().replace('-', ' '))\n",
    "                )\n",
    "            \n",
    "            for model_name in models_to_test:\n",
    "                avg_val = all_classes_means[model_name]\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color=colors[model_name],\n",
    "                          linestyle=avg_line_styles[model_name], linewidth=2,\n",
    "                          label=f'{model_name.upper().split(\"-\")[0]} Average ({avg_val:.1f}%)')\n",
    "                )\n",
    "            \n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color='#ffa500', linestyle=':', linewidth=1.5,\n",
    "                      label='Chance Level (25%)')\n",
    "            )\n",
    "    \n",
    "    # Plot both halves\n",
    "    plot_on_axis(ax1, classes_first_half, is_first=True)\n",
    "    ax1.set_title('SCDC Text-Vision Per-Class Performance - Part 1\\nSame Class Different Color (Size & Texture Controlled)',\n",
    "                 fontsize=13, fontweight='bold', pad=10)\n",
    "    \n",
    "    plot_on_axis(ax2, classes_second_half, is_first=False)\n",
    "    ax2.set_title('SCDC Text-Vision Per-Class Performance - Part 2',\n",
    "                 fontsize=13, fontweight='bold', pad=10)\n",
    "    ax2.set_xlabel('Target Category', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_ax = fig.add_axes([0.125, 0.44, 0.775, 0.08])\n",
    "    legend_ax.axis('off')\n",
    "    \n",
    "    legend = legend_ax.legend(handles=legend_elements,\n",
    "                             loc='center',\n",
    "                             ncol=3,\n",
    "                             fontsize=10,\n",
    "                             frameon=True,\n",
    "                             fancybox=True,\n",
    "                             shadow=True,\n",
    "                             framealpha=0.95,\n",
    "                             columnspacing=2.5,\n",
    "                             handlelength=3)\n",
    "    \n",
    "    legend.get_frame().set_facecolor('white')\n",
    "    legend.get_frame().set_edgecolor('gray')\n",
    "    legend.get_frame().set_linewidth(1.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    \n",
    "    # Save plots\n",
    "    png_path = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass.png')\n",
    "    pdf_path = os.path.join(RESULTS_DIR, 'scdc_textvision_perclass.pdf')\n",
    "    \n",
    "    plt.savefig(png_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(pdf_path, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved plots to:\")\n",
    "    print(f\"  - {png_path}\")\n",
    "    print(f\"  - {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "if len(stats_results) > 0 and len(stats_results[models_to_test[0]]) > 0:\n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    \n",
    "    summary_data = []\n",
    "    for cls in classes:\n",
    "        row = {'Class': cls}\n",
    "        for model in models_to_test:\n",
    "            if cls in stats_results[model]:\n",
    "                stats = stats_results[model][cls]\n",
    "                row[f\"{model}_mean\"] = f\"{stats['mean']:.3f}\"\n",
    "                row[f\"{model}_ci95\"] = f\"±{stats['ci95']:.3f}\"\n",
    "                row[f\"{model}_trials\"] = stats['total_trials']\n",
    "        \n",
    "        # Add difference if both models have results\n",
    "        if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "            diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "            row['difference'] = f\"{diff:+.3f}\"\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SCDC TEXT-VISION PER-CLASS PERFORMANCE SUMMARY\")\n",
    "    print(\"Task: Same Class Different Color (Size & Texture Controlled)\")\n",
    "    print(\"=\"*80)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL SCDC TEXT-VISION PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for model in models_to_test:\n",
    "        all_accs = []\n",
    "        for cls in classes:\n",
    "            if cls in stats_results[model]:\n",
    "                all_accs.extend(stats_results[model][cls]['raw'])\n",
    "        \n",
    "        if len(all_accs) > 0:\n",
    "            mean = np.mean(all_accs)\n",
    "            std = np.std(all_accs)\n",
    "            se = std / np.sqrt(len(all_accs))\n",
    "            ci95 = 1.96 * se\n",
    "            print(f\"{model}: {mean:.3f} ± {ci95:.3f} (SE: {se:.3f}, n={len(all_accs)} samples)\")\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats as scipy_stats\n",
    "    \n",
    "    cvcl_all = []\n",
    "    clip_all = []\n",
    "    for cls in classes:\n",
    "        if cls in stats_results['cvcl-resnext']:\n",
    "            cvcl_all.extend(stats_results['cvcl-resnext'][cls]['raw'])\n",
    "        if cls in stats_results['clip-res']:\n",
    "            clip_all.extend(stats_results['clip-res'][cls]['raw'])\n",
    "    \n",
    "    if len(cvcl_all) > 0 and len(clip_all) > 0:\n",
    "        t_stat, p_value = scipy_stats.ttest_ind(cvcl_all, clip_all)\n",
    "        print(f\"\\nt-test: t={t_stat:.3f}, p={p_value:.6f}\")\n",
    "        if p_value < 0.001:\n",
    "            print(\"Result: Highly significant difference (p < 0.001)\")\n",
    "        elif p_value < 0.01:\n",
    "            print(\"Result: Significant difference (p < 0.01)\")\n",
    "        elif p_value < 0.05:\n",
    "            print(\"Result: Significant difference (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"Result: No significant difference\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"This test measures how well models can distinguish colors within the same object class.\")\n",
    "    print(\"Size and texture are held constant, so performance reflects pure color discrimination.\")\n",
    "    print(\"Higher scores indicate better color-text alignment within object categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create difference plot\n",
    "if len(stats_results) > 0 and len(stats_results[models_to_test[0]]) > 0:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    differences = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "            diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "            differences.append(diff)\n",
    "        else:\n",
    "            differences.append(0)\n",
    "    \n",
    "    colors_diff = ['#2ecc71' if d > 0 else '#e74c3c' for d in differences]\n",
    "    bars = plt.bar(range(len(classes)), differences, color=colors_diff, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (cls, diff) in enumerate(zip(classes, differences)):\n",
    "        if diff != 0:\n",
    "            plt.text(i, diff + (0.01 if diff > 0 else -0.02), f'{diff:.2f}',\n",
    "                    ha='center', va='bottom' if diff > 0 else 'top', fontsize=8)\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    plt.xlabel('Object Class', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Performance Difference\\n(CLIP - CVCL)', fontsize=12, fontweight='bold')\n",
    "    plt.title('SCDC Text-Vision Model Performance Differences by Class\\nColor Discrimination within Same Class',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#2ecc71', alpha=0.7, label='CLIP Better'),\n",
    "        Patch(facecolor='#e74c3c', alpha=0.7, label='CVCL Better')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    diff_plot_path = os.path.join(RESULTS_DIR, 'scdc_textvision_difference.png')\n",
    "    plt.savefig(diff_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved difference plot to {diff_plot_path}\")\n",
    "    \n",
    "    # Print summary of differences\n",
    "    clip_better = sum(1 for d in differences if d > 0)\n",
    "    cvcl_better = sum(1 for d in differences if d < 0)\n",
    "    tied = sum(1 for d in differences if d == 0)\n",
    "    \n",
    "    print(f\"\\nSummary for SCDC (Color Discrimination):\")\n",
    "    print(f\"  CLIP performs better: {clip_better}/{len(classes)} classes\")\n",
    "    print(f\"  CVCL performs better: {cvcl_better}/{len(classes)} classes\")\n",
    "    if tied > 0:\n",
    "        print(f\"  No difference: {tied}/{len(classes)} classes\")\n",
    "    \n",
    "    avg_diff = np.mean([d for d in differences if d != 0])\n",
    "    print(f\"  Average difference: {avg_diff:.3f}\")\n",
    "    print(f\"\\nNote: This measures color discrimination ability within the same object class.\")\n",
    "    print(f\"Higher values suggest better color-text understanding.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
