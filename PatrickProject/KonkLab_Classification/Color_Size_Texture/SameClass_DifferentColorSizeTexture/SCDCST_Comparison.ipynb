{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Class Different Color, Size and Texture (SCDCST) Comparison\n",
    "\n",
    "This notebook compares CVCL and CLIP models on prototype evaluation where distractors are the same class but differ in color, size, AND texture.\n",
    "For example, testing a big rough red apple against small smooth green apple, medium shiny yellow apple, tiny matte blue apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ------------------------------- ------- 10.5/12.8 MB 65.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 66.7 MB/s  0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\clip\\clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "# Add discover-hidden-visual-concepts to path\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "from models.multimodal.multimodal_lit import MultiModalLitModel\n",
    "\n",
    "# hard-coded paths\n",
    "CSV_PATH = os.path.join(REPO_ROOT, 'data', 'KonkLab', 'testdata.csv')\n",
    "IMG_DIR = os.path.join(REPO_ROOT, 'data', 'KonkLab', '17-objects')\n",
    "MASTER_CSV = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'all_prototype_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Dataset and Helper Functions\n",
    "class CSTImageDataset(Dataset):\n",
    "    \"\"\"Dataset returning (img_tensor, class, color, size, texture, idx).\"\"\"\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        required = ['Filename','Class','Color','Size','Texture']\n",
    "        assert all(c in self.df for c in required), f\"CSV must contain columns: {required}\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        cls, col, sz, tex = row['Class'], row['Color'], row['Size'], row['Texture']\n",
    "        fn = row['Filename']\n",
    "        path = os.path.join(self.img_dir, cls, fn)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img), cls, col, sz, tex, idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    colors = [b[2] for b in batch]\n",
    "    sizes = [b[3] for b in batch]\n",
    "    textures = [b[4] for b in batch]\n",
    "    idxs = [b[5] for b in batch]\n",
    "    return imgs, classes, colors, sizes, textures, idxs\n",
    "\n",
    "def run_scdcst_test(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', batch_size=64, trials_per_tuple=10, max_images=None):\n",
    "    \"\"\"Run Same Class Different Color, Size and Texture (SCDCST) evaluation.\"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # 1) load model & transform\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    print(f\"[INFO] Loaded model '{model_name}'\")\n",
    "\n",
    "    # 2) prepare DataLoader & extract embeddings\n",
    "    ds = CSTImageDataset(CSV_PATH, IMG_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    all_embs, all_meta, all_idxs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, colors, sizes, textures, idxs in loader:\n",
    "            feats = extractor.get_img_feature(imgs.to(device))\n",
    "            feats = extractor.norm_features(feats).cpu()\n",
    "            feats = feats.float()\n",
    "            all_embs.append(feats)\n",
    "            all_meta.extend(zip(classes, colors, sizes, textures))\n",
    "            all_idxs.extend(idxs)\n",
    "    all_embs = torch.cat(all_embs, dim=0)\n",
    "    print(f\"[INFO] Extracted embeddings for {len(all_idxs)} images\")\n",
    "\n",
    "    # 3) group by full 4-tuple\n",
    "    tuple2idxs = defaultdict(list)\n",
    "    for idx, meta in zip(all_idxs, all_meta):\n",
    "        tuple2idxs[meta].append(idx)\n",
    "\n",
    "    # 4) run evaluation\n",
    "    total_correct = 0\n",
    "    total_trials = 0\n",
    "    tuple_results = {}\n",
    "    \n",
    "    print(\"[INFO] Running 4-way trials: distractors share class but differ in color, size & texture\")\n",
    "    for (cls, col, sz, tex), idx_list in tuple2idxs.items():\n",
    "        # Get pool: SAME class but different color, size, AND texture\n",
    "        distractor_pool = [i for m, i in zip(all_meta, all_idxs) if m[0]==cls and m[1]!=col and m[2]!=sz and m[3]!=tex]\n",
    "        \n",
    "        if len(idx_list) < 1 or len(distractor_pool) < 3:\n",
    "            continue\n",
    "\n",
    "        correct = 0\n",
    "        for _ in range(trials_per_tuple):\n",
    "            q = random.choice(idx_list)\n",
    "            same_rest = [i for i in idx_list if i != q]\n",
    "            if same_rest:\n",
    "                proto = all_embs[[all_idxs.index(i) for i in same_rest]].mean(0)\n",
    "            else:\n",
    "                proto = all_embs[all_idxs.index(q)]\n",
    "            proto = proto / proto.norm()\n",
    "\n",
    "            distractors = random.sample(distractor_pool, 3)\n",
    "            candidates = [q] + distractors\n",
    "            feats_cand = all_embs[[all_idxs.index(i) for i in candidates]]\n",
    "            sims = feats_cand @ proto\n",
    "            guess = candidates[sims.argmax().item()]\n",
    "\n",
    "            correct += int(guess == q)\n",
    "            total_correct += int(guess == q)\n",
    "            total_trials += 1\n",
    "\n",
    "        acc = correct / trials_per_tuple\n",
    "        key = f\"{cls}-{col}-{sz}-{tex}\"\n",
    "        tuple_results[key] = {'correct': correct, 'trials': trials_per_tuple, 'accuracy': acc}\n",
    "        print(f\"{cls:12s} / {col:10s} / {sz:6s} / {tex:10s} : {correct}/{trials_per_tuple} ({acc:.1%})\")\n",
    "\n",
    "    overall_acc = total_correct / total_trials if total_trials else 0.0\n",
    "    print(f\"\\n[OK] Overall accuracy: {total_correct}/{total_trials} ({overall_acc:.1%})\")\n",
    "    \n",
    "    # 5) save results\n",
    "    summary_df = pd.DataFrame([{'Model': model_name, 'Test': 'Same-Class-Different-Color-Size-Texture', 'Correct': total_correct, 'Trials': total_trials, 'Accuracy': overall_acc}])\n",
    "    \n",
    "    os.makedirs(os.path.dirname(MASTER_CSV), exist_ok=True)\n",
    "    if os.path.exists(MASTER_CSV):\n",
    "        summary_df.to_csv(MASTER_CSV, mode='a', header=False, index=False, float_format='%.4f')\n",
    "    else:\n",
    "        summary_df.to_csv(MASTER_CSV, index=False, float_format='%.4f')\n",
    "\n",
    "    return tuple_results, overall_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVCL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model 'cvcl-resnext'\n",
      "[INFO] Extracted embeddings for 1005 images\n",
      "[INFO] Running 4-way trials: distractors share class but differ in color, size & texture\n",
      "pitcher      / Multicolored / Large  / textured   : 10/10 (100.0%)\n",
      "headband     / Purple     / Medium / smooth     : 10/10 (100.0%)\n",
      "headband     / Red        / Small  / textured   : 10/10 (100.0%)\n",
      "headband     / Pink       / Small  / textured   : 10/10 (100.0%)\n",
      "grill        / Black      / Small  / textured   : 10/10 (100.0%)\n",
      "bell         / Multicolored / Medium / smooth     : 10/10 (100.0%)\n",
      "stapler      / Red        / Medium / textured   : 10/10 (100.0%)\n",
      "stapler      / Multicolored / Small  / smooth     : 4/10 (40.0%)\n",
      "stapler      / Blue       / Medium / textured   : 10/10 (100.0%)\n",
      "stapler      / Grey       / Medium / textured   : 10/10 (100.0%)\n",
      "exercise_equipment / Grey       / Medium / textured   : 10/10 (100.0%)\n",
      "exercise_equipment / Black      / Medium / textured   : 10/10 (100.0%)\n",
      "doorknob     / Yellow     / Large  / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Grey       / Medium / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Yellow     / Small  / textured   : 10/10 (100.0%)\n",
      "doorknob     / Red        / Small  / textured   : 10/10 (100.0%)\n",
      "doorknob     / Yellow     / Small  / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Orange     / Medium / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Multicolored / Medium / smooth     : 0/10 (0.0%)\n",
      "doorknob     / Yellow     / Large  / textured   : 10/10 (100.0%)\n",
      "saddle       / Grey       / Medium / smooth     : 10/10 (100.0%)\n",
      "stool        / Yellow     / Medium / textured   : 10/10 (100.0%)\n",
      "stool        / Grey       / Small  / smooth     : 6/10 (60.0%)\n",
      "candleholderwithcandle / Orange     / Medium / textured   : 10/10 (100.0%)\n",
      "lock         / Orange     / Medium / textured   : 10/10 (100.0%)\n",
      "lock         / Yellow     / Medium / textured   : 10/10 (100.0%)\n",
      "lock         / Multicolored / Small  / smooth     : 10/10 (100.0%)\n",
      "lock         / Grey       / Large  / smooth     : 10/10 (100.0%)\n",
      "goggle       / Grey       / Small  / smooth     : 10/10 (100.0%)\n",
      "goggle       / Yellow     / Small  / textured   : 10/10 (100.0%)\n",
      "toyhorse     / Orange     / Medium / smooth     : 10/10 (100.0%)\n",
      "saltpeppershake / Yellow     / Large  / textured   : 10/10 (100.0%)\n",
      "wineglass    / Multicolored / Medium / smooth     : 10/10 (100.0%)\n",
      "pipe         / Multicolored / Medium / textured   : 10/10 (100.0%)\n",
      "telescope    / Multicolored / Medium / textured   : 10/10 (100.0%)\n",
      "\n",
      "[OK] Overall accuracy: 330/350 (94.3%)\n",
      "\n",
      "CVCL Results by Class-Color-Size-Texture:\n",
      "pitcher-Multicolored-Large-textured     : 10/10 (100.0%)\n",
      "headband-Purple-Medium-smooth           : 10/10 (100.0%)\n",
      "headband-Red-Small-textured             : 10/10 (100.0%)\n",
      "headband-Pink-Small-textured            : 10/10 (100.0%)\n",
      "grill-Black-Small-textured              : 10/10 (100.0%)\n",
      "bell-Multicolored-Medium-smooth         : 10/10 (100.0%)\n",
      "stapler-Red-Medium-textured             : 10/10 (100.0%)\n",
      "stapler-Multicolored-Small-smooth       : 4/10 (40.0%)\n",
      "stapler-Blue-Medium-textured            : 10/10 (100.0%)\n",
      "stapler-Grey-Medium-textured            : 10/10 (100.0%)\n",
      "exercise_equipment-Grey-Medium-textured : 10/10 (100.0%)\n",
      "exercise_equipment-Black-Medium-textured: 10/10 (100.0%)\n",
      "doorknob-Yellow-Large-smooth            : 10/10 (100.0%)\n",
      "doorknob-Grey-Medium-smooth             : 10/10 (100.0%)\n",
      "doorknob-Yellow-Small-textured          : 10/10 (100.0%)\n",
      "doorknob-Red-Small-textured             : 10/10 (100.0%)\n",
      "doorknob-Yellow-Small-smooth            : 10/10 (100.0%)\n",
      "doorknob-Orange-Medium-smooth           : 10/10 (100.0%)\n",
      "doorknob-Multicolored-Medium-smooth     : 0/10 (0.0%)\n",
      "doorknob-Yellow-Large-textured          : 10/10 (100.0%)\n",
      "saddle-Grey-Medium-smooth               : 10/10 (100.0%)\n",
      "stool-Yellow-Medium-textured            : 10/10 (100.0%)\n",
      "stool-Grey-Small-smooth                 : 6/10 (60.0%)\n",
      "candleholderwithcandle-Orange-Medium-textured: 10/10 (100.0%)\n",
      "lock-Orange-Medium-textured             : 10/10 (100.0%)\n",
      "lock-Yellow-Medium-textured             : 10/10 (100.0%)\n",
      "lock-Multicolored-Small-smooth          : 10/10 (100.0%)\n",
      "lock-Grey-Large-smooth                  : 10/10 (100.0%)\n",
      "goggle-Grey-Small-smooth                : 10/10 (100.0%)\n",
      "goggle-Yellow-Small-textured            : 10/10 (100.0%)\n",
      "toyhorse-Orange-Medium-smooth           : 10/10 (100.0%)\n",
      "saltpeppershake-Yellow-Large-textured   : 10/10 (100.0%)\n",
      "wineglass-Multicolored-Medium-smooth    : 10/10 (100.0%)\n",
      "pipe-Multicolored-Medium-textured       : 10/10 (100.0%)\n",
      "telescope-Multicolored-Medium-textured  : 10/10 (100.0%)\n",
      "\n",
      "CVCL Overall Accuracy: 94.3%\n"
     ]
    }
   ],
   "source": [
    "# Run CVCL evaluation\n",
    "cvcl_results, cvcl_overall = run_scdcst_test('cvcl-resnext')\n",
    "\n",
    "print(\"\\nCVCL Results by Class-Color-Size-Texture:\")\n",
    "for key, res in cvcl_results.items():\n",
    "    print(f\"{key:40s}: {res['correct']}/{res['trials']} ({res['accuracy']:.1%})\")\n",
    "print(f\"\\nCVCL Overall Accuracy: {cvcl_overall:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model 'clip-resnext'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracted embeddings for 1005 images\n",
      "[INFO] Running 4-way trials: distractors share class but differ in color, size & texture\n",
      "pitcher      / Multicolored / Large  / textured   : 10/10 (100.0%)\n",
      "headband     / Purple     / Medium / smooth     : 10/10 (100.0%)\n",
      "headband     / Red        / Small  / textured   : 10/10 (100.0%)\n",
      "headband     / Pink       / Small  / textured   : 10/10 (100.0%)\n",
      "grill        / Black      / Small  / textured   : 10/10 (100.0%)\n",
      "bell         / Multicolored / Medium / smooth     : 10/10 (100.0%)\n",
      "stapler      / Red        / Medium / textured   : 10/10 (100.0%)\n",
      "stapler      / Multicolored / Small  / smooth     : 9/10 (90.0%)\n",
      "stapler      / Blue       / Medium / textured   : 10/10 (100.0%)\n",
      "stapler      / Grey       / Medium / textured   : 10/10 (100.0%)\n",
      "exercise_equipment / Grey       / Medium / textured   : 10/10 (100.0%)\n",
      "exercise_equipment / Black      / Medium / textured   : 10/10 (100.0%)\n",
      "doorknob     / Yellow     / Large  / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Grey       / Medium / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Yellow     / Small  / textured   : 10/10 (100.0%)\n",
      "doorknob     / Red        / Small  / textured   : 10/10 (100.0%)\n",
      "doorknob     / Yellow     / Small  / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Orange     / Medium / smooth     : 10/10 (100.0%)\n",
      "doorknob     / Multicolored / Medium / smooth     : 0/10 (0.0%)\n",
      "doorknob     / Yellow     / Large  / textured   : 10/10 (100.0%)\n",
      "saddle       / Grey       / Medium / smooth     : 10/10 (100.0%)\n",
      "stool        / Yellow     / Medium / textured   : 10/10 (100.0%)\n",
      "stool        / Grey       / Small  / smooth     : 6/10 (60.0%)\n",
      "candleholderwithcandle / Orange     / Medium / textured   : 10/10 (100.0%)\n",
      "lock         / Orange     / Medium / textured   : 10/10 (100.0%)\n",
      "lock         / Yellow     / Medium / textured   : 10/10 (100.0%)\n",
      "lock         / Multicolored / Small  / smooth     : 10/10 (100.0%)\n",
      "lock         / Grey       / Large  / smooth     : 10/10 (100.0%)\n",
      "goggle       / Grey       / Small  / smooth     : 10/10 (100.0%)\n",
      "goggle       / Yellow     / Small  / textured   : 10/10 (100.0%)\n",
      "toyhorse     / Orange     / Medium / smooth     : 10/10 (100.0%)\n",
      "saltpeppershake / Yellow     / Large  / textured   : 10/10 (100.0%)\n",
      "wineglass    / Multicolored / Medium / smooth     : 10/10 (100.0%)\n",
      "pipe         / Multicolored / Medium / textured   : 10/10 (100.0%)\n",
      "telescope    / Multicolored / Medium / textured   : 10/10 (100.0%)\n",
      "\n",
      "[OK] Overall accuracy: 335/350 (95.7%)\n",
      "\n",
      "CLIP Results by Class-Color-Size-Texture:\n",
      "pitcher-Multicolored-Large-textured     : 10/10 (100.0%)\n",
      "headband-Purple-Medium-smooth           : 10/10 (100.0%)\n",
      "headband-Red-Small-textured             : 10/10 (100.0%)\n",
      "headband-Pink-Small-textured            : 10/10 (100.0%)\n",
      "grill-Black-Small-textured              : 10/10 (100.0%)\n",
      "bell-Multicolored-Medium-smooth         : 10/10 (100.0%)\n",
      "stapler-Red-Medium-textured             : 10/10 (100.0%)\n",
      "stapler-Multicolored-Small-smooth       : 9/10 (90.0%)\n",
      "stapler-Blue-Medium-textured            : 10/10 (100.0%)\n",
      "stapler-Grey-Medium-textured            : 10/10 (100.0%)\n",
      "exercise_equipment-Grey-Medium-textured : 10/10 (100.0%)\n",
      "exercise_equipment-Black-Medium-textured: 10/10 (100.0%)\n",
      "doorknob-Yellow-Large-smooth            : 10/10 (100.0%)\n",
      "doorknob-Grey-Medium-smooth             : 10/10 (100.0%)\n",
      "doorknob-Yellow-Small-textured          : 10/10 (100.0%)\n",
      "doorknob-Red-Small-textured             : 10/10 (100.0%)\n",
      "doorknob-Yellow-Small-smooth            : 10/10 (100.0%)\n",
      "doorknob-Orange-Medium-smooth           : 10/10 (100.0%)\n",
      "doorknob-Multicolored-Medium-smooth     : 0/10 (0.0%)\n",
      "doorknob-Yellow-Large-textured          : 10/10 (100.0%)\n",
      "saddle-Grey-Medium-smooth               : 10/10 (100.0%)\n",
      "stool-Yellow-Medium-textured            : 10/10 (100.0%)\n",
      "stool-Grey-Small-smooth                 : 6/10 (60.0%)\n",
      "candleholderwithcandle-Orange-Medium-textured: 10/10 (100.0%)\n",
      "lock-Orange-Medium-textured             : 10/10 (100.0%)\n",
      "lock-Yellow-Medium-textured             : 10/10 (100.0%)\n",
      "lock-Multicolored-Small-smooth          : 10/10 (100.0%)\n",
      "lock-Grey-Large-smooth                  : 10/10 (100.0%)\n",
      "goggle-Grey-Small-smooth                : 10/10 (100.0%)\n",
      "goggle-Yellow-Small-textured            : 10/10 (100.0%)\n",
      "toyhorse-Orange-Medium-smooth           : 10/10 (100.0%)\n",
      "saltpeppershake-Yellow-Large-textured   : 10/10 (100.0%)\n",
      "wineglass-Multicolored-Medium-smooth    : 10/10 (100.0%)\n",
      "pipe-Multicolored-Medium-textured       : 10/10 (100.0%)\n",
      "telescope-Multicolored-Medium-textured  : 10/10 (100.0%)\n",
      "\n",
      "CLIP Overall Accuracy: 95.7%\n"
     ]
    }
   ],
   "source": [
    "# Run CLIP evaluation\n",
    "clip_results, clip_overall = run_scdcst_test('clip-resnext')\n",
    "\n",
    "print(\"\\nCLIP Results by Class-Color-Size-Texture:\")\n",
    "for key, res in clip_results.items():\n",
    "    print(f\"{key:40s}: {res['correct']}/{res['trials']} ({res['accuracy']:.1%})\")\n",
    "print(f\"\\nCLIP Overall Accuracy: {clip_overall:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
