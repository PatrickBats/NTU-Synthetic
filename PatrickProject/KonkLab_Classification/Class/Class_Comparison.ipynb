{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------- ----- 11.0/12.8 MB 68.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 66.7 MB/s  0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVCL vs CLIP Classification Comparison\n",
    "\n",
    "This notebook compares the classification performance of CVCL and CLIP models on the KonkLab dataset using prototype-based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# ─── Path setup ───\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "# Add discover-hidden-visual-concepts to path\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "from models.multimodal.multimodal_lit import MultiModalLitModel\n",
    "\n",
    "# ─── hard-coded paths ───\n",
    "CSV_PATH = os.path.join(REPO_ROOT, 'data', 'KonkLab', 'testdata.csv')\n",
    "IMG_DIR = os.path.join(REPO_ROOT, 'data', 'KonkLab', '17-objects')\n",
    "MASTER_CSV = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'all_prototype_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Dataset and Helper Functions\n",
    "class ClassImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        assert 'Filename' in self.df and 'Class' in self.df, \\\n",
    "            \"CSV needs Filename and Class columns\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        cls, fn = row['Class'], row['Filename']\n",
    "        path = os.path.join(self.img_dir, cls, fn)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img), cls, idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    idxs = [b[2] for b in batch]\n",
    "    return imgs, classes, idxs\n",
    "\n",
    "def run_classification_test(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                          batch_size=64, trials_per_class=10, max_images=None):\n",
    "    \"\"\"\n",
    "    Run 4-way classification test using prototype evaluation.\n",
    "    Returns accuracy per class and overall accuracy.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # 1) load model & transform\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "\n",
    "    # 2) optionally subsample CSV\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    if max_images and len(df) > max_images:\n",
    "        df = df.sample(n=max_images, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # 3) load data + extract embeddings\n",
    "    ds = ClassImageDataset(CSV_PATH, IMG_DIR, transform)\n",
    "    # Using single-process data loading to avoid worker issues\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False,\n",
    "                   num_workers=0, collate_fn=collate_fn)\n",
    "    \n",
    "    all_embs, all_classes, all_idxs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, idxs in dl:\n",
    "            feats = extractor.get_img_feature(imgs.to(device))\n",
    "            feats = extractor.norm_features(feats).cpu().float()\n",
    "            all_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_idxs.extend(idxs)\n",
    "    all_embs = torch.cat(all_embs, dim=0)\n",
    "\n",
    "    # 4) build maps for prototype eval\n",
    "    idx2class = {i:c for i,c in zip(all_idxs, all_classes)}\n",
    "    idx2row = {i:r for r,i in enumerate(all_idxs)}\n",
    "    class2idxs = {}\n",
    "    for i,c in idx2class.items():\n",
    "        class2idxs.setdefault(c, []).append(i)\n",
    "\n",
    "    # 5) run 4-way trials\n",
    "    class_results = {}\n",
    "    total_correct = 0\n",
    "    total_trials = 0\n",
    "    \n",
    "    for cls, idxs in class2idxs.items():\n",
    "        if len(idxs) < 2:\n",
    "            continue\n",
    "        correct = 0\n",
    "        for _ in range(trials_per_class):\n",
    "            # query\n",
    "            q = random.choice(idxs)\n",
    "            # prototype over other same-class images\n",
    "            proto_idxs = [i for i in idxs if i != q]\n",
    "            proto = all_embs[[idx2row[i] for i in proto_idxs]].mean(0)\n",
    "            proto = proto / proto.norm()\n",
    "            # distractors\n",
    "            others = [i for i in all_idxs if idx2class[i] != cls]\n",
    "            distractors = random.sample(others, 3)\n",
    "            cands = [q] + distractors\n",
    "            sims = (all_embs[[idx2row[i] for i in cands]] @ proto)\n",
    "            guess = cands[sims.argmax().item()]\n",
    "            if guess == q:\n",
    "                correct += 1\n",
    "            total_correct += int(guess == q)\n",
    "            total_trials += 1\n",
    "\n",
    "        acc = correct / trials_per_class\n",
    "        class_results[cls] = {'correct': correct, 'trials': trials_per_class, 'accuracy': acc}\n",
    "\n",
    "    overall_acc = total_correct / total_trials if total_trials else 0.0\n",
    "    \n",
    "    # 6) save results\n",
    "    summary_df = pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'Test': 'Class-Prototype',\n",
    "        'Correct': total_correct,\n",
    "        'Trials': total_trials,\n",
    "        'Accuracy': overall_acc\n",
    "    }])\n",
    "    \n",
    "    os.makedirs(os.path.dirname(MASTER_CSV), exist_ok=True)\n",
    "    if os.path.exists(MASTER_CSV):\n",
    "        summary_df.to_csv(MASTER_CSV, mode='a', header=False, index=False, float_format='%.4f')\n",
    "    else:\n",
    "        summary_df.to_csv(MASTER_CSV, index=False, float_format='%.4f')\n",
    "\n",
    "    return class_results, overall_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVCL Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CVCL Results per Class:\n",
      "butterfly           : 10/10 (100.0%)\n",
      "muffins             : 10/10 (100.0%)\n",
      "pitcher             : 6/10 (60.0%)\n",
      "tennisracquet       : 10/10 (100.0%)\n",
      "phone               : 8/10 (80.0%)\n",
      "headband            : 7/10 (70.0%)\n",
      "bagel               : 10/10 (100.0%)\n",
      "grill               : 9/10 (90.0%)\n",
      "basket              : 10/10 (100.0%)\n",
      "bell                : 9/10 (90.0%)\n",
      "sodacan             : 10/10 (100.0%)\n",
      "microwave           : 10/10 (100.0%)\n",
      "trophy              : 4/10 (40.0%)\n",
      "fan                 : 9/10 (90.0%)\n",
      "lei                 : 8/10 (80.0%)\n",
      "stapler             : 8/10 (80.0%)\n",
      "exercise_equipment  : 7/10 (70.0%)\n",
      "handgun             : 10/10 (100.0%)\n",
      "seashell            : 10/10 (100.0%)\n",
      "powerstrip          : 9/10 (90.0%)\n",
      "lipstick            : 10/10 (100.0%)\n",
      "lantern             : 10/10 (100.0%)\n",
      "doorknob            : 10/10 (100.0%)\n",
      "abacus              : 10/10 (100.0%)\n",
      "jack-o-lantern      : 10/10 (100.0%)\n",
      "camcorder           : 10/10 (100.0%)\n",
      "bird                : 7/10 (70.0%)\n",
      "saddle              : 10/10 (100.0%)\n",
      "handbag             : 7/10 (70.0%)\n",
      "stool               : 6/10 (60.0%)\n",
      "toyrabbit           : 10/10 (100.0%)\n",
      "candleholderwithcandle: 6/10 (60.0%)\n",
      "cushion             : 6/10 (60.0%)\n",
      "lock                : 8/10 (80.0%)\n",
      "train               : 6/10 (60.0%)\n",
      "bonzai              : 9/10 (90.0%)\n",
      "ring                : 5/10 (50.0%)\n",
      "goggle              : 10/10 (100.0%)\n",
      "trumpet             : 10/10 (100.0%)\n",
      "vase                : 6/10 (60.0%)\n",
      "axe                 : 10/10 (100.0%)\n",
      "tricycle            : 10/10 (100.0%)\n",
      "toothpaste          : 9/10 (90.0%)\n",
      "nailpolish          : 10/10 (100.0%)\n",
      "calculator          : 10/10 (100.0%)\n",
      "pen                 : 10/10 (100.0%)\n",
      "tree                : 9/10 (90.0%)\n",
      "earings             : 9/10 (90.0%)\n",
      "toyhorse            : 10/10 (100.0%)\n",
      "gamehandheld        : 10/10 (100.0%)\n",
      "apple               : 10/10 (100.0%)\n",
      "babushkadolls       : 10/10 (100.0%)\n",
      "saltpeppershake     : 9/10 (90.0%)\n",
      "dresser             : 10/10 (100.0%)\n",
      "rug                 : 9/10 (90.0%)\n",
      "wineglass           : 9/10 (90.0%)\n",
      "breadloaf           : 7/10 (70.0%)\n",
      "keyboard            : 10/10 (100.0%)\n",
      "meat                : 10/10 (100.0%)\n",
      "sippycup            : 10/10 (100.0%)\n",
      "cookie              : 8/10 (80.0%)\n",
      "helmet              : 8/10 (80.0%)\n",
      "doll                : 10/10 (100.0%)\n",
      "pipe                : 10/10 (100.0%)\n",
      "christmastreeornamantball: 8/10 (80.0%)\n",
      "telescope           : 10/10 (100.0%)\n",
      "suitcase            : 5/10 (50.0%)\n",
      "\n",
      "CVCL Overall Accuracy: 88.1%\n"
     ]
    }
   ],
   "source": [
    "# Run CVCL classification\n",
    "cvcl_results, cvcl_overall = run_classification_test('cvcl-resnext')\n",
    "\n",
    "print(\"\\nCVCL Results per Class:\")\n",
    "for cls, res in cvcl_results.items():\n",
    "    print(f\"{cls:20s}: {res['correct']}/{res['trials']} ({res['accuracy']:.1%})\")\n",
    "print(f\"\\nCVCL Overall Accuracy: {cvcl_overall:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLIP Results per Class:\n",
      "butterfly           : 10/10 (100.0%)\n",
      "muffins             : 10/10 (100.0%)\n",
      "pitcher             : 10/10 (100.0%)\n",
      "tennisracquet       : 10/10 (100.0%)\n",
      "phone               : 10/10 (100.0%)\n",
      "headband            : 10/10 (100.0%)\n",
      "bagel               : 10/10 (100.0%)\n",
      "grill               : 10/10 (100.0%)\n",
      "basket              : 10/10 (100.0%)\n",
      "bell                : 7/10 (70.0%)\n",
      "sodacan             : 10/10 (100.0%)\n",
      "microwave           : 10/10 (100.0%)\n",
      "trophy              : 10/10 (100.0%)\n",
      "fan                 : 10/10 (100.0%)\n",
      "lei                 : 10/10 (100.0%)\n",
      "stapler             : 9/10 (90.0%)\n",
      "exercise_equipment  : 10/10 (100.0%)\n",
      "handgun             : 10/10 (100.0%)\n",
      "seashell            : 10/10 (100.0%)\n",
      "powerstrip          : 10/10 (100.0%)\n",
      "lipstick            : 10/10 (100.0%)\n",
      "lantern             : 10/10 (100.0%)\n",
      "doorknob            : 10/10 (100.0%)\n",
      "abacus              : 10/10 (100.0%)\n",
      "jack-o-lantern      : 10/10 (100.0%)\n",
      "camcorder           : 10/10 (100.0%)\n",
      "bird                : 10/10 (100.0%)\n",
      "saddle              : 10/10 (100.0%)\n",
      "handbag             : 8/10 (80.0%)\n",
      "stool               : 10/10 (100.0%)\n",
      "toyrabbit           : 10/10 (100.0%)\n",
      "candleholderwithcandle: 10/10 (100.0%)\n",
      "cushion             : 9/10 (90.0%)\n",
      "lock                : 10/10 (100.0%)\n",
      "train               : 10/10 (100.0%)\n",
      "bonzai              : 10/10 (100.0%)\n",
      "ring                : 8/10 (80.0%)\n",
      "goggle              : 10/10 (100.0%)\n",
      "trumpet             : 10/10 (100.0%)\n",
      "vase                : 10/10 (100.0%)\n",
      "axe                 : 10/10 (100.0%)\n",
      "tricycle            : 10/10 (100.0%)\n",
      "toothpaste          : 10/10 (100.0%)\n",
      "nailpolish          : 10/10 (100.0%)\n",
      "calculator          : 10/10 (100.0%)\n",
      "pen                 : 10/10 (100.0%)\n",
      "tree                : 10/10 (100.0%)\n",
      "earings             : 10/10 (100.0%)\n",
      "toyhorse            : 10/10 (100.0%)\n",
      "gamehandheld        : 10/10 (100.0%)\n",
      "apple               : 10/10 (100.0%)\n",
      "babushkadolls       : 10/10 (100.0%)\n",
      "saltpeppershake     : 10/10 (100.0%)\n",
      "dresser             : 10/10 (100.0%)\n",
      "rug                 : 10/10 (100.0%)\n",
      "wineglass           : 10/10 (100.0%)\n",
      "breadloaf           : 10/10 (100.0%)\n",
      "keyboard            : 10/10 (100.0%)\n",
      "meat                : 10/10 (100.0%)\n",
      "sippycup            : 9/10 (90.0%)\n",
      "cookie              : 9/10 (90.0%)\n",
      "helmet              : 10/10 (100.0%)\n",
      "doll                : 10/10 (100.0%)\n",
      "pipe                : 10/10 (100.0%)\n",
      "christmastreeornamantball: 10/10 (100.0%)\n",
      "telescope           : 10/10 (100.0%)\n",
      "suitcase            : 10/10 (100.0%)\n",
      "\n",
      "CLIP Overall Accuracy: 98.4%\n"
     ]
    }
   ],
   "source": [
    "# Run CLIP classification\n",
    "clip_results, clip_overall = run_classification_test('clip-resnext')\n",
    "\n",
    "print(\"\\nCLIP Results per Class:\")\n",
    "for cls, res in clip_results.items():\n",
    "    print(f\"{cls:20s}: {res['correct']}/{res['trials']} ({res['accuracy']:.1%})\")\n",
    "print(f\"\\nCLIP Overall Accuracy: {clip_overall:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
