{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Class Different Size (SCDS) Comparison\n",
    "\n",
    "This notebook compares CVCL and CLIP models on prototype evaluation where distractors are the same class but differ in size.\n",
    "For example, testing a large apple against small apple, medium apple, tiny apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------- ------------ 8.9/12.8 MB 69.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 72.9 MB/s  0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\clip\\clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir, os.pardir))\n",
    "\n",
    "# Add discover-hidden-visual-concepts to path\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "from models.multimodal.multimodal_lit import MultiModalLitModel\n",
    "\n",
    "# hard-coded paths\n",
    "CSV_PATH = os.path.join(REPO_ROOT, 'data', 'KonkLab', 'testdata.csv')\n",
    "IMG_DIR = os.path.join(REPO_ROOT, 'data', 'KonkLab', '17-objects')\n",
    "MASTER_CSV = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'all_prototype_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Dataset and Helper Functions\n",
    "class SizeImageDataset(Dataset):\n",
    "    \"\"\"Dataset returning (img_tensor, class, size, idx).\"\"\"\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        required = ['Filename','Class','Size']\n",
    "        assert all(c in self.df for c in required), f\"CSV must contain columns: {required}\"\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        cls, sz = row['Class'], row['Size']\n",
    "        fn = row['Filename']\n",
    "        path = os.path.join(self.img_dir, cls, fn)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img), cls, sz, idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    sizes = [b[2] for b in batch]\n",
    "    idxs = [b[3] for b in batch]\n",
    "    return imgs, classes, sizes, idxs\n",
    "\n",
    "def run_scds_test(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', batch_size=64, trials_per_tuple=10, max_images=None):\n",
    "    \"\"\"Run Same Class Different Size (SCDS) evaluation.\n",
    "    \n",
    "    Tests if model can identify objects when distractors are from the SAME class\n",
    "    but differ in size:\n",
    "    - Same class\n",
    "    - Different size\n",
    "    \n",
    "    This is a harder test as distractors share the class but differ only in size.\n",
    "    Example: large apple vs. small apple, medium apple, tiny apple\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # 1) load model & transform\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    print(f\"[INFO] Loaded model '{model_name}'\")\n",
    "\n",
    "    # 2) prepare DataLoader & extract embeddings\n",
    "    ds = SizeImageDataset(CSV_PATH, IMG_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    all_embs, all_classes, all_sizes, all_idxs = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, sizes, idxs in loader:\n",
    "            feats = extractor.get_img_feature(imgs.to(device))\n",
    "            feats = extractor.norm_features(feats).cpu()\n",
    "            feats = feats.float()\n",
    "            all_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_sizes.extend(sizes)\n",
    "            all_idxs.extend(idxs)\n",
    "    all_embs = torch.cat(all_embs, dim=0)\n",
    "    print(f\"[INFO] Extracted embeddings for {len(all_idxs)} images\")\n",
    "\n",
    "    # 3) group by (class, size) pair\n",
    "    cs_idxs = defaultdict(lambda: defaultdict(list))\n",
    "    for idx, cls, sz in zip(all_idxs, all_classes, all_sizes):\n",
    "        cs_idxs[cls][sz].append(idx)\n",
    "\n",
    "    # 4) run evaluation\n",
    "    total_correct = 0\n",
    "    total_trials = 0\n",
    "    tuple_results = {}\n",
    "    \n",
    "    print(\"[INFO] Running 4-way trials: distractors with same class but different size\")\n",
    "    for cls, size_groups in cs_idxs.items():\n",
    "        for size, idx_list in size_groups.items():\n",
    "            # Get pool: same class but different size\n",
    "            other_idxs = [\n",
    "                i for sz2, lst2 in size_groups.items() if sz2 != size\n",
    "                for i in lst2\n",
    "            ]\n",
    "            \n",
    "            if len(idx_list) < 1 or len(other_idxs) < 3:\n",
    "                continue\n",
    "\n",
    "            correct = 0\n",
    "            for _ in range(trials_per_tuple):\n",
    "                q = random.choice(idx_list)\n",
    "                same_rest = [i for i in idx_list if i != q]\n",
    "                if same_rest:\n",
    "                    proto = all_embs[[all_idxs.index(i) for i in same_rest]].mean(0)\n",
    "                else:\n",
    "                    proto = all_embs[all_idxs.index(q)]\n",
    "                proto = proto / proto.norm()\n",
    "\n",
    "                distractors = random.sample(other_idxs, 3)\n",
    "                candidates = [q] + distractors\n",
    "                feats_cand = all_embs[[all_idxs.index(i) for i in candidates]]\n",
    "                sims = feats_cand @ proto\n",
    "                guess = candidates[sims.argmax().item()]\n",
    "\n",
    "                correct += int(guess == q)\n",
    "                total_correct += int(guess == q)\n",
    "                total_trials += 1\n",
    "\n",
    "            acc = correct / trials_per_tuple\n",
    "            key = f\"{cls}-{size}\"\n",
    "            tuple_results[key] = {'correct': correct, 'trials': trials_per_tuple, 'accuracy': acc}\n",
    "            print(f\"{cls:12s} / {size:6s} : {correct}/{trials_per_tuple} ({acc:.1%})\")\n",
    "\n",
    "    overall_acc = total_correct / total_trials if total_trials else 0.0\n",
    "    print(f\"\\n[OK] Overall accuracy: {total_correct}/{total_trials} ({overall_acc:.1%})\")\n",
    "    \n",
    "    # 5) save results\n",
    "    summary_df = pd.DataFrame([{'Model': model_name, 'Test': 'Same-Class-Different-Size', 'Correct': total_correct, 'Trials': total_trials, 'Accuracy': overall_acc}])\n",
    "    \n",
    "    os.makedirs(os.path.dirname(MASTER_CSV), exist_ok=True)\n",
    "    if os.path.exists(MASTER_CSV):\n",
    "        summary_df.to_csv(MASTER_CSV, mode='a', header=False, index=False, float_format='%.4f')\n",
    "    else:\n",
    "        summary_df.to_csv(MASTER_CSV, index=False, float_format='%.4f')\n",
    "\n",
    "    return tuple_results, overall_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVCL Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.8 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\jbats\\.cache\\huggingface\\hub\\models--wkvong--cvcl_s_dino_resnext50_embedding\\snapshots\\f50eaa0c50a6076a5190b1dd52aeeb6c3e747045\\cvcl_s_dino_resnext50_embedding.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model 'cvcl-resnext'\n",
      "[INFO] Extracted embeddings for 1005 images\n",
      "[INFO] Running 4-way trials: distractors with same class but different size\n",
      "muffins      / Medium : 1/10 (10.0%)\n",
      "muffins      / Large  : 6/10 (60.0%)\n",
      "pitcher      / Large  : 10/10 (100.0%)\n",
      "tennisracquet / Medium : 5/10 (50.0%)\n",
      "phone        / Large  : 10/10 (100.0%)\n",
      "phone        / Small  : 10/10 (100.0%)\n",
      "headband     / Medium : 4/10 (40.0%)\n",
      "headband     / Small  : 9/10 (90.0%)\n",
      "bagel        / Large  : 10/10 (100.0%)\n",
      "grill        / Small  : 10/10 (100.0%)\n",
      "basket       / Small  : 4/10 (40.0%)\n",
      "bell         / Medium : 0/10 (0.0%)\n",
      "microwave    / Large  : 10/10 (100.0%)\n",
      "trophy       / Small  : 4/10 (40.0%)\n",
      "trophy       / Medium : 2/10 (20.0%)\n",
      "fan          / Medium : 9/10 (90.0%)\n",
      "fan          / Small  : 10/10 (100.0%)\n",
      "fan          / Large  : 10/10 (100.0%)\n",
      "lei          / Medium : 2/10 (20.0%)\n",
      "lei          / Small  : 3/10 (30.0%)\n",
      "stapler      / Medium : 2/10 (20.0%)\n",
      "stapler      / Small  : 6/10 (60.0%)\n",
      "exercise_equipment / Medium : 0/10 (0.0%)\n",
      "handgun      / Small  : 6/10 (60.0%)\n",
      "handgun      / Medium : 3/10 (30.0%)\n",
      "seashell     / Medium : 0/10 (0.0%)\n",
      "seashell     / Small  : 5/10 (50.0%)\n",
      "powerstrip   / Medium : 1/10 (10.0%)\n",
      "powerstrip   / Small  : 0/10 (0.0%)\n",
      "lipstick     / Small  : 6/10 (60.0%)\n",
      "lipstick     / Medium : 0/10 (0.0%)\n",
      "lantern      / Small  : 1/10 (10.0%)\n",
      "lantern      / Medium : 0/10 (0.0%)\n",
      "doorknob     / Large  : 7/10 (70.0%)\n",
      "doorknob     / Medium : 4/10 (40.0%)\n",
      "doorknob     / Small  : 10/10 (100.0%)\n",
      "abacus       / Small  : 10/10 (100.0%)\n",
      "abacus       / Medium : 7/10 (70.0%)\n",
      "abacus       / Large  : 10/10 (100.0%)\n",
      "jack-o-lantern / Large  : 7/10 (70.0%)\n",
      "jack-o-lantern / Medium : 2/10 (20.0%)\n",
      "bird         / Medium : 1/10 (10.0%)\n",
      "bird         / Small  : 5/10 (50.0%)\n",
      "saddle       / Medium : 0/10 (0.0%)\n",
      "saddle       / Small  : 0/10 (0.0%)\n",
      "handbag      / Small  : 10/10 (100.0%)\n",
      "handbag      / Large  : 10/10 (100.0%)\n",
      "stool        / Medium : 5/10 (50.0%)\n",
      "stool        / Small  : 6/10 (60.0%)\n",
      "toyrabbit    / Small  : 0/10 (0.0%)\n",
      "candleholderwithcandle / Medium : 10/10 (100.0%)\n",
      "lock         / Medium : 9/10 (90.0%)\n",
      "lock         / Small  : 9/10 (90.0%)\n",
      "lock         / Large  : 10/10 (100.0%)\n",
      "train        / Medium : 7/10 (70.0%)\n",
      "train        / Small  : 9/10 (90.0%)\n",
      "bonzai       / Medium : 1/10 (10.0%)\n",
      "bonzai       / Small  : 0/10 (0.0%)\n",
      "ring         / Medium : 2/10 (20.0%)\n",
      "ring         / Small  : 8/10 (80.0%)\n",
      "goggle       / Small  : 5/10 (50.0%)\n",
      "goggle       / Medium : 7/10 (70.0%)\n",
      "trumpet      / Medium : 4/10 (40.0%)\n",
      "vase         / Small  : 0/10 (0.0%)\n",
      "tricycle     / Small  : 5/10 (50.0%)\n",
      "tricycle     / Medium : 4/10 (40.0%)\n",
      "toothpaste   / Small  : 7/10 (70.0%)\n",
      "toothpaste   / Medium : 9/10 (90.0%)\n",
      "nailpolish   / Medium : 2/10 (20.0%)\n",
      "nailpolish   / Small  : 4/10 (40.0%)\n",
      "calculator   / Medium : 0/10 (0.0%)\n",
      "calculator   / Large  : 5/10 (50.0%)\n",
      "tree         / Medium : 9/10 (90.0%)\n",
      "tree         / Small  : 7/10 (70.0%)\n",
      "earings      / Small  : 4/10 (40.0%)\n",
      "earings      / Medium : 0/10 (0.0%)\n",
      "toyhorse     / Medium : 8/10 (80.0%)\n",
      "toyhorse     / Small  : 6/10 (60.0%)\n",
      "apple        / Large  : 7/10 (70.0%)\n",
      "apple        / Medium : 2/10 (20.0%)\n",
      "babushkadolls / Medium : 0/10 (0.0%)\n",
      "babushkadolls / Small  : 6/10 (60.0%)\n",
      "saltpeppershake / Large  : 10/10 (100.0%)\n",
      "dresser      / Medium : 3/10 (30.0%)\n",
      "dresser      / Large  : 1/10 (10.0%)\n",
      "rug          / Large  : 5/10 (50.0%)\n",
      "wineglass    / Medium : 10/10 (100.0%)\n",
      "breadloaf    / Medium : 7/10 (70.0%)\n",
      "breadloaf    / Small  : 2/10 (20.0%)\n",
      "keyboard     / Small  : 0/10 (0.0%)\n",
      "meat         / Large  : 0/10 (0.0%)\n",
      "cookie       / Medium : 5/10 (50.0%)\n",
      "doll         / Medium : 0/10 (0.0%)\n",
      "doll         / Small  : 4/10 (40.0%)\n",
      "pipe         / Medium : 10/10 (100.0%)\n",
      "telescope    / Medium : 10/10 (100.0%)\n",
      "\n",
      "[OK] Overall accuracy: 486/960 (50.6%)\n",
      "\n",
      "CVCL Results by Class-Size:\n",
      "muffins-Medium           : 1/10 (10.0%)\n",
      "muffins-Large            : 6/10 (60.0%)\n",
      "pitcher-Large            : 10/10 (100.0%)\n",
      "tennisracquet-Medium     : 5/10 (50.0%)\n",
      "phone-Large              : 10/10 (100.0%)\n",
      "phone-Small              : 10/10 (100.0%)\n",
      "headband-Medium          : 4/10 (40.0%)\n",
      "headband-Small           : 9/10 (90.0%)\n",
      "bagel-Large              : 10/10 (100.0%)\n",
      "grill-Small              : 10/10 (100.0%)\n",
      "basket-Small             : 4/10 (40.0%)\n",
      "bell-Medium              : 0/10 (0.0%)\n",
      "microwave-Large          : 10/10 (100.0%)\n",
      "trophy-Small             : 4/10 (40.0%)\n",
      "trophy-Medium            : 2/10 (20.0%)\n",
      "fan-Medium               : 9/10 (90.0%)\n",
      "fan-Small                : 10/10 (100.0%)\n",
      "fan-Large                : 10/10 (100.0%)\n",
      "lei-Medium               : 2/10 (20.0%)\n",
      "lei-Small                : 3/10 (30.0%)\n",
      "stapler-Medium           : 2/10 (20.0%)\n",
      "stapler-Small            : 6/10 (60.0%)\n",
      "exercise_equipment-Medium: 0/10 (0.0%)\n",
      "handgun-Small            : 6/10 (60.0%)\n",
      "handgun-Medium           : 3/10 (30.0%)\n",
      "seashell-Medium          : 0/10 (0.0%)\n",
      "seashell-Small           : 5/10 (50.0%)\n",
      "powerstrip-Medium        : 1/10 (10.0%)\n",
      "powerstrip-Small         : 0/10 (0.0%)\n",
      "lipstick-Small           : 6/10 (60.0%)\n",
      "lipstick-Medium          : 0/10 (0.0%)\n",
      "lantern-Small            : 1/10 (10.0%)\n",
      "lantern-Medium           : 0/10 (0.0%)\n",
      "doorknob-Large           : 7/10 (70.0%)\n",
      "doorknob-Medium          : 4/10 (40.0%)\n",
      "doorknob-Small           : 10/10 (100.0%)\n",
      "abacus-Small             : 10/10 (100.0%)\n",
      "abacus-Medium            : 7/10 (70.0%)\n",
      "abacus-Large             : 10/10 (100.0%)\n",
      "jack-o-lantern-Large     : 7/10 (70.0%)\n",
      "jack-o-lantern-Medium    : 2/10 (20.0%)\n",
      "bird-Medium              : 1/10 (10.0%)\n",
      "bird-Small               : 5/10 (50.0%)\n",
      "saddle-Medium            : 0/10 (0.0%)\n",
      "saddle-Small             : 0/10 (0.0%)\n",
      "handbag-Small            : 10/10 (100.0%)\n",
      "handbag-Large            : 10/10 (100.0%)\n",
      "stool-Medium             : 5/10 (50.0%)\n",
      "stool-Small              : 6/10 (60.0%)\n",
      "toyrabbit-Small          : 0/10 (0.0%)\n",
      "candleholderwithcandle-Medium: 10/10 (100.0%)\n",
      "lock-Medium              : 9/10 (90.0%)\n",
      "lock-Small               : 9/10 (90.0%)\n",
      "lock-Large               : 10/10 (100.0%)\n",
      "train-Medium             : 7/10 (70.0%)\n",
      "train-Small              : 9/10 (90.0%)\n",
      "bonzai-Medium            : 1/10 (10.0%)\n",
      "bonzai-Small             : 0/10 (0.0%)\n",
      "ring-Medium              : 2/10 (20.0%)\n",
      "ring-Small               : 8/10 (80.0%)\n",
      "goggle-Small             : 5/10 (50.0%)\n",
      "goggle-Medium            : 7/10 (70.0%)\n",
      "trumpet-Medium           : 4/10 (40.0%)\n",
      "vase-Small               : 0/10 (0.0%)\n",
      "tricycle-Small           : 5/10 (50.0%)\n",
      "tricycle-Medium          : 4/10 (40.0%)\n",
      "toothpaste-Small         : 7/10 (70.0%)\n",
      "toothpaste-Medium        : 9/10 (90.0%)\n",
      "nailpolish-Medium        : 2/10 (20.0%)\n",
      "nailpolish-Small         : 4/10 (40.0%)\n",
      "calculator-Medium        : 0/10 (0.0%)\n",
      "calculator-Large         : 5/10 (50.0%)\n",
      "tree-Medium              : 9/10 (90.0%)\n",
      "tree-Small               : 7/10 (70.0%)\n",
      "earings-Small            : 4/10 (40.0%)\n",
      "earings-Medium           : 0/10 (0.0%)\n",
      "toyhorse-Medium          : 8/10 (80.0%)\n",
      "toyhorse-Small           : 6/10 (60.0%)\n",
      "apple-Large              : 7/10 (70.0%)\n",
      "apple-Medium             : 2/10 (20.0%)\n",
      "babushkadolls-Medium     : 0/10 (0.0%)\n",
      "babushkadolls-Small      : 6/10 (60.0%)\n",
      "saltpeppershake-Large    : 10/10 (100.0%)\n",
      "dresser-Medium           : 3/10 (30.0%)\n",
      "dresser-Large            : 1/10 (10.0%)\n",
      "rug-Large                : 5/10 (50.0%)\n",
      "wineglass-Medium         : 10/10 (100.0%)\n",
      "breadloaf-Medium         : 7/10 (70.0%)\n",
      "breadloaf-Small          : 2/10 (20.0%)\n",
      "keyboard-Small           : 0/10 (0.0%)\n",
      "meat-Large               : 0/10 (0.0%)\n",
      "cookie-Medium            : 5/10 (50.0%)\n",
      "doll-Medium              : 0/10 (0.0%)\n",
      "doll-Small               : 4/10 (40.0%)\n",
      "pipe-Medium              : 10/10 (100.0%)\n",
      "telescope-Medium         : 10/10 (100.0%)\n",
      "\n",
      "CVCL Overall Accuracy: 50.6%\n"
     ]
    }
   ],
   "source": [
    "# Run CVCL evaluation\n",
    "cvcl_results, cvcl_overall = run_scds_test('cvcl-resnext')\n",
    "\n",
    "print(\"\\nCVCL Results by Class-Size:\")\n",
    "for key, res in cvcl_results.items():\n",
    "    print(f\"{key:25s}: {res['correct']}/{res['trials']} ({res['accuracy']:.1%})\")\n",
    "print(f\"\\nCVCL Overall Accuracy: {cvcl_overall:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model 'clip-resnext'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jbats\\miniconda3\\envs\\ntu-synthetic\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracted embeddings for 1005 images\n",
      "[INFO] Running 4-way trials: distractors with same class but different size\n",
      "muffins      / Medium : 3/10 (30.0%)\n",
      "muffins      / Large  : 2/10 (20.0%)\n",
      "pitcher      / Large  : 10/10 (100.0%)\n",
      "tennisracquet / Medium : 4/10 (40.0%)\n",
      "phone        / Large  : 10/10 (100.0%)\n",
      "phone        / Small  : 10/10 (100.0%)\n",
      "headband     / Medium : 9/10 (90.0%)\n",
      "headband     / Small  : 8/10 (80.0%)\n",
      "bagel        / Large  : 10/10 (100.0%)\n",
      "grill        / Small  : 10/10 (100.0%)\n",
      "basket       / Small  : 0/10 (0.0%)\n",
      "bell         / Medium : 0/10 (0.0%)\n",
      "microwave    / Large  : 10/10 (100.0%)\n",
      "trophy       / Small  : 1/10 (10.0%)\n",
      "trophy       / Medium : 4/10 (40.0%)\n",
      "fan          / Medium : 7/10 (70.0%)\n",
      "fan          / Small  : 8/10 (80.0%)\n",
      "fan          / Large  : 10/10 (100.0%)\n",
      "lei          / Medium : 2/10 (20.0%)\n",
      "lei          / Small  : 0/10 (0.0%)\n",
      "stapler      / Medium : 4/10 (40.0%)\n",
      "stapler      / Small  : 3/10 (30.0%)\n",
      "exercise_equipment / Medium : 0/10 (0.0%)\n",
      "handgun      / Small  : 5/10 (50.0%)\n",
      "handgun      / Medium : 6/10 (60.0%)\n",
      "seashell     / Medium : 4/10 (40.0%)\n",
      "seashell     / Small  : 10/10 (100.0%)\n",
      "powerstrip   / Medium : 3/10 (30.0%)\n",
      "powerstrip   / Small  : 2/10 (20.0%)\n",
      "lipstick     / Small  : 5/10 (50.0%)\n",
      "lipstick     / Medium : 2/10 (20.0%)\n",
      "lantern      / Small  : 4/10 (40.0%)\n",
      "lantern      / Medium : 1/10 (10.0%)\n",
      "doorknob     / Large  : 1/10 (10.0%)\n",
      "doorknob     / Medium : 4/10 (40.0%)\n",
      "doorknob     / Small  : 6/10 (60.0%)\n",
      "abacus       / Small  : 10/10 (100.0%)\n",
      "abacus       / Medium : 3/10 (30.0%)\n",
      "abacus       / Large  : 10/10 (100.0%)\n",
      "jack-o-lantern / Large  : 4/10 (40.0%)\n",
      "jack-o-lantern / Medium : 3/10 (30.0%)\n",
      "bird         / Medium : 1/10 (10.0%)\n",
      "bird         / Small  : 1/10 (10.0%)\n",
      "saddle       / Medium : 4/10 (40.0%)\n",
      "saddle       / Small  : 4/10 (40.0%)\n",
      "handbag      / Small  : 10/10 (100.0%)\n",
      "handbag      / Large  : 10/10 (100.0%)\n",
      "stool        / Medium : 7/10 (70.0%)\n",
      "stool        / Small  : 6/10 (60.0%)\n",
      "toyrabbit    / Small  : 0/10 (0.0%)\n",
      "candleholderwithcandle / Medium : 10/10 (100.0%)\n",
      "lock         / Medium : 6/10 (60.0%)\n",
      "lock         / Small  : 6/10 (60.0%)\n",
      "lock         / Large  : 10/10 (100.0%)\n",
      "train        / Medium : 4/10 (40.0%)\n",
      "train        / Small  : 3/10 (30.0%)\n",
      "bonzai       / Medium : 5/10 (50.0%)\n",
      "bonzai       / Small  : 0/10 (0.0%)\n",
      "ring         / Medium : 0/10 (0.0%)\n",
      "ring         / Small  : 8/10 (80.0%)\n",
      "goggle       / Small  : 4/10 (40.0%)\n",
      "goggle       / Medium : 5/10 (50.0%)\n",
      "trumpet      / Medium : 0/10 (0.0%)\n",
      "vase         / Small  : 1/10 (10.0%)\n",
      "tricycle     / Small  : 5/10 (50.0%)\n",
      "tricycle     / Medium : 1/10 (10.0%)\n",
      "toothpaste   / Small  : 5/10 (50.0%)\n",
      "toothpaste   / Medium : 9/10 (90.0%)\n",
      "nailpolish   / Medium : 4/10 (40.0%)\n",
      "nailpolish   / Small  : 4/10 (40.0%)\n",
      "calculator   / Medium : 0/10 (0.0%)\n",
      "calculator   / Large  : 2/10 (20.0%)\n",
      "tree         / Medium : 7/10 (70.0%)\n",
      "tree         / Small  : 6/10 (60.0%)\n",
      "earings      / Small  : 4/10 (40.0%)\n",
      "earings      / Medium : 0/10 (0.0%)\n",
      "toyhorse     / Medium : 9/10 (90.0%)\n",
      "toyhorse     / Small  : 6/10 (60.0%)\n",
      "apple        / Large  : 5/10 (50.0%)\n",
      "apple        / Medium : 4/10 (40.0%)\n",
      "babushkadolls / Medium : 1/10 (10.0%)\n",
      "babushkadolls / Small  : 8/10 (80.0%)\n",
      "saltpeppershake / Large  : 10/10 (100.0%)\n",
      "dresser      / Medium : 1/10 (10.0%)\n",
      "dresser      / Large  : 2/10 (20.0%)\n",
      "rug          / Large  : 4/10 (40.0%)\n",
      "wineglass    / Medium : 10/10 (100.0%)\n",
      "breadloaf    / Medium : 6/10 (60.0%)\n",
      "breadloaf    / Small  : 8/10 (80.0%)\n",
      "keyboard     / Small  : 0/10 (0.0%)\n",
      "meat         / Large  : 0/10 (0.0%)\n",
      "cookie       / Medium : 9/10 (90.0%)\n",
      "doll         / Medium : 2/10 (20.0%)\n",
      "doll         / Small  : 4/10 (40.0%)\n",
      "pipe         / Medium : 10/10 (100.0%)\n",
      "telescope    / Medium : 10/10 (100.0%)\n",
      "\n",
      "[OK] Overall accuracy: 469/960 (48.9%)\n",
      "\n",
      "CLIP Results by Class-Size:\n",
      "muffins-Medium           : 3/10 (30.0%)\n",
      "muffins-Large            : 2/10 (20.0%)\n",
      "pitcher-Large            : 10/10 (100.0%)\n",
      "tennisracquet-Medium     : 4/10 (40.0%)\n",
      "phone-Large              : 10/10 (100.0%)\n",
      "phone-Small              : 10/10 (100.0%)\n",
      "headband-Medium          : 9/10 (90.0%)\n",
      "headband-Small           : 8/10 (80.0%)\n",
      "bagel-Large              : 10/10 (100.0%)\n",
      "grill-Small              : 10/10 (100.0%)\n",
      "basket-Small             : 0/10 (0.0%)\n",
      "bell-Medium              : 0/10 (0.0%)\n",
      "microwave-Large          : 10/10 (100.0%)\n",
      "trophy-Small             : 1/10 (10.0%)\n",
      "trophy-Medium            : 4/10 (40.0%)\n",
      "fan-Medium               : 7/10 (70.0%)\n",
      "fan-Small                : 8/10 (80.0%)\n",
      "fan-Large                : 10/10 (100.0%)\n",
      "lei-Medium               : 2/10 (20.0%)\n",
      "lei-Small                : 0/10 (0.0%)\n",
      "stapler-Medium           : 4/10 (40.0%)\n",
      "stapler-Small            : 3/10 (30.0%)\n",
      "exercise_equipment-Medium: 0/10 (0.0%)\n",
      "handgun-Small            : 5/10 (50.0%)\n",
      "handgun-Medium           : 6/10 (60.0%)\n",
      "seashell-Medium          : 4/10 (40.0%)\n",
      "seashell-Small           : 10/10 (100.0%)\n",
      "powerstrip-Medium        : 3/10 (30.0%)\n",
      "powerstrip-Small         : 2/10 (20.0%)\n",
      "lipstick-Small           : 5/10 (50.0%)\n",
      "lipstick-Medium          : 2/10 (20.0%)\n",
      "lantern-Small            : 4/10 (40.0%)\n",
      "lantern-Medium           : 1/10 (10.0%)\n",
      "doorknob-Large           : 1/10 (10.0%)\n",
      "doorknob-Medium          : 4/10 (40.0%)\n",
      "doorknob-Small           : 6/10 (60.0%)\n",
      "abacus-Small             : 10/10 (100.0%)\n",
      "abacus-Medium            : 3/10 (30.0%)\n",
      "abacus-Large             : 10/10 (100.0%)\n",
      "jack-o-lantern-Large     : 4/10 (40.0%)\n",
      "jack-o-lantern-Medium    : 3/10 (30.0%)\n",
      "bird-Medium              : 1/10 (10.0%)\n",
      "bird-Small               : 1/10 (10.0%)\n",
      "saddle-Medium            : 4/10 (40.0%)\n",
      "saddle-Small             : 4/10 (40.0%)\n",
      "handbag-Small            : 10/10 (100.0%)\n",
      "handbag-Large            : 10/10 (100.0%)\n",
      "stool-Medium             : 7/10 (70.0%)\n",
      "stool-Small              : 6/10 (60.0%)\n",
      "toyrabbit-Small          : 0/10 (0.0%)\n",
      "candleholderwithcandle-Medium: 10/10 (100.0%)\n",
      "lock-Medium              : 6/10 (60.0%)\n",
      "lock-Small               : 6/10 (60.0%)\n",
      "lock-Large               : 10/10 (100.0%)\n",
      "train-Medium             : 4/10 (40.0%)\n",
      "train-Small              : 3/10 (30.0%)\n",
      "bonzai-Medium            : 5/10 (50.0%)\n",
      "bonzai-Small             : 0/10 (0.0%)\n",
      "ring-Medium              : 0/10 (0.0%)\n",
      "ring-Small               : 8/10 (80.0%)\n",
      "goggle-Small             : 4/10 (40.0%)\n",
      "goggle-Medium            : 5/10 (50.0%)\n",
      "trumpet-Medium           : 0/10 (0.0%)\n",
      "vase-Small               : 1/10 (10.0%)\n",
      "tricycle-Small           : 5/10 (50.0%)\n",
      "tricycle-Medium          : 1/10 (10.0%)\n",
      "toothpaste-Small         : 5/10 (50.0%)\n",
      "toothpaste-Medium        : 9/10 (90.0%)\n",
      "nailpolish-Medium        : 4/10 (40.0%)\n",
      "nailpolish-Small         : 4/10 (40.0%)\n",
      "calculator-Medium        : 0/10 (0.0%)\n",
      "calculator-Large         : 2/10 (20.0%)\n",
      "tree-Medium              : 7/10 (70.0%)\n",
      "tree-Small               : 6/10 (60.0%)\n",
      "earings-Small            : 4/10 (40.0%)\n",
      "earings-Medium           : 0/10 (0.0%)\n",
      "toyhorse-Medium          : 9/10 (90.0%)\n",
      "toyhorse-Small           : 6/10 (60.0%)\n",
      "apple-Large              : 5/10 (50.0%)\n",
      "apple-Medium             : 4/10 (40.0%)\n",
      "babushkadolls-Medium     : 1/10 (10.0%)\n",
      "babushkadolls-Small      : 8/10 (80.0%)\n",
      "saltpeppershake-Large    : 10/10 (100.0%)\n",
      "dresser-Medium           : 1/10 (10.0%)\n",
      "dresser-Large            : 2/10 (20.0%)\n",
      "rug-Large                : 4/10 (40.0%)\n",
      "wineglass-Medium         : 10/10 (100.0%)\n",
      "breadloaf-Medium         : 6/10 (60.0%)\n",
      "breadloaf-Small          : 8/10 (80.0%)\n",
      "keyboard-Small           : 0/10 (0.0%)\n",
      "meat-Large               : 0/10 (0.0%)\n",
      "cookie-Medium            : 9/10 (90.0%)\n",
      "doll-Medium              : 2/10 (20.0%)\n",
      "doll-Small               : 4/10 (40.0%)\n",
      "pipe-Medium              : 10/10 (100.0%)\n",
      "telescope-Medium         : 10/10 (100.0%)\n",
      "\n",
      "CLIP Overall Accuracy: 48.9%\n"
     ]
    }
   ],
   "source": [
    "# Run CLIP evaluation\n",
    "clip_results, clip_overall = run_scds_test('clip-resnext')\n",
    "\n",
    "print(\"\\nCLIP Results by Class-Size:\")\n",
    "for key, res in clip_results.items():\n",
    "    print(f\"{key:25s}: {res['correct']}/{res['trials']} ({res['accuracy']:.1%})\")\n",
    "print(f\"\\nCLIP Overall Accuracy: {clip_overall:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
