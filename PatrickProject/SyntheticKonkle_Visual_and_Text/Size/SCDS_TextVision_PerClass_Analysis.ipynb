{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Class Different Size (SCDS) Text-Vision Analysis with Controlled Attributes\n",
    "\n",
    "This notebook tests size discrimination WITHIN the same class using text-vision alignment.\n",
    "All trials have matched color and texture, with only size varying.\n",
    "Text encoding uses size+class format (e.g., \"small apple\", \"large apple\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "import time\n",
    "\n",
    "# Path setup\n",
    "REPO_ROOT = r'C:\\Users\\jbats\\Projects\\NTU-Synthetic'\n",
    "DISCOVER_ROOT = os.path.join(REPO_ROOT, 'discover-hidden-visual-concepts')\n",
    "sys.path.insert(0, DISCOVER_ROOT)\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "# Import from discover-hidden-visual-concepts repo\n",
    "sys.path.append(os.path.join(DISCOVER_ROOT, 'src'))\n",
    "from utils.model_loader import load_model\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "\n",
    "# SyntheticKonkle paths - Using 224x224 resized images\n",
    "DATA_DIR = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle_224')\n",
    "RESULTS_DIR = os.path.join(REPO_ROOT, 'PatrickProject', 'Chart_Generation', 'Textvision')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset setup with proper attribute tracking\n",
    "def build_synthetic_dataset():\n",
    "    \"\"\"Load the master labels CSV with all visual properties.\"\"\"\n",
    "    # Use the master_labels.csv which has all the attribute information\n",
    "    master_csv = os.path.join(DATA_DIR, 'master_labels.csv')\n",
    "    \n",
    "    if not os.path.exists(master_csv):\n",
    "        print(f\"Warning: {master_csv} not found, trying alternative path...\")\n",
    "        # Try the original SyntheticKonkle folder\n",
    "        master_csv = os.path.join(REPO_ROOT, 'data', 'SyntheticKonkle', 'master_labels.csv')\n",
    "    \n",
    "    print(f\"Loading master labels from: {master_csv}\")\n",
    "    df = pd.read_csv(master_csv)\n",
    "    \n",
    "    # Ensure all required columns are present\n",
    "    required_cols = ['folder', 'filename', 'class', 'color', 'size', 'texture']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Clean the data\n",
    "    df = df.dropna(subset=required_cols)\n",
    "    \n",
    "    # Filter to valid sizes only\n",
    "    valid_sizes = ['small', 'medium', 'large']\n",
    "    df = df[df['size'].isin(valid_sizes)].copy()\n",
    "    \n",
    "    print(f\"Loaded {len(df)} images\")\n",
    "    print(f\"Classes: {df['class'].nunique()} unique\")\n",
    "    print(f\"Colors: {df['color'].nunique()} unique\")\n",
    "    print(f\"Sizes: {df['size'].nunique()} unique ({sorted(df['size'].unique())})\")\n",
    "    print(f\"Textures: {df['texture'].nunique()} unique\")\n",
    "    \n",
    "    # Check size distribution within classes\n",
    "    size_per_class = df.groupby('class')['size'].nunique()\n",
    "    print(f\"\\nAverage sizes per class: {size_per_class.mean():.1f}\")\n",
    "    print(f\"Min sizes in a class: {size_per_class.min()}\")\n",
    "    print(f\"Max sizes in a class: {size_per_class.max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "class SyntheticImageDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform):\n",
    "        self.df = df\n",
    "        # For SyntheticKonkle_224, images are in nested structure\n",
    "        self.data_dir = os.path.join(data_dir, 'SyntheticKonkle')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row['folder'], row['filename'])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "        except Exception as e:\n",
    "            # Return a black image if file not found\n",
    "            img = Image.new('RGB', (224, 224), color='black')\n",
    "            return self.transform(img), row['class'], row['color'], row['size'], row['texture'], idx\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch])\n",
    "    classes = [b[1] for b in batch]\n",
    "    colors = [b[2] for b in batch]\n",
    "    sizes = [b[3] for b in batch]\n",
    "    textures = [b[4] for b in batch]\n",
    "    idxs = [b[5] for b in batch]\n",
    "    return imgs, classes, colors, sizes, textures, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scds_text_vision_test_per_class(model_name, seed=0, device='cuda' if torch.cuda.is_available() else 'cpu', \n",
    "                                        batch_size=32, trials_per_class=500):\n",
    "    \"\"\"\n",
    "    Run Same Class Different Size text-vision test with controlled color and texture.\n",
    "    Returns per-class accuracy results.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Check if model supports text encoding\n",
    "    if model_name in ['resnext', 'dino_s_resnext50']:\n",
    "        print(f\"[WARNING] {model_name} has no text encoder, skipping\")\n",
    "        return {}\n",
    "\n",
    "    # Load model & transform\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    model, transform = load_model(model_name, seed=seed, device=device)\n",
    "    extractor = FeatureExtractor(model_name, model, device)\n",
    "    \n",
    "    # Build dataset and extract image embeddings\n",
    "    df = build_synthetic_dataset()\n",
    "    ds = SyntheticImageDataset(df, DATA_DIR, transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    print(\"Extracting image embeddings...\")\n",
    "    all_img_embs, all_classes, all_colors, all_sizes, all_textures, all_idxs = [], [], [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, classes, colors, sizes, textures, idxs in tqdm(loader, desc=\"Processing images\"):\n",
    "            imgs = imgs.to(device)\n",
    "            feats = extractor.get_img_feature(imgs)\n",
    "            feats = extractor.norm_features(feats).cpu().float()\n",
    "            all_img_embs.append(feats)\n",
    "            all_classes.extend(classes)\n",
    "            all_colors.extend(colors)\n",
    "            all_sizes.extend(sizes)\n",
    "            all_textures.extend(textures)\n",
    "            all_idxs.extend(idxs)\n",
    "    \n",
    "    all_img_embs = torch.cat(all_img_embs, dim=0)\n",
    "    print(f\"Extracted {len(all_img_embs)} image embeddings\")\n",
    "\n",
    "    # Group images by class, color, texture, and size\n",
    "    # For SCDS: class, color, texture are fixed; size varies\n",
    "    class_color_texture_size_idxs = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    idx_to_row = {idx: i for i, idx in enumerate(all_idxs)}\n",
    "    \n",
    "    for i, (idx, cls, col, size, texture) in enumerate(zip(all_idxs, all_classes, all_colors, all_sizes, all_textures)):\n",
    "        class_color_texture_size_idxs[cls][(col, texture)][size].append(idx)\n",
    "\n",
    "    # Get unique classes and sizes\n",
    "    unique_classes = list(set(all_classes))\n",
    "    valid_sizes = ['small', 'medium', 'large']\n",
    "    \n",
    "    print(f\"Found {len(unique_classes)} classes\")\n",
    "    \n",
    "    # Pre-encode all size+class text combinations\n",
    "    print(\"Encoding text labels for all size-class combinations...\")\n",
    "    text_features_cache = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Create all size+class combinations\n",
    "        text_labels = []\n",
    "        label_keys = []\n",
    "        for cls in unique_classes:\n",
    "            for size in valid_sizes:\n",
    "                # Format: \"small apple\", \"large apple\", etc.\n",
    "                label = f\"{size} {cls}\"\n",
    "                text_labels.append(label)\n",
    "                label_keys.append((cls, size))\n",
    "        \n",
    "        # Encode in batches for efficiency\n",
    "        if \"clip\" in model_name:\n",
    "            # CLIP text encoding\n",
    "            tokens = clip.tokenize(text_labels, truncate=True).to(device)\n",
    "            txt_features = model.encode_text(tokens)\n",
    "            txt_features = extractor.norm_features(txt_features).cpu().float()\n",
    "            for i, (cls, size) in enumerate(label_keys):\n",
    "                text_features_cache[(cls, size)] = txt_features[i]\n",
    "        else:  # CVCL\n",
    "            # CVCL text encoding with token length\n",
    "            tokens, token_len = model.tokenize(text_labels)\n",
    "            tokens = tokens.to(device)\n",
    "            if isinstance(token_len, torch.Tensor):\n",
    "                token_len = token_len.to(device)\n",
    "            txt_features = model.encode_text(tokens, token_len)\n",
    "            txt_features = extractor.norm_features(txt_features).cpu().float()\n",
    "            for i, (cls, size) in enumerate(label_keys):\n",
    "                text_features_cache[(cls, size)] = txt_features[i]\n",
    "    \n",
    "    print(f\"Encoded {len(text_features_cache)} size-class text combinations\")\n",
    "\n",
    "    # Track per-class performance\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    print(f\"Running {trials_per_class} trials per class for SCDS task...\")\n",
    "    \n",
    "    # Run trials for each class\n",
    "    for target_class in tqdm(unique_classes, desc=f\"Testing {model_name} SCDS\"):\n",
    "        trials_done = 0\n",
    "        \n",
    "        # For each color-texture combination in this class\n",
    "        for (color, texture), size_dict in class_color_texture_size_idxs[target_class].items():\n",
    "            if trials_done >= trials_per_class:\n",
    "                break\n",
    "            \n",
    "            # Need all 3 sizes for this class-color-texture combination\n",
    "            available_sizes = list(size_dict.keys())\n",
    "            if len(available_sizes) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Check if we have all three sizes\n",
    "            if not all(size in available_sizes for size in valid_sizes):\n",
    "                continue\n",
    "            \n",
    "            # Run multiple trials for this combination\n",
    "            n_trials = min(20, trials_per_class - trials_done)  # More trials per combination\n",
    "            \n",
    "            for _ in range(n_trials):\n",
    "                # For SCDS, we need exactly 3 sizes, but 4 candidates\n",
    "                # Solution: Use all 3 sizes + duplicate one randomly\n",
    "                \n",
    "                # Select one image from each size\n",
    "                candidates = []\n",
    "                candidate_sizes = []\n",
    "                \n",
    "                for size in valid_sizes:\n",
    "                    if size_dict[size]:  # If images exist for this size\n",
    "                        img_idx = random.choice(size_dict[size])\n",
    "                        candidates.append(img_idx)\n",
    "                        candidate_sizes.append(size)\n",
    "                \n",
    "                if len(candidates) != 3:\n",
    "                    continue\n",
    "                \n",
    "                # For the 4th candidate, duplicate a random size\n",
    "                duplicate_size = random.choice(valid_sizes)\n",
    "                # Try to get a different image of the same size\n",
    "                available_for_duplicate = [idx for idx in size_dict[duplicate_size] \n",
    "                                         if idx not in candidates]\n",
    "                if available_for_duplicate:\n",
    "                    duplicate_idx = random.choice(available_for_duplicate)\n",
    "                else:\n",
    "                    # If no different image, use the same one (not ideal but rare)\n",
    "                    duplicate_idx = random.choice(size_dict[duplicate_size])\n",
    "                \n",
    "                candidates.append(duplicate_idx)\n",
    "                candidate_sizes.append(duplicate_size)\n",
    "                \n",
    "                # Randomly select target\n",
    "                target_position = random.randint(0, 3)\n",
    "                target_idx = candidates[target_position]\n",
    "                target_size = candidate_sizes[target_position]\n",
    "                \n",
    "                # Get image features for all candidates\n",
    "                cand_features = torch.stack([all_img_embs[idx_to_row[idx]] for idx in candidates]).float()\n",
    "                \n",
    "                # Get text feature for target size+class\n",
    "                target_text_feature = text_features_cache[(target_class, target_size)].float()\n",
    "                \n",
    "                # Compute similarity with text encoding\n",
    "                similarities = cand_features @ target_text_feature\n",
    "                \n",
    "                # Check if model correctly identifies target\n",
    "                prediction = similarities.argmax().item()\n",
    "                \n",
    "                # Update counts\n",
    "                class_correct[target_class] += int(prediction == target_position)\n",
    "                class_total[target_class] += 1\n",
    "                trials_done += 1\n",
    "                \n",
    "                if trials_done >= trials_per_class:\n",
    "                    break\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracies = {}\n",
    "    for cls in unique_classes:\n",
    "        if class_total[cls] > 0:\n",
    "            class_accuracies[cls] = class_correct[cls] / class_total[cls]\n",
    "        else:\n",
    "            class_accuracies[cls] = 0.0\n",
    "    \n",
    "    # Print summary\n",
    "    overall_correct = sum(class_correct.values())\n",
    "    overall_total = sum(class_total.values())\n",
    "    overall_acc = overall_correct / overall_total if overall_total > 0 else 0\n",
    "    \n",
    "    print(f\"\\nSCDS Overall: {overall_correct}/{overall_total} = {overall_acc:.3f}\")\n",
    "    print(f\"Classes tested: {len([c for c in class_accuracies if class_total[c] > 0])}\")\n",
    "    \n",
    "    # Show top and bottom performers\n",
    "    sorted_classes = sorted(class_accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop 5 classes for size discrimination:\")\n",
    "    for cls, acc in sorted_classes[:5]:\n",
    "        if class_total[cls] > 0:\n",
    "            print(f\"  {cls}: {acc:.3f} ({class_total[cls]} trials)\")\n",
    "    print(\"\\nBottom 5 classes for size discrimination:\")\n",
    "    for cls, acc in sorted_classes[-5:]:\n",
    "        if class_total[cls] > 0:\n",
    "            print(f\"  {cls}: {acc:.3f} ({class_total[cls]} trials)\")\n",
    "    \n",
    "    return class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple seeds for statistical analysis\n",
    "n_seeds = 3  # Limited seeds due to potential rate limiting\n",
    "trials_per_class = 500  # Consistent with other tests\n",
    "models_to_test = ['cvcl-resnext', 'clip-res']\n",
    "\n",
    "# Check dataset first\n",
    "test_df = build_synthetic_dataset()\n",
    "n_classes = len(test_df['class'].unique())\n",
    "n_sizes = len(test_df['size'].unique())\n",
    "print(f\"Found {n_classes} unique classes and {n_sizes} unique sizes\")\n",
    "\n",
    "print(f\"\\nStarting SCDS Text-Vision evaluation:\")\n",
    "print(f\"Configuration: {n_seeds} seeds × {trials_per_class} trials/class × {n_classes} classes\")\n",
    "print(f\"Task: Same Class Different Size discrimination\")\n",
    "print(f\"Control: Color and texture are held constant within each trial\")\n",
    "print(f\"Text format: size + class (e.g., 'small apple', 'large apple')\\n\")\n",
    "\n",
    "all_results = {model: defaultdict(list) for model in models_to_test}\n",
    "\n",
    "# Run evaluation\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_name} with SCDS text-vision approach\")\n",
    "    print('='*60)\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        print(f\"\\nSeed {seed+1}/{n_seeds} for {model_name}\")\n",
    "        \n",
    "        try:\n",
    "            class_acc = run_scds_text_vision_test_per_class(\n",
    "                model_name, \n",
    "                seed=seed, \n",
    "                trials_per_class=trials_per_class\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            for cls, acc in class_acc.items():\n",
    "                all_results[model_name][cls].append(acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if len(class_acc) > 0:\n",
    "                mean_acc = np.mean(list(class_acc.values()))\n",
    "                print(f\"  Mean accuracy across classes: {mean_acc:.3f}\")\n",
    "                print(f\"  Classes successfully tested: {len(class_acc)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            if \"404\" in str(e) or \"rate\" in str(e).lower():\n",
    "                print(f\"  Rate limit hit - waiting 60 seconds...\")\n",
    "                time.sleep(60)\n",
    "                # Retry once\n",
    "                try:\n",
    "                    class_acc = run_scds_text_vision_test_per_class(\n",
    "                        model_name, seed=seed, trials_per_class=trials_per_class\n",
    "                    )\n",
    "                    for cls, acc in class_acc.items():\n",
    "                        all_results[model_name][cls].append(acc)\n",
    "                    print(f\"  Retry successful!\")\n",
    "                except:\n",
    "                    print(f\"  Retry failed - skipping seed {seed}\")\n",
    "                    continue\n",
    "        \n",
    "        # Add delay between seeds for CVCL\n",
    "        if 'cvcl' in model_name and seed < n_seeds - 1:\n",
    "            print(\"  Waiting 30 seconds before next seed...\")\n",
    "            time.sleep(30)\n",
    "\n",
    "# Calculate statistics\n",
    "stats_results = {}\n",
    "for model_name in models_to_test:\n",
    "    stats_results[model_name] = {}\n",
    "    for cls, accs in all_results[model_name].items():\n",
    "        if len(accs) > 0:\n",
    "            n_samples = len(accs)\n",
    "            stats_results[model_name][cls] = {\n",
    "                'mean': np.mean(accs),\n",
    "                'std': np.std(accs, ddof=1) if n_samples > 1 else 0,\n",
    "                'se': np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'ci95': 1.96 * np.std(accs, ddof=1) / np.sqrt(n_samples) if n_samples > 1 else 0,\n",
    "                'n_samples': n_samples,\n",
    "                'total_trials': n_samples * trials_per_class,\n",
    "                'raw': accs\n",
    "            }\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCDS TEXT-VISION EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results\n",
    "detailed_df = []\n",
    "for model_name in models_to_test:\n",
    "    for cls, stats in stats_results[model_name].items():\n",
    "        for seed_idx, acc in enumerate(stats['raw']):\n",
    "            detailed_df.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'seed': seed_idx,\n",
    "                'accuracy': acc,\n",
    "                'n_trials': trials_per_class,\n",
    "                'test_type': 'scds_text_vision'\n",
    "            })\n",
    "\n",
    "if len(detailed_df) > 0:\n",
    "    detailed_df = pd.DataFrame(detailed_df)\n",
    "    output_path = os.path.join(RESULTS_DIR, 'scds_textvision_perclass_results.csv')\n",
    "    detailed_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSaved detailed results to {output_path}\")\n",
    "    \n",
    "    # Save summary statistics\n",
    "    summary_stats = []\n",
    "    for model_name in models_to_test:\n",
    "        for cls, stats in stats_results[model_name].items():\n",
    "            summary_stats.append({\n",
    "                'model': model_name,\n",
    "                'class': cls,\n",
    "                'mean_accuracy': stats['mean'],\n",
    "                'std': stats['std'],\n",
    "                'se': stats['se'],\n",
    "                'ci95': stats['ci95'],\n",
    "                'n_seeds': stats['n_samples'],\n",
    "                'total_trials': stats['total_trials']\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_stats)\n",
    "    summary_path = os.path.join(RESULTS_DIR, 'scds_textvision_perclass_summary.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"Saved summary statistics to {summary_path}\")\n",
    "else:\n",
    "    print(\"\\nNo results to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "if len(stats_results[models_to_test[0]]) > 0:\n",
    "    fig = plt.figure(figsize=(14, 11))\n",
    "    \n",
    "    # Create subplots\n",
    "    ax1 = plt.subplot2grid((20, 1), (0, 0), rowspan=8)\n",
    "    ax2 = plt.subplot2grid((20, 1), (12, 0), rowspan=8)\n",
    "    \n",
    "    # Prepare data\n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    mid_point = len(classes) // 2\n",
    "    classes_first_half = classes[:mid_point]\n",
    "    classes_second_half = classes[mid_point:]\n",
    "    \n",
    "    # Define colors and markers\n",
    "    colors = {\n",
    "        'cvcl-resnext': '#2a9d8f',  # Teal for CVCL\n",
    "        'clip-res': '#e63946'  # Red for CLIP\n",
    "    }\n",
    "    markers = {\n",
    "        'cvcl-resnext': 'o',\n",
    "        'clip-res': 's'\n",
    "    }\n",
    "    avg_line_styles = {\n",
    "        'cvcl-resnext': '--',\n",
    "        'clip-res': '-.'\n",
    "    }\n",
    "    \n",
    "    legend_elements = []\n",
    "    \n",
    "    def plot_on_axis(ax, class_subset, is_first=False):\n",
    "        x_pos = np.arange(len(class_subset))\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            means = [stats_results[model_name][cls]['mean'] * 100 for cls in class_subset]\n",
    "            errors = [stats_results[model_name][cls]['ci95'] * 100 for cls in class_subset]\n",
    "            \n",
    "            ax.errorbar(x_pos, means, yerr=errors,\n",
    "                       label=model_name.upper().replace('-', ' '),\n",
    "                       color=colors[model_name],\n",
    "                       marker=markers[model_name],\n",
    "                       markersize=7,\n",
    "                       linewidth=0,\n",
    "                       capsize=4,\n",
    "                       capthick=1.5,\n",
    "                       alpha=0.9,\n",
    "                       markeredgecolor='black',\n",
    "                       markeredgewidth=0.5)\n",
    "        \n",
    "        # Add chance level\n",
    "        ax.axhline(y=25, color='#ffa500', linestyle=':', alpha=0.8, linewidth=1.5)\n",
    "        \n",
    "        # Calculate overall averages\n",
    "        all_classes_means = {}\n",
    "        for model_name in models_to_test:\n",
    "            all_means = [stats_results[model_name][cls]['mean'] * 100 for cls in classes]\n",
    "            all_classes_means[model_name] = np.mean(all_means)\n",
    "        \n",
    "        # Add average lines\n",
    "        for model_name in models_to_test:\n",
    "            avg_performance = all_classes_means[model_name]\n",
    "            ax.axhline(y=avg_performance,\n",
    "                      color=colors[model_name],\n",
    "                      linestyle=avg_line_styles[model_name],\n",
    "                      alpha=0.7,\n",
    "                      linewidth=2)\n",
    "            \n",
    "            if is_first:\n",
    "                ax.text(len(class_subset) + 0.8, avg_performance,\n",
    "                       f'{avg_performance:.1f}%',\n",
    "                       fontsize=9,\n",
    "                       color=colors[model_name],\n",
    "                       va='center',\n",
    "                       fontweight='bold')\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_ylabel('SCDS Text-Vision Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(class_subset, rotation=45, ha='right', fontsize=10)\n",
    "        ax.set_ylim(0, 105)\n",
    "        ax.set_yticks([0, 25, 50, 75, 100])\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_facecolor('#fafafa')\n",
    "        \n",
    "        # Create legend elements\n",
    "        global legend_elements\n",
    "        if is_first:\n",
    "            from matplotlib.lines import Line2D\n",
    "            legend_elements = []\n",
    "            \n",
    "            for model_name in models_to_test:\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], marker=markers[model_name], color='w',\n",
    "                          markerfacecolor=colors[model_name], markeredgecolor='black',\n",
    "                          markersize=8, label=model_name.upper().replace('-', ' '))\n",
    "                )\n",
    "            \n",
    "            for model_name in models_to_test:\n",
    "                avg_val = all_classes_means[model_name]\n",
    "                legend_elements.append(\n",
    "                    Line2D([0], [0], color=colors[model_name],\n",
    "                          linestyle=avg_line_styles[model_name], linewidth=2,\n",
    "                          label=f'{model_name.upper().split(\"-\")[0]} Average ({avg_val:.1f}%)')\n",
    "                )\n",
    "            \n",
    "            legend_elements.append(\n",
    "                Line2D([0], [0], color='#ffa500', linestyle=':', linewidth=1.5,\n",
    "                      label='Chance Level (25%)')\n",
    "            )\n",
    "    \n",
    "    # Plot both halves\n",
    "    plot_on_axis(ax1, classes_first_half, is_first=True)\n",
    "    ax1.set_title('SCDS Text-Vision Per-Class Performance - Part 1\\nSame Class Different Size (Color & Texture Controlled)',\n",
    "                 fontsize=13, fontweight='bold', pad=10)\n",
    "    \n",
    "    plot_on_axis(ax2, classes_second_half, is_first=False)\n",
    "    ax2.set_title('SCDS Text-Vision Per-Class Performance - Part 2',\n",
    "                 fontsize=13, fontweight='bold', pad=10)\n",
    "    ax2.set_xlabel('Target Category', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_ax = fig.add_axes([0.125, 0.44, 0.775, 0.08])\n",
    "    legend_ax.axis('off')\n",
    "    \n",
    "    legend = legend_ax.legend(handles=legend_elements,\n",
    "                             loc='center',\n",
    "                             ncol=3,\n",
    "                             fontsize=10,\n",
    "                             frameon=True,\n",
    "                             fancybox=True,\n",
    "                             shadow=True,\n",
    "                             framealpha=0.95,\n",
    "                             columnspacing=2.5,\n",
    "                             handlelength=3)\n",
    "    \n",
    "    legend.get_frame().set_facecolor('white')\n",
    "    legend.get_frame().set_edgecolor('gray')\n",
    "    legend.get_frame().set_linewidth(1.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    \n",
    "    # Save plots\n",
    "    png_path = os.path.join(RESULTS_DIR, 'scds_textvision_perclass.png')\n",
    "    pdf_path = os.path.join(RESULTS_DIR, 'scds_textvision_perclass.pdf')\n",
    "    \n",
    "    plt.savefig(png_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.savefig(pdf_path, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved plots to:\")\n",
    "    print(f\"  - {png_path}\")\n",
    "    print(f\"  - {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "if len(stats_results) > 0 and len(stats_results[models_to_test[0]]) > 0:\n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    \n",
    "    summary_data = []\n",
    "    for cls in classes:\n",
    "        row = {'Class': cls}\n",
    "        for model in models_to_test:\n",
    "            if cls in stats_results[model]:\n",
    "                stats = stats_results[model][cls]\n",
    "                row[f\"{model}_mean\"] = f\"{stats['mean']:.3f}\"\n",
    "                row[f\"{model}_ci95\"] = f\"±{stats['ci95']:.3f}\"\n",
    "                row[f\"{model}_trials\"] = stats['total_trials']\n",
    "        \n",
    "        # Add difference if both models have results\n",
    "        if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "            diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "            row['difference'] = f\"{diff:+.3f}\"\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SCDS TEXT-VISION PER-CLASS PERFORMANCE SUMMARY\")\n",
    "    print(\"Task: Same Class Different Size (Color & Texture Controlled)\")\n",
    "    print(\"=\"*80)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL SCDS TEXT-VISION PERFORMANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for model in models_to_test:\n",
    "        all_accs = []\n",
    "        for cls in classes:\n",
    "            if cls in stats_results[model]:\n",
    "                all_accs.extend(stats_results[model][cls]['raw'])\n",
    "        \n",
    "        if len(all_accs) > 0:\n",
    "            mean = np.mean(all_accs)\n",
    "            std = np.std(all_accs)\n",
    "            se = std / np.sqrt(len(all_accs))\n",
    "            ci95 = 1.96 * se\n",
    "            print(f\"{model}: {mean:.3f} ± {ci95:.3f} (SE: {se:.3f}, n={len(all_accs)} samples)\")\n",
    "    \n",
    "    # Statistical test\n",
    "    from scipy import stats as scipy_stats\n",
    "    \n",
    "    cvcl_all = []\n",
    "    clip_all = []\n",
    "    for cls in classes:\n",
    "        if cls in stats_results['cvcl-resnext']:\n",
    "            cvcl_all.extend(stats_results['cvcl-resnext'][cls]['raw'])\n",
    "        if cls in stats_results['clip-res']:\n",
    "            clip_all.extend(stats_results['clip-res'][cls]['raw'])\n",
    "    \n",
    "    if len(cvcl_all) > 0 and len(clip_all) > 0:\n",
    "        t_stat, p_value = scipy_stats.ttest_ind(cvcl_all, clip_all)\n",
    "        print(f\"\\nt-test: t={t_stat:.3f}, p={p_value:.6f}\")\n",
    "        if p_value < 0.001:\n",
    "            print(\"Result: Highly significant difference (p < 0.001)\")\n",
    "        elif p_value < 0.01:\n",
    "            print(\"Result: Significant difference (p < 0.01)\")\n",
    "        elif p_value < 0.05:\n",
    "            print(\"Result: Significant difference (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"Result: No significant difference\")\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"This test measures how well models can distinguish sizes within the same object class.\")\n",
    "    print(\"Color and texture are held constant, so performance reflects pure size discrimination.\")\n",
    "    print(\"Note: Size discrimination is often harder than color as size is relative.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create difference plot and comparison with other tests\n",
    "if len(stats_results) > 0 and len(stats_results[models_to_test[0]]) > 0:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    classes = sorted(list(stats_results[models_to_test[0]].keys()))\n",
    "    differences = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        if cls in stats_results['clip-res'] and cls in stats_results['cvcl-resnext']:\n",
    "            diff = stats_results['clip-res'][cls]['mean'] - stats_results['cvcl-resnext'][cls]['mean']\n",
    "            differences.append(diff)\n",
    "        else:\n",
    "            differences.append(0)\n",
    "    \n",
    "    colors_diff = ['#2ecc71' if d > 0 else '#e74c3c' for d in differences]\n",
    "    bars = plt.bar(range(len(classes)), differences, color=colors_diff, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (cls, diff) in enumerate(zip(classes, differences)):\n",
    "        if diff != 0:\n",
    "            plt.text(i, diff + (0.01 if diff > 0 else -0.02), f'{diff:.2f}',\n",
    "                    ha='center', va='bottom' if diff > 0 else 'top', fontsize=8)\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    plt.xlabel('Object Class', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Performance Difference\\n(CLIP - CVCL)', fontsize=12, fontweight='bold')\n",
    "    plt.title('SCDS Text-Vision Model Performance Differences by Class\\nSize Discrimination within Same Class',\n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#2ecc71', alpha=0.7, label='CLIP Better'),\n",
    "        Patch(facecolor='#e74c3c', alpha=0.7, label='CVCL Better')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    diff_plot_path = os.path.join(RESULTS_DIR, 'scds_textvision_difference.png')\n",
    "    plt.savefig(diff_plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSaved difference plot to {diff_plot_path}\")\n",
    "    \n",
    "    # Print summary of differences\n",
    "    clip_better = sum(1 for d in differences if d > 0)\n",
    "    cvcl_better = sum(1 for d in differences if d < 0)\n",
    "    tied = sum(1 for d in differences if d == 0)\n",
    "    \n",
    "    print(f\"\\nSummary for SCDS (Size Discrimination):\")\n",
    "    print(f\"  CLIP performs better: {clip_better}/{len(classes)} classes\")\n",
    "    print(f\"  CVCL performs better: {cvcl_better}/{len(classes)} classes\")\n",
    "    if tied > 0:\n",
    "        print(f\"  No difference: {tied}/{len(classes)} classes\")\n",
    "    \n",
    "    avg_diff = np.mean([d for d in differences if d != 0])\n",
    "    print(f\"  Average difference: {avg_diff:.3f}\")\n",
    "    print(f\"\\nNote: Size discrimination is often challenging as size is a relative concept.\")\n",
    "    print(f\"Performance may be lower than color discrimination due to this complexity.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntu-synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}